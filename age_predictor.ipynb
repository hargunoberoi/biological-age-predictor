{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f8e51da8",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "f8e51da8",
        "outputId": "2e453832-436f-4011-a782-07c0e5ce2d5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender  Height (cm)  Weight (kg) Blood Pressure (s/d)  \\\n",
              "0    Male   171.148359    86.185197              151/109   \n",
              "1    Male   172.946206    79.641937              134/112   \n",
              "2  Female   155.945488    49.167058              160/101   \n",
              "3  Female   169.078298    56.017921               133/94   \n",
              "4  Female   163.758355    73.966304              170/106   \n",
              "\n",
              "   Cholesterol Level (mg/dL)        BMI  Blood Glucose Level (mg/dL)  \\\n",
              "0                 259.465814  29.423017                   157.652848   \n",
              "1                 263.630292  26.626847                   118.507805   \n",
              "2                 207.846206  20.217553                   143.587550   \n",
              "3                 253.283779  19.595270                   137.448581   \n",
              "4                 236.119899  27.582078                   145.328695   \n",
              "\n",
              "   Bone Density (g/cm²)  Vision Sharpness  Hearing Ability (dB)  ...  \\\n",
              "0              0.132868          0.200000             58.786198  ...   \n",
              "1              0.629534          0.267312             54.635270  ...   \n",
              "2              0.473487          0.248667             54.564632  ...   \n",
              "3              1.184315          0.513818             79.722963  ...   \n",
              "4              0.434562          0.306864             52.479469  ...   \n",
              "\n",
              "  Family History Cognitive Function Mental Health Status Sleep Patterns  \\\n",
              "0            NaN          44.059172                 Good       Insomnia   \n",
              "1  Heart Disease          45.312298                 Good         Normal   \n",
              "2   Hypertension          56.246991                 Poor       Insomnia   \n",
              "3   Hypertension          55.196092                 Poor       Insomnia   \n",
              "4            NaN          53.023379                 Good         Normal   \n",
              "\n",
              "  Stress Levels Pollution Exposure Sun Exposure  Education Level Income Level  \\\n",
              "0      2.797064           5.142344     7.108975              NaN       Medium   \n",
              "1      9.339930           7.272720     3.918489    Undergraduate       Medium   \n",
              "2      9.234637           8.500386     5.393408              NaN       Medium   \n",
              "3      4.693446           7.555511     2.745578              NaN          Low   \n",
              "4      4.038537           9.429097     3.878435    Undergraduate         High   \n",
              "\n",
              "  Age (years)  \n",
              "0          89  \n",
              "1          77  \n",
              "2          70  \n",
              "3          52  \n",
              "4          79  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60d30b47-d235-401f-92c5-84236fc0695d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Blood Pressure (s/d)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>...</th>\n",
              "      <th>Family History</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Mental Health Status</th>\n",
              "      <th>Sleep Patterns</th>\n",
              "      <th>Stress Levels</th>\n",
              "      <th>Pollution Exposure</th>\n",
              "      <th>Sun Exposure</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Income Level</th>\n",
              "      <th>Age (years)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>151/109</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>Good</td>\n",
              "      <td>Insomnia</td>\n",
              "      <td>2.797064</td>\n",
              "      <td>5.142344</td>\n",
              "      <td>7.108975</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Medium</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>134/112</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>...</td>\n",
              "      <td>Heart Disease</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>9.339930</td>\n",
              "      <td>7.272720</td>\n",
              "      <td>3.918489</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>Medium</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>160/101</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>...</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>Poor</td>\n",
              "      <td>Insomnia</td>\n",
              "      <td>9.234637</td>\n",
              "      <td>8.500386</td>\n",
              "      <td>5.393408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Medium</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>133/94</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>...</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>Poor</td>\n",
              "      <td>Insomnia</td>\n",
              "      <td>4.693446</td>\n",
              "      <td>7.555511</td>\n",
              "      <td>2.745578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Low</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>170/106</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>Good</td>\n",
              "      <td>Normal</td>\n",
              "      <td>4.038537</td>\n",
              "      <td>9.429097</td>\n",
              "      <td>3.878435</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>High</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60d30b47-d235-401f-92c5-84236fc0695d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60d30b47-d235-401f-92c5-84236fc0695d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60d30b47-d235-401f-92c5-84236fc0695d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09ee2964-cb83-419f-b50b-56865ff30fb1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09ee2964-cb83-419f-b50b-56865ff30fb1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09ee2964-cb83-419f-b50b-56865ff30fb1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "484fe2ab",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "484fe2ab",
        "outputId": "5de74e77-85c0-4b21-f1e8-fc32ef177e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg) Blood Pressure (s/d)  Cholesterol Level (mg/dL)  \\\n",
              "0   171.148359    86.185197              151/109                 259.465814   \n",
              "1   172.946206    79.641937              134/112                 263.630292   \n",
              "2   155.945488    49.167058              160/101                 207.846206   \n",
              "3   169.078298    56.017921               133/94                 253.283779   \n",
              "4   163.758355    73.966304              170/106                 236.119899   \n",
              "\n",
              "         BMI  Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  \\\n",
              "0  29.423017                   157.652848              0.132868   \n",
              "1  26.626847                   118.507805              0.629534   \n",
              "2  20.217553                   143.587550              0.473487   \n",
              "3  19.595270                   137.448581              1.184315   \n",
              "4  27.582078                   145.328695              0.434562   \n",
              "\n",
              "   Vision Sharpness  Hearing Ability (dB) Physical Activity Level  \\\n",
              "0          0.200000             58.786198                Moderate   \n",
              "1          0.267312             54.635270                     Low   \n",
              "2          0.248667             54.564632                Moderate   \n",
              "3          0.513818             79.722963                Moderate   \n",
              "4          0.306864             52.479469                     Low   \n",
              "\n",
              "  Chronic Diseases Medication Use  Cognitive Function Education Level  \\\n",
              "0              NaN            NaN           44.059172             NaN   \n",
              "1     Hypertension            NaN           45.312298   Undergraduate   \n",
              "2     Hypertension        Regular           56.246991             NaN   \n",
              "3         Diabetes     Occasional           55.196092             NaN   \n",
              "4              NaN            NaN           53.023379   Undergraduate   \n",
              "\n",
              "   Age (years)  \n",
              "0           89  \n",
              "1           77  \n",
              "2           70  \n",
              "3           52  \n",
              "4           79  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47d0eec3-718f-482a-936d-adbcbb8c6bdf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Blood Pressure (s/d)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Physical Activity Level</th>\n",
              "      <th>Chronic Diseases</th>\n",
              "      <th>Medication Use</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Age (years)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>151/109</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>134/112</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>Low</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>160/101</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>Regular</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>133/94</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>Occasional</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>170/106</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>Low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47d0eec3-718f-482a-936d-adbcbb8c6bdf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47d0eec3-718f-482a-936d-adbcbb8c6bdf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47d0eec3-718f-482a-936d-adbcbb8c6bdf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94fce161-7aff-49ae-8e83-aba674c09b28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94fce161-7aff-49ae-8e83-aba674c09b28')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94fce161-7aff-49ae-8e83-aba674c09b28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"Height (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.293006149785462,\n        \"min\": 141.13098471818066,\n        \"max\": 198.11221514973244,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          164.52942832880117,\n          160.75189445184782,\n          178.2282294243993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (kg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.190734050609166,\n        \"min\": 32.53767213511866,\n        \"max\": 123.5986030653524,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          43.36567712205252,\n          56.0668676801358,\n          55.50821076079476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Pressure (s/d)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1606,\n        \"samples\": [\n          \"149/85\",\n          \"121/86\",\n          \"132/71\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.52143564344368,\n        \"min\": 148.81151354262943,\n        \"max\": 331.3005889676171,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          268.60254417231374,\n          223.16086477641505,\n          234.87950995030573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.36732238976739,\n        \"min\": 12.049899787257836,\n        \"max\": 43.32986945741556,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          16.019868783773468,\n          21.696720494489508,\n          17.47447928359639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Glucose Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.2261238819685,\n        \"min\": 69.86688423817394,\n        \"max\": 185.73614430684265,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          129.2896450954457,\n          121.75142616843188,\n          102.52447463902472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bone Density (g/cm\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4435496677978386,\n        \"min\": -0.2197872135911742,\n        \"max\": 1.999828884756388,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          0.6808761132989083,\n          0.8260307833788126,\n          0.9084450360516064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vision Sharpness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20972564701184743,\n        \"min\": 0.2,\n        \"max\": 1.062537457634618,\n        \"num_unique_values\": 2561,\n        \"samples\": [\n          0.2854193637729128,\n          0.4576575338765847,\n          0.6683389953426998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hearing Ability (dB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.336463867958974,\n        \"min\": 0.0,\n        \"max\": 94.00382427807536,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          74.43253325428122,\n          36.75657226745562,\n          20.490809352374928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Physical Activity Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moderate\",\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chronic Diseases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Hypertension\",\n          \"Diabetes\",\n          \"Heart Disease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medication Use\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Occasional\",\n          \"Regular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cognitive Function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.755738415840467,\n        \"min\": 30.38209819769691,\n        \"max\": 106.479830780602,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          47.5050940237241,\n          69.96109635102123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Undergraduate\",\n          \"High School\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age (years)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 18,\n        \"max\": 89,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          79,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "clean_df = train_df.drop([\"Gender\",\"Smoking Status\", \"Alcohol Consumption\", \"Diet\", \"Family History\", \"Mental Health Status\", \"Sleep Patterns\", \"Stress Levels\", \"Pollution Exposure\", \"Sun Exposure\", \"Income Level\"], axis='columns')\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c911ab9f",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c911ab9f",
        "outputId": "82ea86c5-562e-4cdc-e58c-c98010da4973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Chronic Diseases', 'Medication Use', 'Education Level']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\n",
        "\n",
        "columns_with_empty_cells = clean_df.columns[clean_df.isna().any()].tolist()\n",
        "columns_with_empty_cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "676cccf0",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "676cccf0",
        "outputId": "c51430b6-e226-427a-dd52-ad38e668c50c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg) Blood Pressure (s/d)  Cholesterol Level (mg/dL)  \\\n",
              "0   171.148359    86.185197              151/109                 259.465814   \n",
              "1   172.946206    79.641937              134/112                 263.630292   \n",
              "2   155.945488    49.167058              160/101                 207.846206   \n",
              "3   169.078298    56.017921               133/94                 253.283779   \n",
              "4   163.758355    73.966304              170/106                 236.119899   \n",
              "\n",
              "         BMI  Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  \\\n",
              "0  29.423017                   157.652848              0.132868   \n",
              "1  26.626847                   118.507805              0.629534   \n",
              "2  20.217553                   143.587550              0.473487   \n",
              "3  19.595270                   137.448581              1.184315   \n",
              "4  27.582078                   145.328695              0.434562   \n",
              "\n",
              "   Vision Sharpness  Hearing Ability (dB) Physical Activity Level  \\\n",
              "0          0.200000             58.786198                Moderate   \n",
              "1          0.267312             54.635270                     Low   \n",
              "2          0.248667             54.564632                Moderate   \n",
              "3          0.513818             79.722963                Moderate   \n",
              "4          0.306864             52.479469                     Low   \n",
              "\n",
              "  Chronic Diseases Medication Use  Cognitive Function Education Level  \\\n",
              "0            None1          None2           44.059172           None3   \n",
              "1     Hypertension          None2           45.312298   Undergraduate   \n",
              "2     Hypertension        Regular           56.246991           None3   \n",
              "3         Diabetes     Occasional           55.196092           None3   \n",
              "4            None1          None2           53.023379   Undergraduate   \n",
              "\n",
              "   Age (years)  \n",
              "0           89  \n",
              "1           77  \n",
              "2           70  \n",
              "3           52  \n",
              "4           79  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c275fbf-d2ba-4459-95b1-38e38266043f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Blood Pressure (s/d)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Physical Activity Level</th>\n",
              "      <th>Chronic Diseases</th>\n",
              "      <th>Medication Use</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Age (years)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>151/109</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>None3</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>134/112</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>Low</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>None2</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>160/101</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>Regular</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>None3</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>133/94</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>Occasional</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>None3</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>170/106</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>Low</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c275fbf-d2ba-4459-95b1-38e38266043f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c275fbf-d2ba-4459-95b1-38e38266043f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c275fbf-d2ba-4459-95b1-38e38266043f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-460547e6-66f5-4900-817e-965c69e87886\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-460547e6-66f5-4900-817e-965c69e87886')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-460547e6-66f5-4900-817e-965c69e87886 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"Height (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.293006149785462,\n        \"min\": 141.13098471818066,\n        \"max\": 198.11221514973244,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          164.52942832880117,\n          160.75189445184782,\n          178.2282294243993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (kg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.190734050609166,\n        \"min\": 32.53767213511866,\n        \"max\": 123.5986030653524,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          43.36567712205252,\n          56.0668676801358,\n          55.50821076079476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Pressure (s/d)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1606,\n        \"samples\": [\n          \"149/85\",\n          \"121/86\",\n          \"132/71\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.52143564344368,\n        \"min\": 148.81151354262943,\n        \"max\": 331.3005889676171,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          268.60254417231374,\n          223.16086477641505,\n          234.87950995030573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.36732238976739,\n        \"min\": 12.049899787257836,\n        \"max\": 43.32986945741556,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          16.019868783773468,\n          21.696720494489508,\n          17.47447928359639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Glucose Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.2261238819685,\n        \"min\": 69.86688423817394,\n        \"max\": 185.73614430684265,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          129.2896450954457,\n          121.75142616843188,\n          102.52447463902472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bone Density (g/cm\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4435496677978386,\n        \"min\": -0.2197872135911742,\n        \"max\": 1.999828884756388,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          0.6808761132989083,\n          0.8260307833788126,\n          0.9084450360516064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vision Sharpness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20972564701184743,\n        \"min\": 0.2,\n        \"max\": 1.062537457634618,\n        \"num_unique_values\": 2561,\n        \"samples\": [\n          0.2854193637729128,\n          0.4576575338765847,\n          0.6683389953426998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hearing Ability (dB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.336463867958974,\n        \"min\": 0.0,\n        \"max\": 94.00382427807536,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          74.43253325428122,\n          36.75657226745562,\n          20.490809352374928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Physical Activity Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moderate\",\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chronic Diseases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hypertension\",\n          \"Heart Disease\",\n          \"None1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medication Use\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None2\",\n          \"Regular\",\n          \"Occasional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cognitive Function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.755738415840467,\n        \"min\": 30.38209819769691,\n        \"max\": 106.479830780602,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          47.5050940237241,\n          69.96109635102123,\n          61.971876323110735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Undergraduate\",\n          \"Postgraduate\",\n          \"None3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age (years)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 18,\n        \"max\": 89,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          79,\n          51,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "\n",
        "\n",
        "i=1\n",
        "for col in columns_with_empty_cells:\n",
        "    clean_df[col] = clean_df[col].fillna(f\"None{i}\")\n",
        "    i+=1\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ce863338",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "ce863338",
        "outputId": "980e46d5-9f2a-4630-c0bf-31e4e3bc9627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg) Blood Pressure (s/d)  Cholesterol Level (mg/dL)  \\\n",
              "0   171.148359    86.185197              151/109                 259.465814   \n",
              "1   172.946206    79.641937              134/112                 263.630292   \n",
              "2   155.945488    49.167058              160/101                 207.846206   \n",
              "3   169.078298    56.017921               133/94                 253.283779   \n",
              "4   163.758355    73.966304              170/106                 236.119899   \n",
              "\n",
              "         BMI  Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  \\\n",
              "0  29.423017                   157.652848              0.132868   \n",
              "1  26.626847                   118.507805              0.629534   \n",
              "2  20.217553                   143.587550              0.473487   \n",
              "3  19.595270                   137.448581              1.184315   \n",
              "4  27.582078                   145.328695              0.434562   \n",
              "\n",
              "   Vision Sharpness  Hearing Ability (dB) Physical Activity Level  \\\n",
              "0          0.200000             58.786198                Moderate   \n",
              "1          0.267312             54.635270                     Low   \n",
              "2          0.248667             54.564632                Moderate   \n",
              "3          0.513818             79.722963                Moderate   \n",
              "4          0.306864             52.479469                     Low   \n",
              "\n",
              "  Chronic Diseases Medication Use  Cognitive Function Education Level  \\\n",
              "0            None1          None2           44.059172           None3   \n",
              "1     Hypertension          None2           45.312298   Undergraduate   \n",
              "2     Hypertension        Regular           56.246991           None3   \n",
              "3         Diabetes     Occasional           55.196092           None3   \n",
              "4            None1          None2           53.023379   Undergraduate   \n",
              "\n",
              "   Age (years) Systolic Blood Pressure Diastolic Blood Pressure  \n",
              "0           89                     151                      109  \n",
              "1           77                     134                      112  \n",
              "2           70                     160                      101  \n",
              "3           52                     133                       94  \n",
              "4           79                     170                      106  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4ed7d12-36c6-4fcc-9fe2-2aa0f9aaf686\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Blood Pressure (s/d)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Physical Activity Level</th>\n",
              "      <th>Chronic Diseases</th>\n",
              "      <th>Medication Use</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Age (years)</th>\n",
              "      <th>Systolic Blood Pressure</th>\n",
              "      <th>Diastolic Blood Pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>151/109</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>None3</td>\n",
              "      <td>89</td>\n",
              "      <td>151</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>134/112</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>Low</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>None2</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>77</td>\n",
              "      <td>134</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>160/101</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>Regular</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>None3</td>\n",
              "      <td>70</td>\n",
              "      <td>160</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>133/94</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>Occasional</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>None3</td>\n",
              "      <td>52</td>\n",
              "      <td>133</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>170/106</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>Low</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>79</td>\n",
              "      <td>170</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4ed7d12-36c6-4fcc-9fe2-2aa0f9aaf686')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4ed7d12-36c6-4fcc-9fe2-2aa0f9aaf686 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4ed7d12-36c6-4fcc-9fe2-2aa0f9aaf686');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-04a54ab4-3767-49e3-a501-69b72f726c51\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04a54ab4-3767-49e3-a501-69b72f726c51')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-04a54ab4-3767-49e3-a501-69b72f726c51 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"Height (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.293006149785462,\n        \"min\": 141.13098471818066,\n        \"max\": 198.11221514973244,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          164.52942832880117,\n          160.75189445184782,\n          178.2282294243993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (kg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.190734050609166,\n        \"min\": 32.53767213511866,\n        \"max\": 123.5986030653524,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          43.36567712205252,\n          56.0668676801358,\n          55.50821076079476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Pressure (s/d)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1606,\n        \"samples\": [\n          \"149/85\",\n          \"121/86\",\n          \"132/71\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.52143564344368,\n        \"min\": 148.81151354262943,\n        \"max\": 331.3005889676171,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          268.60254417231374,\n          223.16086477641505,\n          234.87950995030573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.36732238976739,\n        \"min\": 12.049899787257836,\n        \"max\": 43.32986945741556,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          16.019868783773468,\n          21.696720494489508,\n          17.47447928359639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Glucose Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.2261238819685,\n        \"min\": 69.86688423817394,\n        \"max\": 185.73614430684265,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          129.2896450954457,\n          121.75142616843188,\n          102.52447463902472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bone Density (g/cm\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4435496677978386,\n        \"min\": -0.2197872135911742,\n        \"max\": 1.999828884756388,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          0.6808761132989083,\n          0.8260307833788126,\n          0.9084450360516064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vision Sharpness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20972564701184743,\n        \"min\": 0.2,\n        \"max\": 1.062537457634618,\n        \"num_unique_values\": 2561,\n        \"samples\": [\n          0.2854193637729128,\n          0.4576575338765847,\n          0.6683389953426998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hearing Ability (dB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.336463867958974,\n        \"min\": 0.0,\n        \"max\": 94.00382427807536,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          74.43253325428122,\n          36.75657226745562,\n          20.490809352374928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Physical Activity Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moderate\",\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chronic Diseases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hypertension\",\n          \"Heart Disease\",\n          \"None1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medication Use\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None2\",\n          \"Regular\",\n          \"Occasional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cognitive Function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.755738415840467,\n        \"min\": 30.38209819769691,\n        \"max\": 106.479830780602,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          47.5050940237241,\n          69.96109635102123,\n          61.971876323110735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Undergraduate\",\n          \"Postgraduate\",\n          \"None3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age (years)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 18,\n        \"max\": 89,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          79,\n          51,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Systolic Blood Pressure\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"135\",\n          \"131\",\n          \"124\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diastolic Blood Pressure\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"109\",\n          \"75\",\n          \"77\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "\n",
        "clean_df[['Systolic Blood Pressure', 'Diastolic Blood Pressure']] = clean_df[\"Blood Pressure (s/d)\"].str.split('/', expand=True)\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f8512866",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "f8512866",
        "outputId": "756a7e9a-86c4-4675-8b14-52e7a6eb47b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
              "0   171.148359    86.185197                 259.465814  29.423017   \n",
              "1   172.946206    79.641937                 263.630292  26.626847   \n",
              "2   155.945488    49.167058                 207.846206  20.217553   \n",
              "3   169.078298    56.017921                 253.283779  19.595270   \n",
              "4   163.758355    73.966304                 236.119899  27.582078   \n",
              "\n",
              "   Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
              "0                   157.652848              0.132868          0.200000   \n",
              "1                   118.507805              0.629534          0.267312   \n",
              "2                   143.587550              0.473487          0.248667   \n",
              "3                   137.448581              1.184315          0.513818   \n",
              "4                   145.328695              0.434562          0.306864   \n",
              "\n",
              "   Hearing Ability (dB) Physical Activity Level Chronic Diseases  \\\n",
              "0             58.786198                Moderate            None1   \n",
              "1             54.635270                     Low     Hypertension   \n",
              "2             54.564632                Moderate     Hypertension   \n",
              "3             79.722963                Moderate         Diabetes   \n",
              "4             52.479469                     Low            None1   \n",
              "\n",
              "  Medication Use  Cognitive Function Education Level  Age (years)  \\\n",
              "0          None2           44.059172           None3           89   \n",
              "1          None2           45.312298   Undergraduate           77   \n",
              "2        Regular           56.246991           None3           70   \n",
              "3     Occasional           55.196092           None3           52   \n",
              "4          None2           53.023379   Undergraduate           79   \n",
              "\n",
              "   Systolic Blood Pressure  Diastolic Blood Pressure  \n",
              "0                      151                       109  \n",
              "1                      134                       112  \n",
              "2                      160                       101  \n",
              "3                      133                        94  \n",
              "4                      170                       106  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-518ce5a0-d6e0-43cc-bc60-7d95227131d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Physical Activity Level</th>\n",
              "      <th>Chronic Diseases</th>\n",
              "      <th>Medication Use</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Education Level</th>\n",
              "      <th>Age (years)</th>\n",
              "      <th>Systolic Blood Pressure</th>\n",
              "      <th>Diastolic Blood Pressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>None3</td>\n",
              "      <td>89</td>\n",
              "      <td>151</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>Low</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>None2</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>77</td>\n",
              "      <td>134</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Hypertension</td>\n",
              "      <td>Regular</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>None3</td>\n",
              "      <td>70</td>\n",
              "      <td>160</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>Occasional</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>None3</td>\n",
              "      <td>52</td>\n",
              "      <td>133</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>Low</td>\n",
              "      <td>None1</td>\n",
              "      <td>None2</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>79</td>\n",
              "      <td>170</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-518ce5a0-d6e0-43cc-bc60-7d95227131d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-518ce5a0-d6e0-43cc-bc60-7d95227131d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-518ce5a0-d6e0-43cc-bc60-7d95227131d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1bcc93d-4306-416f-b00a-933fa8b8e596\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1bcc93d-4306-416f-b00a-933fa8b8e596')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1bcc93d-4306-416f-b00a-933fa8b8e596 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"Height (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.293006149785462,\n        \"min\": 141.13098471818066,\n        \"max\": 198.11221514973244,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          164.52942832880117,\n          160.75189445184782,\n          178.2282294243993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (kg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.190734050609166,\n        \"min\": 32.53767213511866,\n        \"max\": 123.5986030653524,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          43.36567712205252,\n          56.0668676801358,\n          55.50821076079476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.52143564344368,\n        \"min\": 148.81151354262943,\n        \"max\": 331.3005889676171,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          268.60254417231374,\n          223.16086477641505,\n          234.87950995030573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.36732238976739,\n        \"min\": 12.049899787257836,\n        \"max\": 43.32986945741556,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          16.019868783773468,\n          21.696720494489508,\n          17.47447928359639\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blood Glucose Level (mg/dL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.2261238819685,\n        \"min\": 69.86688423817394,\n        \"max\": 185.73614430684265,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          129.2896450954457,\n          121.75142616843188,\n          102.52447463902472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bone Density (g/cm\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4435496677978386,\n        \"min\": -0.2197872135911742,\n        \"max\": 1.999828884756388,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          0.6808761132989083,\n          0.8260307833788126,\n          0.9084450360516064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vision Sharpness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20972564701184743,\n        \"min\": 0.2,\n        \"max\": 1.062537457634618,\n        \"num_unique_values\": 2561,\n        \"samples\": [\n          0.2854193637729128,\n          0.4576575338765847,\n          0.6683389953426998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hearing Ability (dB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.336463867958974,\n        \"min\": 0.0,\n        \"max\": 94.00382427807536,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          74.43253325428122,\n          36.75657226745562,\n          20.490809352374928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Physical Activity Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moderate\",\n          \"Low\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chronic Diseases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hypertension\",\n          \"Heart Disease\",\n          \"None1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medication Use\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"None2\",\n          \"Regular\",\n          \"Occasional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cognitive Function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.755738415840467,\n        \"min\": 30.38209819769691,\n        \"max\": 106.479830780602,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          47.5050940237241,\n          69.96109635102123,\n          61.971876323110735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Undergraduate\",\n          \"Postgraduate\",\n          \"None3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age (years)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 18,\n        \"max\": 89,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          79,\n          51,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Systolic Blood Pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 97,\n        \"max\": 193,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          135,\n          131,\n          124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diastolic Blood Pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 60,\n        \"max\": 133,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          109,\n          75,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "\n",
        "\n",
        "clean_df['Systolic Blood Pressure'] = clean_df['Systolic Blood Pressure'].astype(int)\n",
        "clean_df['Diastolic Blood Pressure'] = clean_df['Diastolic Blood Pressure'].astype(int)\n",
        "clean_df.pop(\"Blood Pressure (s/d)\")\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1deff953",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "1deff953",
        "outputId": "7d6e9747-a4b2-48bb-c180-b73cf071fc98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
              "0   171.148359    86.185197                 259.465814  29.423017   \n",
              "1   172.946206    79.641937                 263.630292  26.626847   \n",
              "2   155.945488    49.167058                 207.846206  20.217553   \n",
              "3   169.078298    56.017921                 253.283779  19.595270   \n",
              "4   163.758355    73.966304                 236.119899  27.582078   \n",
              "\n",
              "   Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
              "0                   157.652848              0.132868          0.200000   \n",
              "1                   118.507805              0.629534          0.267312   \n",
              "2                   143.587550              0.473487          0.248667   \n",
              "3                   137.448581              1.184315          0.513818   \n",
              "4                   145.328695              0.434562          0.306864   \n",
              "\n",
              "   Hearing Ability (dB)  Cognitive Function  Age (years)  ...  \\\n",
              "0             58.786198           44.059172           89  ...   \n",
              "1             54.635270           45.312298           77  ...   \n",
              "2             54.564632           56.246991           70  ...   \n",
              "3             79.722963           55.196092           52  ...   \n",
              "4             52.479469           53.023379           79  ...   \n",
              "\n",
              "   Medication Use_None2  Medication Use_Occasional  Medication Use_Regular  \\\n",
              "0                  True                      False                   False   \n",
              "1                  True                      False                   False   \n",
              "2                 False                      False                    True   \n",
              "3                 False                       True                   False   \n",
              "4                  True                      False                   False   \n",
              "\n",
              "   Education Level_High School  Education Level_None3  \\\n",
              "0                        False                   True   \n",
              "1                        False                  False   \n",
              "2                        False                   True   \n",
              "3                        False                   True   \n",
              "4                        False                  False   \n",
              "\n",
              "   Education Level_Postgraduate  Education Level_Undergraduate  \\\n",
              "0                         False                          False   \n",
              "1                         False                           True   \n",
              "2                         False                          False   \n",
              "3                         False                          False   \n",
              "4                         False                           True   \n",
              "\n",
              "   Physical Activity Level_High  Physical Activity Level_Low  \\\n",
              "0                         False                        False   \n",
              "1                         False                         True   \n",
              "2                         False                        False   \n",
              "3                         False                        False   \n",
              "4                         False                         True   \n",
              "\n",
              "   Physical Activity Level_Moderate  \n",
              "0                              True  \n",
              "1                             False  \n",
              "2                              True  \n",
              "3                              True  \n",
              "4                             False  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b97ddee-0ce3-4c93-9e3f-76a675852570\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Age (years)</th>\n",
              "      <th>...</th>\n",
              "      <th>Medication Use_None2</th>\n",
              "      <th>Medication Use_Occasional</th>\n",
              "      <th>Medication Use_Regular</th>\n",
              "      <th>Education Level_High School</th>\n",
              "      <th>Education Level_None3</th>\n",
              "      <th>Education Level_Postgraduate</th>\n",
              "      <th>Education Level_Undergraduate</th>\n",
              "      <th>Physical Activity Level_High</th>\n",
              "      <th>Physical Activity Level_Low</th>\n",
              "      <th>Physical Activity Level_Moderate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>77</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>79</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b97ddee-0ce3-4c93-9e3f-76a675852570')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b97ddee-0ce3-4c93-9e3f-76a675852570 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b97ddee-0ce3-4c93-9e3f-76a675852570');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ac65b51-aeb3-471c-848c-258f6c4f10f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ac65b51-aeb3-471c-848c-258f6c4f10f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ac65b51-aeb3-471c-848c-258f6c4f10f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "categorical_columns = [\"Chronic Diseases\", \"Medication Use\", \"Education Level\", \"Physical Activity Level\"]\n",
        "\n",
        "# Use pandas get_dummies function to one-hot encode the categorical variables\n",
        "clean_df = pd.get_dummies(clean_df, columns=categorical_columns)\n",
        "\n",
        "# Display the transformed dataframe\n",
        "clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2bef46c0",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "2bef46c0",
        "outputId": "e213fe51-6ea5-4526-df33-4a5bd7296cf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
              "0   171.148359    86.185197                 259.465814  29.423017   \n",
              "1   172.946206    79.641937                 263.630292  26.626847   \n",
              "2   155.945488    49.167058                 207.846206  20.217553   \n",
              "3   169.078298    56.017921                 253.283779  19.595270   \n",
              "4   163.758355    73.966304                 236.119899  27.582078   \n",
              "\n",
              "   Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
              "0                   157.652848              0.132868          0.200000   \n",
              "1                   118.507805              0.629534          0.267312   \n",
              "2                   143.587550              0.473487          0.248667   \n",
              "3                   137.448581              1.184315          0.513818   \n",
              "4                   145.328695              0.434562          0.306864   \n",
              "\n",
              "   Hearing Ability (dB)  Cognitive Function  Systolic Blood Pressure  ...  \\\n",
              "0             58.786198           44.059172                      151  ...   \n",
              "1             54.635270           45.312298                      134  ...   \n",
              "2             54.564632           56.246991                      160  ...   \n",
              "3             79.722963           55.196092                      133  ...   \n",
              "4             52.479469           53.023379                      170  ...   \n",
              "\n",
              "   Medication Use_None2  Medication Use_Occasional  Medication Use_Regular  \\\n",
              "0                  True                      False                   False   \n",
              "1                  True                      False                   False   \n",
              "2                 False                      False                    True   \n",
              "3                 False                       True                   False   \n",
              "4                  True                      False                   False   \n",
              "\n",
              "   Education Level_High School  Education Level_None3  \\\n",
              "0                        False                   True   \n",
              "1                        False                  False   \n",
              "2                        False                   True   \n",
              "3                        False                   True   \n",
              "4                        False                  False   \n",
              "\n",
              "   Education Level_Postgraduate  Education Level_Undergraduate  \\\n",
              "0                         False                          False   \n",
              "1                         False                           True   \n",
              "2                         False                          False   \n",
              "3                         False                          False   \n",
              "4                         False                           True   \n",
              "\n",
              "   Physical Activity Level_High  Physical Activity Level_Low  \\\n",
              "0                         False                        False   \n",
              "1                         False                         True   \n",
              "2                         False                        False   \n",
              "3                         False                        False   \n",
              "4                         False                         True   \n",
              "\n",
              "   Physical Activity Level_Moderate  \n",
              "0                              True  \n",
              "1                             False  \n",
              "2                              True  \n",
              "3                              True  \n",
              "4                             False  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-745a5065-1a52-4f1c-831e-627d3bdd1511\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Weight (kg)</th>\n",
              "      <th>Cholesterol Level (mg/dL)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Glucose Level (mg/dL)</th>\n",
              "      <th>Bone Density (g/cm²)</th>\n",
              "      <th>Vision Sharpness</th>\n",
              "      <th>Hearing Ability (dB)</th>\n",
              "      <th>Cognitive Function</th>\n",
              "      <th>Systolic Blood Pressure</th>\n",
              "      <th>...</th>\n",
              "      <th>Medication Use_None2</th>\n",
              "      <th>Medication Use_Occasional</th>\n",
              "      <th>Medication Use_Regular</th>\n",
              "      <th>Education Level_High School</th>\n",
              "      <th>Education Level_None3</th>\n",
              "      <th>Education Level_Postgraduate</th>\n",
              "      <th>Education Level_Undergraduate</th>\n",
              "      <th>Physical Activity Level_High</th>\n",
              "      <th>Physical Activity Level_Low</th>\n",
              "      <th>Physical Activity Level_Moderate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.148359</td>\n",
              "      <td>86.185197</td>\n",
              "      <td>259.465814</td>\n",
              "      <td>29.423017</td>\n",
              "      <td>157.652848</td>\n",
              "      <td>0.132868</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>58.786198</td>\n",
              "      <td>44.059172</td>\n",
              "      <td>151</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172.946206</td>\n",
              "      <td>79.641937</td>\n",
              "      <td>263.630292</td>\n",
              "      <td>26.626847</td>\n",
              "      <td>118.507805</td>\n",
              "      <td>0.629534</td>\n",
              "      <td>0.267312</td>\n",
              "      <td>54.635270</td>\n",
              "      <td>45.312298</td>\n",
              "      <td>134</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.945488</td>\n",
              "      <td>49.167058</td>\n",
              "      <td>207.846206</td>\n",
              "      <td>20.217553</td>\n",
              "      <td>143.587550</td>\n",
              "      <td>0.473487</td>\n",
              "      <td>0.248667</td>\n",
              "      <td>54.564632</td>\n",
              "      <td>56.246991</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169.078298</td>\n",
              "      <td>56.017921</td>\n",
              "      <td>253.283779</td>\n",
              "      <td>19.595270</td>\n",
              "      <td>137.448581</td>\n",
              "      <td>1.184315</td>\n",
              "      <td>0.513818</td>\n",
              "      <td>79.722963</td>\n",
              "      <td>55.196092</td>\n",
              "      <td>133</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>163.758355</td>\n",
              "      <td>73.966304</td>\n",
              "      <td>236.119899</td>\n",
              "      <td>27.582078</td>\n",
              "      <td>145.328695</td>\n",
              "      <td>0.434562</td>\n",
              "      <td>0.306864</td>\n",
              "      <td>52.479469</td>\n",
              "      <td>53.023379</td>\n",
              "      <td>170</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-745a5065-1a52-4f1c-831e-627d3bdd1511')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-745a5065-1a52-4f1c-831e-627d3bdd1511 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-745a5065-1a52-4f1c-831e-627d3bdd1511');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c70a0d5a-58e3-4679-b562-8449aff0894e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c70a0d5a-58e3-4679-b562-8449aff0894e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c70a0d5a-58e3-4679-b562-8449aff0894e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "xtrain"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "\n",
        "\n",
        "xtrain = clean_df.drop(\"Age (years)\", axis=\"columns\")\n",
        "xtrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5c99c378",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "5c99c378",
        "outputId": "55bb6336-e345-4700-9daf-a8179781a5a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    89\n",
              "1    77\n",
              "2    70\n",
              "3    52\n",
              "4    79\n",
              "Name: Age (years), dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age (years)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "\n",
        "\n",
        "yTrain = clean_df[\"Age (years)\"]\n",
        "yTrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b5856f46",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "b5856f46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from torch import nn, Tensor, optim\n",
        "xTrainNumpy = xtrain.to_numpy()\n",
        "yTrainNumpy = yTrain.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "1fbc54c1",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fbc54c1",
        "outputId": "bd5721da-cb73-40e2-c2e6-c8919f16ff75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "\n",
        "xTrainNumpy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "539e7dd5",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "539e7dd5",
        "outputId": "3e4f4251-cdf5-4b19-f181-5f6ce31d2e7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "\n",
        "\n",
        "yTrainNumpy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "18d88618",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "18d88618"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "class AgePredictionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AgePredictionNN, self).__init__()\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(25, 64)\n",
        "        self.ln1 = nn.LayerNorm(64)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc2 = nn.Linear(64, 16)\n",
        "        self.ln2 = nn.LayerNorm(16)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Kaiming initialization for layers with GELU\n",
        "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        # Xavier initialization for output layer\n",
        "        nn.init.xavier_normal_(self.fc3.weight)\n",
        "\n",
        "        # Initialize biases to small values\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "        nn.init.zeros_(self.fc3.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First layer with LayerNorm and Dropout\n",
        "        identity = x  # For potential skip connection in future layers\n",
        "\n",
        "        outHiddenLayer1 = self.fc1(x)\n",
        "        outHiddenLayer1 = self.ln1(outHiddenLayer1)\n",
        "        # Using GELU as a more modern activation function\n",
        "        activate1 = F.gelu(outHiddenLayer1)\n",
        "        activate1 = self.dropout1(activate1)\n",
        "\n",
        "        # Second layer with LayerNorm, Dropout and skip connection\n",
        "        outHiddenLayer2 = self.fc2(activate1)\n",
        "        outHiddenLayer2 = self.ln2(outHiddenLayer2)\n",
        "        activate2 = F.gelu(outHiddenLayer2)\n",
        "        activate2 = self.dropout2(activate2)\n",
        "\n",
        "        # Skip connection isn't directly applicable here due to dimension mismatch\n",
        "        # but we could project identity if needed\n",
        "\n",
        "        # Output layer\n",
        "        outHiddenLayer3 = self.fc3(activate2)\n",
        "        return outHiddenLayer3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a1708519",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "a1708519"
      },
      "outputs": [],
      "source": [
        "# change device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AgePredictionNN().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "99f7456c",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99f7456c",
        "outputId": "fe97c507-207b-4b6d-e13d-50bd6b833bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[171.1484,  86.1852, 259.4658,  ...,   0.0000,   0.0000,   1.0000],\n",
            "        [172.9462,  79.6419, 263.6303,  ...,   0.0000,   1.0000,   0.0000],\n",
            "        [155.9455,  49.1671, 207.8462,  ...,   0.0000,   0.0000,   1.0000],\n",
            "        ...,\n",
            "        [177.8577,  86.2589, 238.6415,  ...,   0.0000,   0.0000,   1.0000],\n",
            "        [162.2872,  41.3710, 198.2443,  ...,   0.0000,   0.0000,   1.0000],\n",
            "        [175.3417,  78.7180, 279.1182,  ...,   1.0000,   0.0000,   0.0000]])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "xTrainNumpy = np.array(xTrainNumpy, dtype=np.float32)\n",
        "xTrainNumpy[xTrainNumpy == True] = 1\n",
        "xTrainNumpy[xTrainNumpy == False] = 0\n",
        "\n",
        "xTrainTensor = torch.tensor(xTrainNumpy, dtype=torch.float32)\n",
        "yTrainTensor = torch.tensor(yTrainNumpy, dtype=torch.float32)\n",
        "\n",
        "print(xTrainTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d945eb77",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d945eb77",
        "outputId": "197637b8-3acd-4937-96ae-d69ef84c6111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of xTrainTensor: torch.Size([3000, 25])\n",
            "Shape of yTrainTensor: torch.Size([3000])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of xTrainTensor:\", xTrainTensor.shape)\n",
        "print(\"Shape of yTrainTensor:\", yTrainTensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4567c505",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4567c505",
        "outputId": "0b4d2be0-8817-4eda-f61f-4aadc5e974ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [5001/10000], Loss: 494.1620\n",
            "Epoch [5002/10000], Loss: 501.8937\n",
            "Epoch [5003/10000], Loss: 502.3541\n",
            "Epoch [5004/10000], Loss: 507.4970\n",
            "Epoch [5005/10000], Loss: 506.7163\n",
            "Epoch [5006/10000], Loss: 509.0202\n",
            "Epoch [5007/10000], Loss: 504.8919\n",
            "Epoch [5008/10000], Loss: 508.4955\n",
            "Epoch [5009/10000], Loss: 504.8350\n",
            "Epoch [5010/10000], Loss: 514.5621\n",
            "Epoch [5011/10000], Loss: 509.7013\n",
            "Epoch [5012/10000], Loss: 499.6158\n",
            "Epoch [5013/10000], Loss: 500.9186\n",
            "Epoch [5014/10000], Loss: 500.2177\n",
            "Epoch [5015/10000], Loss: 502.2192\n",
            "Epoch [5016/10000], Loss: 504.0491\n",
            "Epoch [5017/10000], Loss: 497.2339\n",
            "Epoch [5018/10000], Loss: 497.6298\n",
            "Epoch [5019/10000], Loss: 507.0522\n",
            "Epoch [5020/10000], Loss: 501.9834\n",
            "Epoch [5021/10000], Loss: 499.0476\n",
            "Epoch [5022/10000], Loss: 494.0682\n",
            "Epoch [5023/10000], Loss: 497.9457\n",
            "Epoch [5024/10000], Loss: 494.4751\n",
            "Epoch [5025/10000], Loss: 500.2710\n",
            "Epoch [5026/10000], Loss: 501.0488\n",
            "Epoch [5027/10000], Loss: 488.8400\n",
            "Epoch [5028/10000], Loss: 493.9757\n",
            "Epoch [5029/10000], Loss: 492.0515\n",
            "Epoch [5030/10000], Loss: 489.8285\n",
            "Epoch [5031/10000], Loss: 490.7843\n",
            "Epoch [5032/10000], Loss: 501.4113\n",
            "Epoch [5033/10000], Loss: 491.7415\n",
            "Epoch [5034/10000], Loss: 485.7458\n",
            "Epoch [5035/10000], Loss: 499.4042\n",
            "Epoch [5036/10000], Loss: 489.5360\n",
            "Epoch [5037/10000], Loss: 484.2091\n",
            "Epoch [5038/10000], Loss: 490.1419\n",
            "Epoch [5039/10000], Loss: 486.8765\n",
            "Epoch [5040/10000], Loss: 508.5842\n",
            "Epoch [5041/10000], Loss: 488.2019\n",
            "Epoch [5042/10000], Loss: 491.1068\n",
            "Epoch [5043/10000], Loss: 483.7748\n",
            "Epoch [5044/10000], Loss: 485.0579\n",
            "Epoch [5045/10000], Loss: 487.7032\n",
            "Epoch [5046/10000], Loss: 479.1721\n",
            "Epoch [5047/10000], Loss: 488.7728\n",
            "Epoch [5048/10000], Loss: 481.3642\n",
            "Epoch [5049/10000], Loss: 483.9631\n",
            "Epoch [5050/10000], Loss: 484.7930\n",
            "Epoch [5051/10000], Loss: 477.2148\n",
            "Epoch [5052/10000], Loss: 478.7751\n",
            "Epoch [5053/10000], Loss: 485.4081\n",
            "Epoch [5054/10000], Loss: 474.3118\n",
            "Epoch [5055/10000], Loss: 486.1201\n",
            "Epoch [5056/10000], Loss: 478.1821\n",
            "Epoch [5057/10000], Loss: 482.0338\n",
            "Epoch [5058/10000], Loss: 472.1873\n",
            "Epoch [5059/10000], Loss: 472.7340\n",
            "Epoch [5060/10000], Loss: 479.4951\n",
            "Epoch [5061/10000], Loss: 468.2912\n",
            "Epoch [5062/10000], Loss: 469.0254\n",
            "Epoch [5063/10000], Loss: 469.2305\n",
            "Epoch [5064/10000], Loss: 464.0666\n",
            "Epoch [5065/10000], Loss: 470.8545\n",
            "Epoch [5066/10000], Loss: 473.6582\n",
            "Epoch [5067/10000], Loss: 458.0950\n",
            "Epoch [5068/10000], Loss: 458.8310\n",
            "Epoch [5069/10000], Loss: 470.0453\n",
            "Epoch [5070/10000], Loss: 468.4909\n",
            "Epoch [5071/10000], Loss: 470.3273\n",
            "Epoch [5072/10000], Loss: 457.3744\n",
            "Epoch [5073/10000], Loss: 460.2320\n",
            "Epoch [5074/10000], Loss: 460.6949\n",
            "Epoch [5075/10000], Loss: 463.0891\n",
            "Epoch [5076/10000], Loss: 467.1658\n",
            "Epoch [5077/10000], Loss: 454.3223\n",
            "Epoch [5078/10000], Loss: 449.4348\n",
            "Epoch [5079/10000], Loss: 451.1201\n",
            "Epoch [5080/10000], Loss: 454.4294\n",
            "Epoch [5081/10000], Loss: 438.5719\n",
            "Epoch [5082/10000], Loss: 449.7571\n",
            "Epoch [5083/10000], Loss: 463.1800\n",
            "Epoch [5084/10000], Loss: 456.4608\n",
            "Epoch [5085/10000], Loss: 449.8281\n",
            "Epoch [5086/10000], Loss: 455.8087\n",
            "Epoch [5087/10000], Loss: 450.1605\n",
            "Epoch [5088/10000], Loss: 445.0430\n",
            "Epoch [5089/10000], Loss: 445.1347\n",
            "Epoch [5090/10000], Loss: 453.1321\n",
            "Epoch [5091/10000], Loss: 447.2762\n",
            "Epoch [5092/10000], Loss: 445.2897\n",
            "Epoch [5093/10000], Loss: 450.9377\n",
            "Epoch [5094/10000], Loss: 441.4353\n",
            "Epoch [5095/10000], Loss: 444.4631\n",
            "Epoch [5096/10000], Loss: 449.0652\n",
            "Epoch [5097/10000], Loss: 444.9519\n",
            "Epoch [5098/10000], Loss: 438.3466\n",
            "Epoch [5099/10000], Loss: 439.1910\n",
            "Epoch [5100/10000], Loss: 443.0717\n",
            "Epoch [5101/10000], Loss: 436.7155\n",
            "Epoch [5102/10000], Loss: 434.3584\n",
            "Epoch [5103/10000], Loss: 432.2917\n",
            "Epoch [5104/10000], Loss: 434.4147\n",
            "Epoch [5105/10000], Loss: 432.7602\n",
            "Epoch [5106/10000], Loss: 437.2652\n",
            "Epoch [5107/10000], Loss: 439.2108\n",
            "Epoch [5108/10000], Loss: 426.5197\n",
            "Epoch [5109/10000], Loss: 429.7589\n",
            "Epoch [5110/10000], Loss: 435.0198\n",
            "Epoch [5111/10000], Loss: 433.1113\n",
            "Epoch [5112/10000], Loss: 434.9221\n",
            "Epoch [5113/10000], Loss: 427.1599\n",
            "Epoch [5114/10000], Loss: 428.9034\n",
            "Epoch [5115/10000], Loss: 424.7043\n",
            "Epoch [5116/10000], Loss: 429.4868\n",
            "Epoch [5117/10000], Loss: 429.5640\n",
            "Epoch [5118/10000], Loss: 422.2823\n",
            "Epoch [5119/10000], Loss: 428.0660\n",
            "Epoch [5120/10000], Loss: 426.2383\n",
            "Epoch [5121/10000], Loss: 430.3297\n",
            "Epoch [5122/10000], Loss: 416.5868\n",
            "Epoch [5123/10000], Loss: 428.1907\n",
            "Epoch [5124/10000], Loss: 427.2182\n",
            "Epoch [5125/10000], Loss: 431.3868\n",
            "Epoch [5126/10000], Loss: 426.0432\n",
            "Epoch [5127/10000], Loss: 415.0289\n",
            "Epoch [5128/10000], Loss: 414.8913\n",
            "Epoch [5129/10000], Loss: 425.5686\n",
            "Epoch [5130/10000], Loss: 423.2600\n",
            "Epoch [5131/10000], Loss: 425.9886\n",
            "Epoch [5132/10000], Loss: 417.3185\n",
            "Epoch [5133/10000], Loss: 426.6932\n",
            "Epoch [5134/10000], Loss: 421.1282\n",
            "Epoch [5135/10000], Loss: 423.6536\n",
            "Epoch [5136/10000], Loss: 411.1456\n",
            "Epoch [5137/10000], Loss: 418.0960\n",
            "Epoch [5138/10000], Loss: 414.8108\n",
            "Epoch [5139/10000], Loss: 425.5531\n",
            "Epoch [5140/10000], Loss: 418.8017\n",
            "Epoch [5141/10000], Loss: 423.2472\n",
            "Epoch [5142/10000], Loss: 418.9836\n",
            "Epoch [5143/10000], Loss: 413.6825\n",
            "Epoch [5144/10000], Loss: 417.6306\n",
            "Epoch [5145/10000], Loss: 420.1975\n",
            "Epoch [5146/10000], Loss: 419.7612\n",
            "Epoch [5147/10000], Loss: 418.8031\n",
            "Epoch [5148/10000], Loss: 419.5187\n",
            "Epoch [5149/10000], Loss: 426.1313\n",
            "Epoch [5150/10000], Loss: 415.1793\n",
            "Epoch [5151/10000], Loss: 416.0782\n",
            "Epoch [5152/10000], Loss: 418.4371\n",
            "Epoch [5153/10000], Loss: 415.6148\n",
            "Epoch [5154/10000], Loss: 411.5112\n",
            "Epoch [5155/10000], Loss: 411.4018\n",
            "Epoch [5156/10000], Loss: 411.0127\n",
            "Epoch [5157/10000], Loss: 419.7013\n",
            "Epoch [5158/10000], Loss: 418.5676\n",
            "Epoch [5159/10000], Loss: 411.3873\n",
            "Epoch [5160/10000], Loss: 407.6447\n",
            "Epoch [5161/10000], Loss: 401.0448\n",
            "Epoch [5162/10000], Loss: 408.1110\n",
            "Epoch [5163/10000], Loss: 408.5139\n",
            "Epoch [5164/10000], Loss: 405.7333\n",
            "Epoch [5165/10000], Loss: 411.1646\n",
            "Epoch [5166/10000], Loss: 407.7845\n",
            "Epoch [5167/10000], Loss: 403.6412\n",
            "Epoch [5168/10000], Loss: 414.8633\n",
            "Epoch [5169/10000], Loss: 409.6541\n",
            "Epoch [5170/10000], Loss: 423.6138\n",
            "Epoch [5171/10000], Loss: 405.8099\n",
            "Epoch [5172/10000], Loss: 400.6136\n",
            "Epoch [5173/10000], Loss: 403.5717\n",
            "Epoch [5174/10000], Loss: 407.0623\n",
            "Epoch [5175/10000], Loss: 409.1630\n",
            "Epoch [5176/10000], Loss: 405.6874\n",
            "Epoch [5177/10000], Loss: 414.1309\n",
            "Epoch [5178/10000], Loss: 402.1083\n",
            "Epoch [5179/10000], Loss: 410.7990\n",
            "Epoch [5180/10000], Loss: 410.5940\n",
            "Epoch [5181/10000], Loss: 408.9218\n",
            "Epoch [5182/10000], Loss: 405.1941\n",
            "Epoch [5183/10000], Loss: 412.5437\n",
            "Epoch [5184/10000], Loss: 416.7110\n",
            "Epoch [5185/10000], Loss: 415.3913\n",
            "Epoch [5186/10000], Loss: 414.2729\n",
            "Epoch [5187/10000], Loss: 408.9166\n",
            "Epoch [5188/10000], Loss: 402.0899\n",
            "Epoch [5189/10000], Loss: 404.2085\n",
            "Epoch [5190/10000], Loss: 413.2510\n",
            "Epoch [5191/10000], Loss: 407.6646\n",
            "Epoch [5192/10000], Loss: 405.3988\n",
            "Epoch [5193/10000], Loss: 406.6286\n",
            "Epoch [5194/10000], Loss: 406.3828\n",
            "Epoch [5195/10000], Loss: 398.3979\n",
            "Epoch [5196/10000], Loss: 402.0471\n",
            "Epoch [5197/10000], Loss: 398.4936\n",
            "Epoch [5198/10000], Loss: 393.4427\n",
            "Epoch [5199/10000], Loss: 396.8899\n",
            "Epoch [5200/10000], Loss: 404.1098\n",
            "Epoch [5201/10000], Loss: 402.6865\n",
            "Epoch [5202/10000], Loss: 392.1899\n",
            "Epoch [5203/10000], Loss: 403.0232\n",
            "Epoch [5204/10000], Loss: 402.1628\n",
            "Epoch [5205/10000], Loss: 396.1651\n",
            "Epoch [5206/10000], Loss: 397.7837\n",
            "Epoch [5207/10000], Loss: 414.3902\n",
            "Epoch [5208/10000], Loss: 392.3905\n",
            "Epoch [5209/10000], Loss: 394.4560\n",
            "Epoch [5210/10000], Loss: 411.0107\n",
            "Epoch [5211/10000], Loss: 398.5887\n",
            "Epoch [5212/10000], Loss: 400.3796\n",
            "Epoch [5213/10000], Loss: 401.7465\n",
            "Epoch [5214/10000], Loss: 401.6632\n",
            "Epoch [5215/10000], Loss: 396.1294\n",
            "Epoch [5216/10000], Loss: 398.9767\n",
            "Epoch [5217/10000], Loss: 401.3507\n",
            "Epoch [5218/10000], Loss: 401.4892\n",
            "Epoch [5219/10000], Loss: 388.9100\n",
            "Epoch [5220/10000], Loss: 394.7049\n",
            "Epoch [5221/10000], Loss: 392.8184\n",
            "Epoch [5222/10000], Loss: 395.1140\n",
            "Epoch [5223/10000], Loss: 392.7125\n",
            "Epoch [5224/10000], Loss: 400.2479\n",
            "Epoch [5225/10000], Loss: 395.7237\n",
            "Epoch [5226/10000], Loss: 399.2570\n",
            "Epoch [5227/10000], Loss: 396.5041\n",
            "Epoch [5228/10000], Loss: 391.8756\n",
            "Epoch [5229/10000], Loss: 390.8217\n",
            "Epoch [5230/10000], Loss: 390.9872\n",
            "Epoch [5231/10000], Loss: 384.6350\n",
            "Epoch [5232/10000], Loss: 402.1811\n",
            "Epoch [5233/10000], Loss: 393.0934\n",
            "Epoch [5234/10000], Loss: 400.5514\n",
            "Epoch [5235/10000], Loss: 392.4783\n",
            "Epoch [5236/10000], Loss: 393.6386\n",
            "Epoch [5237/10000], Loss: 382.8075\n",
            "Epoch [5238/10000], Loss: 381.7248\n",
            "Epoch [5239/10000], Loss: 396.2664\n",
            "Epoch [5240/10000], Loss: 395.3111\n",
            "Epoch [5241/10000], Loss: 395.5590\n",
            "Epoch [5242/10000], Loss: 400.9242\n",
            "Epoch [5243/10000], Loss: 398.6188\n",
            "Epoch [5244/10000], Loss: 384.0222\n",
            "Epoch [5245/10000], Loss: 383.5557\n",
            "Epoch [5246/10000], Loss: 396.7718\n",
            "Epoch [5247/10000], Loss: 384.1062\n",
            "Epoch [5248/10000], Loss: 391.2039\n",
            "Epoch [5249/10000], Loss: 394.2012\n",
            "Epoch [5250/10000], Loss: 387.3029\n",
            "Epoch [5251/10000], Loss: 383.5180\n",
            "Epoch [5252/10000], Loss: 395.1641\n",
            "Epoch [5253/10000], Loss: 391.1923\n",
            "Epoch [5254/10000], Loss: 389.5414\n",
            "Epoch [5255/10000], Loss: 381.2864\n",
            "Epoch [5256/10000], Loss: 393.6025\n",
            "Epoch [5257/10000], Loss: 384.9220\n",
            "Epoch [5258/10000], Loss: 384.8279\n",
            "Epoch [5259/10000], Loss: 390.0684\n",
            "Epoch [5260/10000], Loss: 388.2101\n",
            "Epoch [5261/10000], Loss: 390.7544\n",
            "Epoch [5262/10000], Loss: 392.3182\n",
            "Epoch [5263/10000], Loss: 395.5940\n",
            "Epoch [5264/10000], Loss: 379.7702\n",
            "Epoch [5265/10000], Loss: 379.4407\n",
            "Epoch [5266/10000], Loss: 382.2431\n",
            "Epoch [5267/10000], Loss: 398.0219\n",
            "Epoch [5268/10000], Loss: 386.3763\n",
            "Epoch [5269/10000], Loss: 390.5435\n",
            "Epoch [5270/10000], Loss: 382.3278\n",
            "Epoch [5271/10000], Loss: 379.7724\n",
            "Epoch [5272/10000], Loss: 383.9277\n",
            "Epoch [5273/10000], Loss: 397.5201\n",
            "Epoch [5274/10000], Loss: 391.1779\n",
            "Epoch [5275/10000], Loss: 391.1918\n",
            "Epoch [5276/10000], Loss: 388.1039\n",
            "Epoch [5277/10000], Loss: 378.3763\n",
            "Epoch [5278/10000], Loss: 381.9078\n",
            "Epoch [5279/10000], Loss: 368.1939\n",
            "Epoch [5280/10000], Loss: 380.5712\n",
            "Epoch [5281/10000], Loss: 374.2527\n",
            "Epoch [5282/10000], Loss: 385.4126\n",
            "Epoch [5283/10000], Loss: 380.4190\n",
            "Epoch [5284/10000], Loss: 369.4229\n",
            "Epoch [5285/10000], Loss: 383.7047\n",
            "Epoch [5286/10000], Loss: 372.4709\n",
            "Epoch [5287/10000], Loss: 380.7460\n",
            "Epoch [5288/10000], Loss: 380.0307\n",
            "Epoch [5289/10000], Loss: 369.8173\n",
            "Epoch [5290/10000], Loss: 388.9912\n",
            "Epoch [5291/10000], Loss: 385.7838\n",
            "Epoch [5292/10000], Loss: 376.6712\n",
            "Epoch [5293/10000], Loss: 377.8833\n",
            "Epoch [5294/10000], Loss: 371.7495\n",
            "Epoch [5295/10000], Loss: 378.6588\n",
            "Epoch [5296/10000], Loss: 377.8639\n",
            "Epoch [5297/10000], Loss: 372.2330\n",
            "Epoch [5298/10000], Loss: 382.4373\n",
            "Epoch [5299/10000], Loss: 374.8577\n",
            "Epoch [5300/10000], Loss: 380.3520\n",
            "Epoch [5301/10000], Loss: 383.3608\n",
            "Epoch [5302/10000], Loss: 367.8957\n",
            "Epoch [5303/10000], Loss: 378.2458\n",
            "Epoch [5304/10000], Loss: 375.9025\n",
            "Epoch [5305/10000], Loss: 380.3709\n",
            "Epoch [5306/10000], Loss: 376.0690\n",
            "Epoch [5307/10000], Loss: 374.9093\n",
            "Epoch [5308/10000], Loss: 371.9365\n",
            "Epoch [5309/10000], Loss: 374.2125\n",
            "Epoch [5310/10000], Loss: 367.7747\n",
            "Epoch [5311/10000], Loss: 368.7093\n",
            "Epoch [5312/10000], Loss: 368.4811\n",
            "Epoch [5313/10000], Loss: 381.3513\n",
            "Epoch [5314/10000], Loss: 359.5181\n",
            "Epoch [5315/10000], Loss: 374.3398\n",
            "Epoch [5316/10000], Loss: 368.6306\n",
            "Epoch [5317/10000], Loss: 366.2236\n",
            "Epoch [5318/10000], Loss: 373.5036\n",
            "Epoch [5319/10000], Loss: 373.4837\n",
            "Epoch [5320/10000], Loss: 368.9673\n",
            "Epoch [5321/10000], Loss: 369.1772\n",
            "Epoch [5322/10000], Loss: 372.0332\n",
            "Epoch [5323/10000], Loss: 370.5332\n",
            "Epoch [5324/10000], Loss: 376.2712\n",
            "Epoch [5325/10000], Loss: 381.3207\n",
            "Epoch [5326/10000], Loss: 375.0471\n",
            "Epoch [5327/10000], Loss: 368.2780\n",
            "Epoch [5328/10000], Loss: 370.6108\n",
            "Epoch [5329/10000], Loss: 361.1642\n",
            "Epoch [5330/10000], Loss: 372.8955\n",
            "Epoch [5331/10000], Loss: 362.8077\n",
            "Epoch [5332/10000], Loss: 373.2702\n",
            "Epoch [5333/10000], Loss: 356.8851\n",
            "Epoch [5334/10000], Loss: 366.2367\n",
            "Epoch [5335/10000], Loss: 370.4448\n",
            "Epoch [5336/10000], Loss: 369.7102\n",
            "Epoch [5337/10000], Loss: 365.2538\n",
            "Epoch [5338/10000], Loss: 379.2226\n",
            "Epoch [5339/10000], Loss: 366.9905\n",
            "Epoch [5340/10000], Loss: 367.2632\n",
            "Epoch [5341/10000], Loss: 359.5334\n",
            "Epoch [5342/10000], Loss: 372.3397\n",
            "Epoch [5343/10000], Loss: 376.4252\n",
            "Epoch [5344/10000], Loss: 374.2021\n",
            "Epoch [5345/10000], Loss: 372.4449\n",
            "Epoch [5346/10000], Loss: 357.9872\n",
            "Epoch [5347/10000], Loss: 367.9106\n",
            "Epoch [5348/10000], Loss: 360.2982\n",
            "Epoch [5349/10000], Loss: 359.7343\n",
            "Epoch [5350/10000], Loss: 360.8215\n",
            "Epoch [5351/10000], Loss: 364.7271\n",
            "Epoch [5352/10000], Loss: 357.8104\n",
            "Epoch [5353/10000], Loss: 371.5350\n",
            "Epoch [5354/10000], Loss: 362.8744\n",
            "Epoch [5355/10000], Loss: 364.9822\n",
            "Epoch [5356/10000], Loss: 356.2538\n",
            "Epoch [5357/10000], Loss: 357.6822\n",
            "Epoch [5358/10000], Loss: 355.5327\n",
            "Epoch [5359/10000], Loss: 357.0159\n",
            "Epoch [5360/10000], Loss: 360.4145\n",
            "Epoch [5361/10000], Loss: 356.6382\n",
            "Epoch [5362/10000], Loss: 368.1641\n",
            "Epoch [5363/10000], Loss: 364.2221\n",
            "Epoch [5364/10000], Loss: 363.5868\n",
            "Epoch [5365/10000], Loss: 357.2589\n",
            "Epoch [5366/10000], Loss: 359.6206\n",
            "Epoch [5367/10000], Loss: 358.0269\n",
            "Epoch [5368/10000], Loss: 352.7573\n",
            "Epoch [5369/10000], Loss: 365.2607\n",
            "Epoch [5370/10000], Loss: 359.7006\n",
            "Epoch [5371/10000], Loss: 353.4456\n",
            "Epoch [5372/10000], Loss: 357.9752\n",
            "Epoch [5373/10000], Loss: 368.2014\n",
            "Epoch [5374/10000], Loss: 358.4345\n",
            "Epoch [5375/10000], Loss: 350.1445\n",
            "Epoch [5376/10000], Loss: 364.5703\n",
            "Epoch [5377/10000], Loss: 354.9699\n",
            "Epoch [5378/10000], Loss: 357.3415\n",
            "Epoch [5379/10000], Loss: 359.1118\n",
            "Epoch [5380/10000], Loss: 356.5962\n",
            "Epoch [5381/10000], Loss: 347.3837\n",
            "Epoch [5382/10000], Loss: 357.2872\n",
            "Epoch [5383/10000], Loss: 347.1994\n",
            "Epoch [5384/10000], Loss: 359.1284\n",
            "Epoch [5385/10000], Loss: 364.8977\n",
            "Epoch [5386/10000], Loss: 350.9965\n",
            "Epoch [5387/10000], Loss: 345.0907\n",
            "Epoch [5388/10000], Loss: 356.0348\n",
            "Epoch [5389/10000], Loss: 350.9496\n",
            "Epoch [5390/10000], Loss: 358.1083\n",
            "Epoch [5391/10000], Loss: 354.8351\n",
            "Epoch [5392/10000], Loss: 354.0286\n",
            "Epoch [5393/10000], Loss: 342.6693\n",
            "Epoch [5394/10000], Loss: 362.9698\n",
            "Epoch [5395/10000], Loss: 363.3831\n",
            "Epoch [5396/10000], Loss: 358.2579\n",
            "Epoch [5397/10000], Loss: 363.2603\n",
            "Epoch [5398/10000], Loss: 346.6497\n",
            "Epoch [5399/10000], Loss: 344.0545\n",
            "Epoch [5400/10000], Loss: 354.9924\n",
            "Epoch [5401/10000], Loss: 346.1357\n",
            "Epoch [5402/10000], Loss: 357.1961\n",
            "Epoch [5403/10000], Loss: 346.5276\n",
            "Epoch [5404/10000], Loss: 345.9009\n",
            "Epoch [5405/10000], Loss: 351.5082\n",
            "Epoch [5406/10000], Loss: 350.6369\n",
            "Epoch [5407/10000], Loss: 355.1355\n",
            "Epoch [5408/10000], Loss: 345.2753\n",
            "Epoch [5409/10000], Loss: 343.5797\n",
            "Epoch [5410/10000], Loss: 345.1532\n",
            "Epoch [5411/10000], Loss: 349.0381\n",
            "Epoch [5412/10000], Loss: 353.3680\n",
            "Epoch [5413/10000], Loss: 340.4975\n",
            "Epoch [5414/10000], Loss: 342.4556\n",
            "Epoch [5415/10000], Loss: 351.5938\n",
            "Epoch [5416/10000], Loss: 343.0410\n",
            "Epoch [5417/10000], Loss: 355.0266\n",
            "Epoch [5418/10000], Loss: 344.7499\n",
            "Epoch [5419/10000], Loss: 342.8428\n",
            "Epoch [5420/10000], Loss: 341.8182\n",
            "Epoch [5421/10000], Loss: 351.0652\n",
            "Epoch [5422/10000], Loss: 345.1939\n",
            "Epoch [5423/10000], Loss: 341.1228\n",
            "Epoch [5424/10000], Loss: 340.8889\n",
            "Epoch [5425/10000], Loss: 343.1933\n",
            "Epoch [5426/10000], Loss: 345.0078\n",
            "Epoch [5427/10000], Loss: 344.2465\n",
            "Epoch [5428/10000], Loss: 349.0315\n",
            "Epoch [5429/10000], Loss: 347.3238\n",
            "Epoch [5430/10000], Loss: 342.2756\n",
            "Epoch [5431/10000], Loss: 338.1163\n",
            "Epoch [5432/10000], Loss: 339.1772\n",
            "Epoch [5433/10000], Loss: 343.6308\n",
            "Epoch [5434/10000], Loss: 344.0256\n",
            "Epoch [5435/10000], Loss: 346.0490\n",
            "Epoch [5436/10000], Loss: 353.4130\n",
            "Epoch [5437/10000], Loss: 352.6584\n",
            "Epoch [5438/10000], Loss: 346.0275\n",
            "Epoch [5439/10000], Loss: 342.9666\n",
            "Epoch [5440/10000], Loss: 346.2929\n",
            "Epoch [5441/10000], Loss: 340.7993\n",
            "Epoch [5442/10000], Loss: 346.0373\n",
            "Epoch [5443/10000], Loss: 344.7400\n",
            "Epoch [5444/10000], Loss: 338.0252\n",
            "Epoch [5445/10000], Loss: 340.1735\n",
            "Epoch [5446/10000], Loss: 343.1801\n",
            "Epoch [5447/10000], Loss: 349.9914\n",
            "Epoch [5448/10000], Loss: 340.3925\n",
            "Epoch [5449/10000], Loss: 346.1735\n",
            "Epoch [5450/10000], Loss: 338.3172\n",
            "Epoch [5451/10000], Loss: 337.1613\n",
            "Epoch [5452/10000], Loss: 345.0352\n",
            "Epoch [5453/10000], Loss: 343.0001\n",
            "Epoch [5454/10000], Loss: 341.0035\n",
            "Epoch [5455/10000], Loss: 342.1406\n",
            "Epoch [5456/10000], Loss: 334.2104\n",
            "Epoch [5457/10000], Loss: 332.8024\n",
            "Epoch [5458/10000], Loss: 342.7333\n",
            "Epoch [5459/10000], Loss: 332.2437\n",
            "Epoch [5460/10000], Loss: 332.6613\n",
            "Epoch [5461/10000], Loss: 346.2324\n",
            "Epoch [5462/10000], Loss: 339.0667\n",
            "Epoch [5463/10000], Loss: 334.2158\n",
            "Epoch [5464/10000], Loss: 329.5311\n",
            "Epoch [5465/10000], Loss: 338.8113\n",
            "Epoch [5466/10000], Loss: 334.9343\n",
            "Epoch [5467/10000], Loss: 336.5486\n",
            "Epoch [5468/10000], Loss: 340.2800\n",
            "Epoch [5469/10000], Loss: 337.4267\n",
            "Epoch [5470/10000], Loss: 331.7726\n",
            "Epoch [5471/10000], Loss: 335.2101\n",
            "Epoch [5472/10000], Loss: 339.1355\n",
            "Epoch [5473/10000], Loss: 335.3786\n",
            "Epoch [5474/10000], Loss: 330.9547\n",
            "Epoch [5475/10000], Loss: 341.0693\n",
            "Epoch [5476/10000], Loss: 346.0838\n",
            "Epoch [5477/10000], Loss: 339.4598\n",
            "Epoch [5478/10000], Loss: 341.1789\n",
            "Epoch [5479/10000], Loss: 332.6891\n",
            "Epoch [5480/10000], Loss: 345.0413\n",
            "Epoch [5481/10000], Loss: 334.4899\n",
            "Epoch [5482/10000], Loss: 345.4607\n",
            "Epoch [5483/10000], Loss: 328.1250\n",
            "Epoch [5484/10000], Loss: 326.5518\n",
            "Epoch [5485/10000], Loss: 333.9389\n",
            "Epoch [5486/10000], Loss: 332.9944\n",
            "Epoch [5487/10000], Loss: 330.6800\n",
            "Epoch [5488/10000], Loss: 332.4501\n",
            "Epoch [5489/10000], Loss: 325.2111\n",
            "Epoch [5490/10000], Loss: 342.5791\n",
            "Epoch [5491/10000], Loss: 327.3301\n",
            "Epoch [5492/10000], Loss: 328.7169\n",
            "Epoch [5493/10000], Loss: 328.9865\n",
            "Epoch [5494/10000], Loss: 335.7635\n",
            "Epoch [5495/10000], Loss: 328.8043\n",
            "Epoch [5496/10000], Loss: 333.1411\n",
            "Epoch [5497/10000], Loss: 343.1772\n",
            "Epoch [5498/10000], Loss: 338.6790\n",
            "Epoch [5499/10000], Loss: 327.7829\n",
            "Epoch [5500/10000], Loss: 335.8477\n",
            "Epoch [5501/10000], Loss: 338.1418\n",
            "Epoch [5502/10000], Loss: 327.5982\n",
            "Epoch [5503/10000], Loss: 330.6723\n",
            "Epoch [5504/10000], Loss: 338.1263\n",
            "Epoch [5505/10000], Loss: 328.5689\n",
            "Epoch [5506/10000], Loss: 317.6064\n",
            "Epoch [5507/10000], Loss: 330.1949\n",
            "Epoch [5508/10000], Loss: 322.4716\n",
            "Epoch [5509/10000], Loss: 335.7378\n",
            "Epoch [5510/10000], Loss: 322.0518\n",
            "Epoch [5511/10000], Loss: 321.8286\n",
            "Epoch [5512/10000], Loss: 332.8924\n",
            "Epoch [5513/10000], Loss: 333.2727\n",
            "Epoch [5514/10000], Loss: 329.4683\n",
            "Epoch [5515/10000], Loss: 322.7177\n",
            "Epoch [5516/10000], Loss: 327.5185\n",
            "Epoch [5517/10000], Loss: 324.8970\n",
            "Epoch [5518/10000], Loss: 342.8407\n",
            "Epoch [5519/10000], Loss: 326.3324\n",
            "Epoch [5520/10000], Loss: 327.5709\n",
            "Epoch [5521/10000], Loss: 333.6615\n",
            "Epoch [5522/10000], Loss: 327.5779\n",
            "Epoch [5523/10000], Loss: 326.3525\n",
            "Epoch [5524/10000], Loss: 322.0124\n",
            "Epoch [5525/10000], Loss: 324.7374\n",
            "Epoch [5526/10000], Loss: 331.7630\n",
            "Epoch [5527/10000], Loss: 321.9206\n",
            "Epoch [5528/10000], Loss: 328.4755\n",
            "Epoch [5529/10000], Loss: 327.9992\n",
            "Epoch [5530/10000], Loss: 321.4755\n",
            "Epoch [5531/10000], Loss: 321.8281\n",
            "Epoch [5532/10000], Loss: 329.6453\n",
            "Epoch [5533/10000], Loss: 334.4510\n",
            "Epoch [5534/10000], Loss: 325.5463\n",
            "Epoch [5535/10000], Loss: 327.0059\n",
            "Epoch [5536/10000], Loss: 321.7072\n",
            "Epoch [5537/10000], Loss: 330.0695\n",
            "Epoch [5538/10000], Loss: 317.6469\n",
            "Epoch [5539/10000], Loss: 316.0041\n",
            "Epoch [5540/10000], Loss: 314.4750\n",
            "Epoch [5541/10000], Loss: 318.8804\n",
            "Epoch [5542/10000], Loss: 322.9973\n",
            "Epoch [5543/10000], Loss: 319.0283\n",
            "Epoch [5544/10000], Loss: 323.3964\n",
            "Epoch [5545/10000], Loss: 329.9945\n",
            "Epoch [5546/10000], Loss: 312.8435\n",
            "Epoch [5547/10000], Loss: 314.2863\n",
            "Epoch [5548/10000], Loss: 324.4055\n",
            "Epoch [5549/10000], Loss: 313.9734\n",
            "Epoch [5550/10000], Loss: 315.0161\n",
            "Epoch [5551/10000], Loss: 322.3747\n",
            "Epoch [5552/10000], Loss: 322.1783\n",
            "Epoch [5553/10000], Loss: 317.0593\n",
            "Epoch [5554/10000], Loss: 316.3125\n",
            "Epoch [5555/10000], Loss: 319.8114\n",
            "Epoch [5556/10000], Loss: 311.2516\n",
            "Epoch [5557/10000], Loss: 318.6563\n",
            "Epoch [5558/10000], Loss: 319.0678\n",
            "Epoch [5559/10000], Loss: 314.5073\n",
            "Epoch [5560/10000], Loss: 324.6719\n",
            "Epoch [5561/10000], Loss: 315.0756\n",
            "Epoch [5562/10000], Loss: 319.3681\n",
            "Epoch [5563/10000], Loss: 318.8236\n",
            "Epoch [5564/10000], Loss: 321.2745\n",
            "Epoch [5565/10000], Loss: 310.0394\n",
            "Epoch [5566/10000], Loss: 314.5963\n",
            "Epoch [5567/10000], Loss: 308.0331\n",
            "Epoch [5568/10000], Loss: 312.3282\n",
            "Epoch [5569/10000], Loss: 313.9941\n",
            "Epoch [5570/10000], Loss: 312.3109\n",
            "Epoch [5571/10000], Loss: 308.1752\n",
            "Epoch [5572/10000], Loss: 323.9142\n",
            "Epoch [5573/10000], Loss: 306.3934\n",
            "Epoch [5574/10000], Loss: 318.8062\n",
            "Epoch [5575/10000], Loss: 327.2289\n",
            "Epoch [5576/10000], Loss: 310.4711\n",
            "Epoch [5577/10000], Loss: 314.8709\n",
            "Epoch [5578/10000], Loss: 311.0815\n",
            "Epoch [5579/10000], Loss: 321.0528\n",
            "Epoch [5580/10000], Loss: 319.7522\n",
            "Epoch [5581/10000], Loss: 310.1351\n",
            "Epoch [5582/10000], Loss: 310.7458\n",
            "Epoch [5583/10000], Loss: 315.8595\n",
            "Epoch [5584/10000], Loss: 319.3651\n",
            "Epoch [5585/10000], Loss: 317.3073\n",
            "Epoch [5586/10000], Loss: 312.6118\n",
            "Epoch [5587/10000], Loss: 311.9945\n",
            "Epoch [5588/10000], Loss: 315.6019\n",
            "Epoch [5589/10000], Loss: 315.5644\n",
            "Epoch [5590/10000], Loss: 306.7199\n",
            "Epoch [5591/10000], Loss: 319.2861\n",
            "Epoch [5592/10000], Loss: 306.2137\n",
            "Epoch [5593/10000], Loss: 307.6014\n",
            "Epoch [5594/10000], Loss: 314.8410\n",
            "Epoch [5595/10000], Loss: 315.3845\n",
            "Epoch [5596/10000], Loss: 313.6146\n",
            "Epoch [5597/10000], Loss: 311.6540\n",
            "Epoch [5598/10000], Loss: 320.8251\n",
            "Epoch [5599/10000], Loss: 317.8012\n",
            "Epoch [5600/10000], Loss: 309.1815\n",
            "Epoch [5601/10000], Loss: 308.5405\n",
            "Epoch [5602/10000], Loss: 312.8105\n",
            "Epoch [5603/10000], Loss: 301.3507\n",
            "Epoch [5604/10000], Loss: 304.8614\n",
            "Epoch [5605/10000], Loss: 305.1882\n",
            "Epoch [5606/10000], Loss: 308.4998\n",
            "Epoch [5607/10000], Loss: 308.0675\n",
            "Epoch [5608/10000], Loss: 319.2633\n",
            "Epoch [5609/10000], Loss: 301.8345\n",
            "Epoch [5610/10000], Loss: 301.5000\n",
            "Epoch [5611/10000], Loss: 311.7087\n",
            "Epoch [5612/10000], Loss: 304.6320\n",
            "Epoch [5613/10000], Loss: 304.3864\n",
            "Epoch [5614/10000], Loss: 303.1290\n",
            "Epoch [5615/10000], Loss: 315.9022\n",
            "Epoch [5616/10000], Loss: 311.3169\n",
            "Epoch [5617/10000], Loss: 302.7199\n",
            "Epoch [5618/10000], Loss: 300.7063\n",
            "Epoch [5619/10000], Loss: 308.1320\n",
            "Epoch [5620/10000], Loss: 293.8291\n",
            "Epoch [5621/10000], Loss: 299.4000\n",
            "Epoch [5622/10000], Loss: 300.9589\n",
            "Epoch [5623/10000], Loss: 306.4917\n",
            "Epoch [5624/10000], Loss: 302.4985\n",
            "Epoch [5625/10000], Loss: 299.5205\n",
            "Epoch [5626/10000], Loss: 316.4487\n",
            "Epoch [5627/10000], Loss: 314.0126\n",
            "Epoch [5628/10000], Loss: 304.8744\n",
            "Epoch [5629/10000], Loss: 289.7155\n",
            "Epoch [5630/10000], Loss: 305.7943\n",
            "Epoch [5631/10000], Loss: 308.3374\n",
            "Epoch [5632/10000], Loss: 297.9767\n",
            "Epoch [5633/10000], Loss: 294.1823\n",
            "Epoch [5634/10000], Loss: 299.7196\n",
            "Epoch [5635/10000], Loss: 302.9323\n",
            "Epoch [5636/10000], Loss: 300.4576\n",
            "Epoch [5637/10000], Loss: 301.6471\n",
            "Epoch [5638/10000], Loss: 303.2878\n",
            "Epoch [5639/10000], Loss: 299.6642\n",
            "Epoch [5640/10000], Loss: 309.4364\n",
            "Epoch [5641/10000], Loss: 308.4673\n",
            "Epoch [5642/10000], Loss: 311.4738\n",
            "Epoch [5643/10000], Loss: 301.7428\n",
            "Epoch [5644/10000], Loss: 307.7188\n",
            "Epoch [5645/10000], Loss: 298.1495\n",
            "Epoch [5646/10000], Loss: 304.3430\n",
            "Epoch [5647/10000], Loss: 306.3487\n",
            "Epoch [5648/10000], Loss: 299.5819\n",
            "Epoch [5649/10000], Loss: 302.3233\n",
            "Epoch [5650/10000], Loss: 303.0180\n",
            "Epoch [5651/10000], Loss: 298.2386\n",
            "Epoch [5652/10000], Loss: 303.1331\n",
            "Epoch [5653/10000], Loss: 313.1611\n",
            "Epoch [5654/10000], Loss: 302.2238\n",
            "Epoch [5655/10000], Loss: 292.3001\n",
            "Epoch [5656/10000], Loss: 301.4333\n",
            "Epoch [5657/10000], Loss: 296.6149\n",
            "Epoch [5658/10000], Loss: 298.7313\n",
            "Epoch [5659/10000], Loss: 295.8467\n",
            "Epoch [5660/10000], Loss: 299.1615\n",
            "Epoch [5661/10000], Loss: 296.1568\n",
            "Epoch [5662/10000], Loss: 297.7563\n",
            "Epoch [5663/10000], Loss: 307.8324\n",
            "Epoch [5664/10000], Loss: 293.8868\n",
            "Epoch [5665/10000], Loss: 297.1589\n",
            "Epoch [5666/10000], Loss: 311.8295\n",
            "Epoch [5667/10000], Loss: 311.1257\n",
            "Epoch [5668/10000], Loss: 296.4731\n",
            "Epoch [5669/10000], Loss: 295.1072\n",
            "Epoch [5670/10000], Loss: 294.8534\n",
            "Epoch [5671/10000], Loss: 300.1647\n",
            "Epoch [5672/10000], Loss: 300.3815\n",
            "Epoch [5673/10000], Loss: 295.0764\n",
            "Epoch [5674/10000], Loss: 293.3239\n",
            "Epoch [5675/10000], Loss: 304.2002\n",
            "Epoch [5676/10000], Loss: 287.2980\n",
            "Epoch [5677/10000], Loss: 294.9793\n",
            "Epoch [5678/10000], Loss: 288.8817\n",
            "Epoch [5679/10000], Loss: 287.4741\n",
            "Epoch [5680/10000], Loss: 305.8207\n",
            "Epoch [5681/10000], Loss: 298.2348\n",
            "Epoch [5682/10000], Loss: 305.2014\n",
            "Epoch [5683/10000], Loss: 294.9248\n",
            "Epoch [5684/10000], Loss: 291.0503\n",
            "Epoch [5685/10000], Loss: 291.5762\n",
            "Epoch [5686/10000], Loss: 295.1090\n",
            "Epoch [5687/10000], Loss: 289.4345\n",
            "Epoch [5688/10000], Loss: 289.8201\n",
            "Epoch [5689/10000], Loss: 295.0671\n",
            "Epoch [5690/10000], Loss: 297.1001\n",
            "Epoch [5691/10000], Loss: 296.8071\n",
            "Epoch [5692/10000], Loss: 290.7733\n",
            "Epoch [5693/10000], Loss: 285.7317\n",
            "Epoch [5694/10000], Loss: 291.1797\n",
            "Epoch [5695/10000], Loss: 295.1128\n",
            "Epoch [5696/10000], Loss: 279.4579\n",
            "Epoch [5697/10000], Loss: 287.2558\n",
            "Epoch [5698/10000], Loss: 283.3854\n",
            "Epoch [5699/10000], Loss: 290.9380\n",
            "Epoch [5700/10000], Loss: 281.8071\n",
            "Epoch [5701/10000], Loss: 293.8649\n",
            "Epoch [5702/10000], Loss: 292.8715\n",
            "Epoch [5703/10000], Loss: 289.4378\n",
            "Epoch [5704/10000], Loss: 281.9221\n",
            "Epoch [5705/10000], Loss: 290.4734\n",
            "Epoch [5706/10000], Loss: 289.6028\n",
            "Epoch [5707/10000], Loss: 294.7805\n",
            "Epoch [5708/10000], Loss: 288.1242\n",
            "Epoch [5709/10000], Loss: 283.4838\n",
            "Epoch [5710/10000], Loss: 282.0952\n",
            "Epoch [5711/10000], Loss: 289.4478\n",
            "Epoch [5712/10000], Loss: 289.8530\n",
            "Epoch [5713/10000], Loss: 297.7796\n",
            "Epoch [5714/10000], Loss: 280.1157\n",
            "Epoch [5715/10000], Loss: 281.8436\n",
            "Epoch [5716/10000], Loss: 291.9635\n",
            "Epoch [5717/10000], Loss: 296.2638\n",
            "Epoch [5718/10000], Loss: 286.2075\n",
            "Epoch [5719/10000], Loss: 281.2686\n",
            "Epoch [5720/10000], Loss: 292.0337\n",
            "Epoch [5721/10000], Loss: 275.6202\n",
            "Epoch [5722/10000], Loss: 276.7126\n",
            "Epoch [5723/10000], Loss: 282.9715\n",
            "Epoch [5724/10000], Loss: 283.8241\n",
            "Epoch [5725/10000], Loss: 287.7255\n",
            "Epoch [5726/10000], Loss: 280.9507\n",
            "Epoch [5727/10000], Loss: 281.8054\n",
            "Epoch [5728/10000], Loss: 278.7522\n",
            "Epoch [5729/10000], Loss: 289.1577\n",
            "Epoch [5730/10000], Loss: 277.0050\n",
            "Epoch [5731/10000], Loss: 285.4757\n",
            "Epoch [5732/10000], Loss: 279.4936\n",
            "Epoch [5733/10000], Loss: 294.1929\n",
            "Epoch [5734/10000], Loss: 285.8433\n",
            "Epoch [5735/10000], Loss: 280.9791\n",
            "Epoch [5736/10000], Loss: 282.5077\n",
            "Epoch [5737/10000], Loss: 288.9897\n",
            "Epoch [5738/10000], Loss: 287.4272\n",
            "Epoch [5739/10000], Loss: 279.5871\n",
            "Epoch [5740/10000], Loss: 283.1768\n",
            "Epoch [5741/10000], Loss: 286.5607\n",
            "Epoch [5742/10000], Loss: 280.7722\n",
            "Epoch [5743/10000], Loss: 283.0042\n",
            "Epoch [5744/10000], Loss: 285.2870\n",
            "Epoch [5745/10000], Loss: 283.6491\n",
            "Epoch [5746/10000], Loss: 268.3947\n",
            "Epoch [5747/10000], Loss: 280.9467\n",
            "Epoch [5748/10000], Loss: 278.9291\n",
            "Epoch [5749/10000], Loss: 288.5905\n",
            "Epoch [5750/10000], Loss: 296.2585\n",
            "Epoch [5751/10000], Loss: 274.2054\n",
            "Epoch [5752/10000], Loss: 283.4057\n",
            "Epoch [5753/10000], Loss: 274.8867\n",
            "Epoch [5754/10000], Loss: 286.1995\n",
            "Epoch [5755/10000], Loss: 282.1009\n",
            "Epoch [5756/10000], Loss: 288.7471\n",
            "Epoch [5757/10000], Loss: 286.4658\n",
            "Epoch [5758/10000], Loss: 280.2543\n",
            "Epoch [5759/10000], Loss: 274.9395\n",
            "Epoch [5760/10000], Loss: 283.1583\n",
            "Epoch [5761/10000], Loss: 274.8230\n",
            "Epoch [5762/10000], Loss: 289.2282\n",
            "Epoch [5763/10000], Loss: 277.6339\n",
            "Epoch [5764/10000], Loss: 274.3578\n",
            "Epoch [5765/10000], Loss: 272.6432\n",
            "Epoch [5766/10000], Loss: 285.8084\n",
            "Epoch [5767/10000], Loss: 288.7439\n",
            "Epoch [5768/10000], Loss: 278.8887\n",
            "Epoch [5769/10000], Loss: 270.3864\n",
            "Epoch [5770/10000], Loss: 279.4175\n",
            "Epoch [5771/10000], Loss: 279.5323\n",
            "Epoch [5772/10000], Loss: 280.2787\n",
            "Epoch [5773/10000], Loss: 286.3263\n",
            "Epoch [5774/10000], Loss: 278.1818\n",
            "Epoch [5775/10000], Loss: 269.1776\n",
            "Epoch [5776/10000], Loss: 278.7228\n",
            "Epoch [5777/10000], Loss: 279.2527\n",
            "Epoch [5778/10000], Loss: 271.0087\n",
            "Epoch [5779/10000], Loss: 273.7695\n",
            "Epoch [5780/10000], Loss: 279.4053\n",
            "Epoch [5781/10000], Loss: 276.5486\n",
            "Epoch [5782/10000], Loss: 270.5151\n",
            "Epoch [5783/10000], Loss: 278.9724\n",
            "Epoch [5784/10000], Loss: 270.1714\n",
            "Epoch [5785/10000], Loss: 275.2485\n",
            "Epoch [5786/10000], Loss: 271.0784\n",
            "Epoch [5787/10000], Loss: 265.1305\n",
            "Epoch [5788/10000], Loss: 269.3859\n",
            "Epoch [5789/10000], Loss: 282.6072\n",
            "Epoch [5790/10000], Loss: 273.8400\n",
            "Epoch [5791/10000], Loss: 271.0591\n",
            "Epoch [5792/10000], Loss: 283.4602\n",
            "Epoch [5793/10000], Loss: 281.1062\n",
            "Epoch [5794/10000], Loss: 271.7728\n",
            "Epoch [5795/10000], Loss: 282.0998\n",
            "Epoch [5796/10000], Loss: 279.7068\n",
            "Epoch [5797/10000], Loss: 274.7473\n",
            "Epoch [5798/10000], Loss: 276.4948\n",
            "Epoch [5799/10000], Loss: 277.7603\n",
            "Epoch [5800/10000], Loss: 269.5602\n",
            "Epoch [5801/10000], Loss: 274.9783\n",
            "Epoch [5802/10000], Loss: 261.9232\n",
            "Epoch [5803/10000], Loss: 272.6024\n",
            "Epoch [5804/10000], Loss: 270.0029\n",
            "Epoch [5805/10000], Loss: 279.2585\n",
            "Epoch [5806/10000], Loss: 279.4688\n",
            "Epoch [5807/10000], Loss: 262.3328\n",
            "Epoch [5808/10000], Loss: 261.0851\n",
            "Epoch [5809/10000], Loss: 266.2158\n",
            "Epoch [5810/10000], Loss: 270.9994\n",
            "Epoch [5811/10000], Loss: 266.1834\n",
            "Epoch [5812/10000], Loss: 283.9633\n",
            "Epoch [5813/10000], Loss: 264.9181\n",
            "Epoch [5814/10000], Loss: 273.3981\n",
            "Epoch [5815/10000], Loss: 267.6256\n",
            "Epoch [5816/10000], Loss: 269.2473\n",
            "Epoch [5817/10000], Loss: 270.4555\n",
            "Epoch [5818/10000], Loss: 275.7056\n",
            "Epoch [5819/10000], Loss: 270.1443\n",
            "Epoch [5820/10000], Loss: 262.7260\n",
            "Epoch [5821/10000], Loss: 266.0882\n",
            "Epoch [5822/10000], Loss: 270.1020\n",
            "Epoch [5823/10000], Loss: 264.1100\n",
            "Epoch [5824/10000], Loss: 274.5045\n",
            "Epoch [5825/10000], Loss: 264.7443\n",
            "Epoch [5826/10000], Loss: 268.2219\n",
            "Epoch [5827/10000], Loss: 260.2307\n",
            "Epoch [5828/10000], Loss: 272.3009\n",
            "Epoch [5829/10000], Loss: 267.5712\n",
            "Epoch [5830/10000], Loss: 265.7039\n",
            "Epoch [5831/10000], Loss: 264.7348\n",
            "Epoch [5832/10000], Loss: 272.9062\n",
            "Epoch [5833/10000], Loss: 272.1169\n",
            "Epoch [5834/10000], Loss: 262.0292\n",
            "Epoch [5835/10000], Loss: 277.1390\n",
            "Epoch [5836/10000], Loss: 267.8662\n",
            "Epoch [5837/10000], Loss: 258.1967\n",
            "Epoch [5838/10000], Loss: 260.7341\n",
            "Epoch [5839/10000], Loss: 269.1489\n",
            "Epoch [5840/10000], Loss: 270.9344\n",
            "Epoch [5841/10000], Loss: 252.7210\n",
            "Epoch [5842/10000], Loss: 266.5544\n",
            "Epoch [5843/10000], Loss: 263.0345\n",
            "Epoch [5844/10000], Loss: 269.0672\n",
            "Epoch [5845/10000], Loss: 262.9496\n",
            "Epoch [5846/10000], Loss: 266.8036\n",
            "Epoch [5847/10000], Loss: 270.0635\n",
            "Epoch [5848/10000], Loss: 263.9149\n",
            "Epoch [5849/10000], Loss: 268.0083\n",
            "Epoch [5850/10000], Loss: 262.3408\n",
            "Epoch [5851/10000], Loss: 270.8572\n",
            "Epoch [5852/10000], Loss: 254.9857\n",
            "Epoch [5853/10000], Loss: 270.8595\n",
            "Epoch [5854/10000], Loss: 264.1724\n",
            "Epoch [5855/10000], Loss: 251.2671\n",
            "Epoch [5856/10000], Loss: 262.0617\n",
            "Epoch [5857/10000], Loss: 271.0054\n",
            "Epoch [5858/10000], Loss: 262.4708\n",
            "Epoch [5859/10000], Loss: 256.0962\n",
            "Epoch [5860/10000], Loss: 267.0577\n",
            "Epoch [5861/10000], Loss: 261.9807\n",
            "Epoch [5862/10000], Loss: 252.5551\n",
            "Epoch [5863/10000], Loss: 263.1107\n",
            "Epoch [5864/10000], Loss: 261.4985\n",
            "Epoch [5865/10000], Loss: 259.1517\n",
            "Epoch [5866/10000], Loss: 255.7900\n",
            "Epoch [5867/10000], Loss: 268.0642\n",
            "Epoch [5868/10000], Loss: 258.9784\n",
            "Epoch [5869/10000], Loss: 253.4729\n",
            "Epoch [5870/10000], Loss: 253.4982\n",
            "Epoch [5871/10000], Loss: 267.4909\n",
            "Epoch [5872/10000], Loss: 264.4655\n",
            "Epoch [5873/10000], Loss: 259.8965\n",
            "Epoch [5874/10000], Loss: 253.4715\n",
            "Epoch [5875/10000], Loss: 254.0236\n",
            "Epoch [5876/10000], Loss: 261.3871\n",
            "Epoch [5877/10000], Loss: 261.3370\n",
            "Epoch [5878/10000], Loss: 266.5439\n",
            "Epoch [5879/10000], Loss: 269.3195\n",
            "Epoch [5880/10000], Loss: 258.7589\n",
            "Epoch [5881/10000], Loss: 256.1060\n",
            "Epoch [5882/10000], Loss: 258.8723\n",
            "Epoch [5883/10000], Loss: 279.9389\n",
            "Epoch [5884/10000], Loss: 267.2675\n",
            "Epoch [5885/10000], Loss: 267.0453\n",
            "Epoch [5886/10000], Loss: 252.1233\n",
            "Epoch [5887/10000], Loss: 253.3148\n",
            "Epoch [5888/10000], Loss: 261.5042\n",
            "Epoch [5889/10000], Loss: 260.1781\n",
            "Epoch [5890/10000], Loss: 261.7618\n",
            "Epoch [5891/10000], Loss: 260.1620\n",
            "Epoch [5892/10000], Loss: 263.6628\n",
            "Epoch [5893/10000], Loss: 266.8881\n",
            "Epoch [5894/10000], Loss: 257.6231\n",
            "Epoch [5895/10000], Loss: 252.9375\n",
            "Epoch [5896/10000], Loss: 255.8395\n",
            "Epoch [5897/10000], Loss: 258.9810\n",
            "Epoch [5898/10000], Loss: 258.9152\n",
            "Epoch [5899/10000], Loss: 265.9003\n",
            "Epoch [5900/10000], Loss: 247.1405\n",
            "Epoch [5901/10000], Loss: 261.1344\n",
            "Epoch [5902/10000], Loss: 262.5048\n",
            "Epoch [5903/10000], Loss: 256.4160\n",
            "Epoch [5904/10000], Loss: 268.6130\n",
            "Epoch [5905/10000], Loss: 259.3941\n",
            "Epoch [5906/10000], Loss: 247.5007\n",
            "Epoch [5907/10000], Loss: 253.6660\n",
            "Epoch [5908/10000], Loss: 256.2509\n",
            "Epoch [5909/10000], Loss: 254.8434\n",
            "Epoch [5910/10000], Loss: 266.5060\n",
            "Epoch [5911/10000], Loss: 247.2514\n",
            "Epoch [5912/10000], Loss: 257.4240\n",
            "Epoch [5913/10000], Loss: 255.0135\n",
            "Epoch [5914/10000], Loss: 254.7174\n",
            "Epoch [5915/10000], Loss: 248.1713\n",
            "Epoch [5916/10000], Loss: 243.6831\n",
            "Epoch [5917/10000], Loss: 249.5025\n",
            "Epoch [5918/10000], Loss: 253.1540\n",
            "Epoch [5919/10000], Loss: 255.1316\n",
            "Epoch [5920/10000], Loss: 254.0020\n",
            "Epoch [5921/10000], Loss: 256.8713\n",
            "Epoch [5922/10000], Loss: 250.5324\n",
            "Epoch [5923/10000], Loss: 253.8496\n",
            "Epoch [5924/10000], Loss: 259.0396\n",
            "Epoch [5925/10000], Loss: 249.3188\n",
            "Epoch [5926/10000], Loss: 252.8799\n",
            "Epoch [5927/10000], Loss: 246.8886\n",
            "Epoch [5928/10000], Loss: 251.0248\n",
            "Epoch [5929/10000], Loss: 247.4019\n",
            "Epoch [5930/10000], Loss: 260.3290\n",
            "Epoch [5931/10000], Loss: 252.7078\n",
            "Epoch [5932/10000], Loss: 245.1146\n",
            "Epoch [5933/10000], Loss: 252.4221\n",
            "Epoch [5934/10000], Loss: 244.9657\n",
            "Epoch [5935/10000], Loss: 265.0307\n",
            "Epoch [5936/10000], Loss: 245.8307\n",
            "Epoch [5937/10000], Loss: 241.0730\n",
            "Epoch [5938/10000], Loss: 245.1164\n",
            "Epoch [5939/10000], Loss: 242.1693\n",
            "Epoch [5940/10000], Loss: 250.9232\n",
            "Epoch [5941/10000], Loss: 252.0142\n",
            "Epoch [5942/10000], Loss: 252.6524\n",
            "Epoch [5943/10000], Loss: 247.8920\n",
            "Epoch [5944/10000], Loss: 244.5947\n",
            "Epoch [5945/10000], Loss: 248.1817\n",
            "Epoch [5946/10000], Loss: 247.4121\n",
            "Epoch [5947/10000], Loss: 260.2608\n",
            "Epoch [5948/10000], Loss: 245.3072\n",
            "Epoch [5949/10000], Loss: 249.2122\n",
            "Epoch [5950/10000], Loss: 248.4853\n",
            "Epoch [5951/10000], Loss: 244.7219\n",
            "Epoch [5952/10000], Loss: 255.0870\n",
            "Epoch [5953/10000], Loss: 249.7854\n",
            "Epoch [5954/10000], Loss: 247.9759\n",
            "Epoch [5955/10000], Loss: 241.0448\n",
            "Epoch [5956/10000], Loss: 246.7901\n",
            "Epoch [5957/10000], Loss: 246.8378\n",
            "Epoch [5958/10000], Loss: 251.2327\n",
            "Epoch [5959/10000], Loss: 246.2930\n",
            "Epoch [5960/10000], Loss: 248.6855\n",
            "Epoch [5961/10000], Loss: 249.4939\n",
            "Epoch [5962/10000], Loss: 254.5980\n",
            "Epoch [5963/10000], Loss: 242.9798\n",
            "Epoch [5964/10000], Loss: 246.7945\n",
            "Epoch [5965/10000], Loss: 245.9769\n",
            "Epoch [5966/10000], Loss: 237.5262\n",
            "Epoch [5967/10000], Loss: 241.2429\n",
            "Epoch [5968/10000], Loss: 239.7389\n",
            "Epoch [5969/10000], Loss: 248.0865\n",
            "Epoch [5970/10000], Loss: 244.9580\n",
            "Epoch [5971/10000], Loss: 246.4449\n",
            "Epoch [5972/10000], Loss: 243.5683\n",
            "Epoch [5973/10000], Loss: 249.7706\n",
            "Epoch [5974/10000], Loss: 242.9377\n",
            "Epoch [5975/10000], Loss: 246.8610\n",
            "Epoch [5976/10000], Loss: 248.2883\n",
            "Epoch [5977/10000], Loss: 264.5765\n",
            "Epoch [5978/10000], Loss: 246.7391\n",
            "Epoch [5979/10000], Loss: 238.8362\n",
            "Epoch [5980/10000], Loss: 250.7026\n",
            "Epoch [5981/10000], Loss: 243.4033\n",
            "Epoch [5982/10000], Loss: 247.9810\n",
            "Epoch [5983/10000], Loss: 252.8009\n",
            "Epoch [5984/10000], Loss: 243.1771\n",
            "Epoch [5985/10000], Loss: 244.6246\n",
            "Epoch [5986/10000], Loss: 247.5777\n",
            "Epoch [5987/10000], Loss: 243.9429\n",
            "Epoch [5988/10000], Loss: 257.4500\n",
            "Epoch [5989/10000], Loss: 239.3927\n",
            "Epoch [5990/10000], Loss: 257.4989\n",
            "Epoch [5991/10000], Loss: 245.1856\n",
            "Epoch [5992/10000], Loss: 235.4003\n",
            "Epoch [5993/10000], Loss: 240.5716\n",
            "Epoch [5994/10000], Loss: 243.4250\n",
            "Epoch [5995/10000], Loss: 244.3135\n",
            "Epoch [5996/10000], Loss: 246.6464\n",
            "Epoch [5997/10000], Loss: 239.0255\n",
            "Epoch [5998/10000], Loss: 248.0267\n",
            "Epoch [5999/10000], Loss: 249.5290\n",
            "Epoch [6000/10000], Loss: 241.1825\n",
            "Epoch [6001/10000], Loss: 244.2115\n",
            "Epoch [6002/10000], Loss: 235.2533\n",
            "Epoch [6003/10000], Loss: 252.2064\n",
            "Epoch [6004/10000], Loss: 241.7859\n",
            "Epoch [6005/10000], Loss: 232.1261\n",
            "Epoch [6006/10000], Loss: 244.7800\n",
            "Epoch [6007/10000], Loss: 247.6080\n",
            "Epoch [6008/10000], Loss: 251.1277\n",
            "Epoch [6009/10000], Loss: 243.9281\n",
            "Epoch [6010/10000], Loss: 243.8184\n",
            "Epoch [6011/10000], Loss: 247.5764\n",
            "Epoch [6012/10000], Loss: 238.8482\n",
            "Epoch [6013/10000], Loss: 241.0621\n",
            "Epoch [6014/10000], Loss: 234.4745\n",
            "Epoch [6015/10000], Loss: 238.9844\n",
            "Epoch [6016/10000], Loss: 233.1872\n",
            "Epoch [6017/10000], Loss: 235.0932\n",
            "Epoch [6018/10000], Loss: 250.7461\n",
            "Epoch [6019/10000], Loss: 242.0014\n",
            "Epoch [6020/10000], Loss: 238.4512\n",
            "Epoch [6021/10000], Loss: 237.1693\n",
            "Epoch [6022/10000], Loss: 236.0168\n",
            "Epoch [6023/10000], Loss: 240.9705\n",
            "Epoch [6024/10000], Loss: 240.6927\n",
            "Epoch [6025/10000], Loss: 231.0166\n",
            "Epoch [6026/10000], Loss: 237.4275\n",
            "Epoch [6027/10000], Loss: 230.5857\n",
            "Epoch [6028/10000], Loss: 243.6916\n",
            "Epoch [6029/10000], Loss: 231.2271\n",
            "Epoch [6030/10000], Loss: 241.7361\n",
            "Epoch [6031/10000], Loss: 239.9606\n",
            "Epoch [6032/10000], Loss: 233.7468\n",
            "Epoch [6033/10000], Loss: 243.1803\n",
            "Epoch [6034/10000], Loss: 248.0336\n",
            "Epoch [6035/10000], Loss: 243.5491\n",
            "Epoch [6036/10000], Loss: 243.5160\n",
            "Epoch [6037/10000], Loss: 238.5992\n",
            "Epoch [6038/10000], Loss: 242.7906\n",
            "Epoch [6039/10000], Loss: 238.2020\n",
            "Epoch [6040/10000], Loss: 243.1880\n",
            "Epoch [6041/10000], Loss: 227.1695\n",
            "Epoch [6042/10000], Loss: 242.8630\n",
            "Epoch [6043/10000], Loss: 242.4950\n",
            "Epoch [6044/10000], Loss: 237.2376\n",
            "Epoch [6045/10000], Loss: 237.0514\n",
            "Epoch [6046/10000], Loss: 237.9191\n",
            "Epoch [6047/10000], Loss: 233.7164\n",
            "Epoch [6048/10000], Loss: 240.2640\n",
            "Epoch [6049/10000], Loss: 237.2231\n",
            "Epoch [6050/10000], Loss: 238.3252\n",
            "Epoch [6051/10000], Loss: 234.2716\n",
            "Epoch [6052/10000], Loss: 239.3144\n",
            "Epoch [6053/10000], Loss: 243.2431\n",
            "Epoch [6054/10000], Loss: 234.0391\n",
            "Epoch [6055/10000], Loss: 228.3032\n",
            "Epoch [6056/10000], Loss: 240.1581\n",
            "Epoch [6057/10000], Loss: 236.1628\n",
            "Epoch [6058/10000], Loss: 240.8640\n",
            "Epoch [6059/10000], Loss: 234.7998\n",
            "Epoch [6060/10000], Loss: 231.8330\n",
            "Epoch [6061/10000], Loss: 239.3752\n",
            "Epoch [6062/10000], Loss: 237.3175\n",
            "Epoch [6063/10000], Loss: 221.3764\n",
            "Epoch [6064/10000], Loss: 231.8355\n",
            "Epoch [6065/10000], Loss: 236.4525\n",
            "Epoch [6066/10000], Loss: 232.2109\n",
            "Epoch [6067/10000], Loss: 236.5967\n",
            "Epoch [6068/10000], Loss: 228.5997\n",
            "Epoch [6069/10000], Loss: 232.8230\n",
            "Epoch [6070/10000], Loss: 233.5892\n",
            "Epoch [6071/10000], Loss: 235.2845\n",
            "Epoch [6072/10000], Loss: 234.5816\n",
            "Epoch [6073/10000], Loss: 242.1629\n",
            "Epoch [6074/10000], Loss: 230.7055\n",
            "Epoch [6075/10000], Loss: 224.7040\n",
            "Epoch [6076/10000], Loss: 237.1238\n",
            "Epoch [6077/10000], Loss: 238.3468\n",
            "Epoch [6078/10000], Loss: 238.2073\n",
            "Epoch [6079/10000], Loss: 232.4731\n",
            "Epoch [6080/10000], Loss: 234.2672\n",
            "Epoch [6081/10000], Loss: 232.6346\n",
            "Epoch [6082/10000], Loss: 226.0151\n",
            "Epoch [6083/10000], Loss: 234.2218\n",
            "Epoch [6084/10000], Loss: 237.7490\n",
            "Epoch [6085/10000], Loss: 235.3833\n",
            "Epoch [6086/10000], Loss: 234.4147\n",
            "Epoch [6087/10000], Loss: 234.5420\n",
            "Epoch [6088/10000], Loss: 235.8253\n",
            "Epoch [6089/10000], Loss: 221.6590\n",
            "Epoch [6090/10000], Loss: 230.4235\n",
            "Epoch [6091/10000], Loss: 226.4453\n",
            "Epoch [6092/10000], Loss: 227.1650\n",
            "Epoch [6093/10000], Loss: 220.5797\n",
            "Epoch [6094/10000], Loss: 224.8547\n",
            "Epoch [6095/10000], Loss: 233.6056\n",
            "Epoch [6096/10000], Loss: 231.6992\n",
            "Epoch [6097/10000], Loss: 225.8237\n",
            "Epoch [6098/10000], Loss: 221.6447\n",
            "Epoch [6099/10000], Loss: 235.1095\n",
            "Epoch [6100/10000], Loss: 224.9129\n",
            "Epoch [6101/10000], Loss: 229.0158\n",
            "Epoch [6102/10000], Loss: 230.5762\n",
            "Epoch [6103/10000], Loss: 234.0458\n",
            "Epoch [6104/10000], Loss: 223.9552\n",
            "Epoch [6105/10000], Loss: 228.3886\n",
            "Epoch [6106/10000], Loss: 229.2942\n",
            "Epoch [6107/10000], Loss: 223.6490\n",
            "Epoch [6108/10000], Loss: 228.4993\n",
            "Epoch [6109/10000], Loss: 233.7129\n",
            "Epoch [6110/10000], Loss: 225.9747\n",
            "Epoch [6111/10000], Loss: 222.0151\n",
            "Epoch [6112/10000], Loss: 229.9376\n",
            "Epoch [6113/10000], Loss: 232.8571\n",
            "Epoch [6114/10000], Loss: 225.1917\n",
            "Epoch [6115/10000], Loss: 233.0482\n",
            "Epoch [6116/10000], Loss: 228.1048\n",
            "Epoch [6117/10000], Loss: 222.5371\n",
            "Epoch [6118/10000], Loss: 231.9215\n",
            "Epoch [6119/10000], Loss: 228.0890\n",
            "Epoch [6120/10000], Loss: 227.6585\n",
            "Epoch [6121/10000], Loss: 228.6233\n",
            "Epoch [6122/10000], Loss: 230.8498\n",
            "Epoch [6123/10000], Loss: 220.8082\n",
            "Epoch [6124/10000], Loss: 228.8863\n",
            "Epoch [6125/10000], Loss: 233.5648\n",
            "Epoch [6126/10000], Loss: 227.3522\n",
            "Epoch [6127/10000], Loss: 226.8670\n",
            "Epoch [6128/10000], Loss: 221.6856\n",
            "Epoch [6129/10000], Loss: 226.3140\n",
            "Epoch [6130/10000], Loss: 230.5592\n",
            "Epoch [6131/10000], Loss: 225.9231\n",
            "Epoch [6132/10000], Loss: 227.8260\n",
            "Epoch [6133/10000], Loss: 223.8313\n",
            "Epoch [6134/10000], Loss: 219.3793\n",
            "Epoch [6135/10000], Loss: 225.1788\n",
            "Epoch [6136/10000], Loss: 223.5069\n",
            "Epoch [6137/10000], Loss: 220.3142\n",
            "Epoch [6138/10000], Loss: 220.8812\n",
            "Epoch [6139/10000], Loss: 232.7100\n",
            "Epoch [6140/10000], Loss: 227.6941\n",
            "Epoch [6141/10000], Loss: 220.3250\n",
            "Epoch [6142/10000], Loss: 228.4414\n",
            "Epoch [6143/10000], Loss: 226.9912\n",
            "Epoch [6144/10000], Loss: 219.4707\n",
            "Epoch [6145/10000], Loss: 232.2468\n",
            "Epoch [6146/10000], Loss: 227.4773\n",
            "Epoch [6147/10000], Loss: 226.2153\n",
            "Epoch [6148/10000], Loss: 226.2501\n",
            "Epoch [6149/10000], Loss: 229.6165\n",
            "Epoch [6150/10000], Loss: 216.0970\n",
            "Epoch [6151/10000], Loss: 231.2736\n",
            "Epoch [6152/10000], Loss: 225.4593\n",
            "Epoch [6153/10000], Loss: 221.6252\n",
            "Epoch [6154/10000], Loss: 219.9168\n",
            "Epoch [6155/10000], Loss: 228.8089\n",
            "Epoch [6156/10000], Loss: 227.0241\n",
            "Epoch [6157/10000], Loss: 222.5306\n",
            "Epoch [6158/10000], Loss: 229.6358\n",
            "Epoch [6159/10000], Loss: 224.5259\n",
            "Epoch [6160/10000], Loss: 233.1315\n",
            "Epoch [6161/10000], Loss: 237.6647\n",
            "Epoch [6162/10000], Loss: 223.5066\n",
            "Epoch [6163/10000], Loss: 222.1347\n",
            "Epoch [6164/10000], Loss: 222.3904\n",
            "Epoch [6165/10000], Loss: 229.2107\n",
            "Epoch [6166/10000], Loss: 219.7429\n",
            "Epoch [6167/10000], Loss: 219.4818\n",
            "Epoch [6168/10000], Loss: 222.9954\n",
            "Epoch [6169/10000], Loss: 219.4044\n",
            "Epoch [6170/10000], Loss: 222.9901\n",
            "Epoch [6171/10000], Loss: 221.2384\n",
            "Epoch [6172/10000], Loss: 229.3935\n",
            "Epoch [6173/10000], Loss: 224.4467\n",
            "Epoch [6174/10000], Loss: 230.4548\n",
            "Epoch [6175/10000], Loss: 230.4308\n",
            "Epoch [6176/10000], Loss: 225.1921\n",
            "Epoch [6177/10000], Loss: 220.2187\n",
            "Epoch [6178/10000], Loss: 223.8857\n",
            "Epoch [6179/10000], Loss: 218.6416\n",
            "Epoch [6180/10000], Loss: 220.8815\n",
            "Epoch [6181/10000], Loss: 217.2843\n",
            "Epoch [6182/10000], Loss: 221.1719\n",
            "Epoch [6183/10000], Loss: 218.7147\n",
            "Epoch [6184/10000], Loss: 225.3400\n",
            "Epoch [6185/10000], Loss: 228.7837\n",
            "Epoch [6186/10000], Loss: 223.9854\n",
            "Epoch [6187/10000], Loss: 223.0734\n",
            "Epoch [6188/10000], Loss: 215.1406\n",
            "Epoch [6189/10000], Loss: 223.9964\n",
            "Epoch [6190/10000], Loss: 219.6772\n",
            "Epoch [6191/10000], Loss: 231.1592\n",
            "Epoch [6192/10000], Loss: 221.9160\n",
            "Epoch [6193/10000], Loss: 224.4473\n",
            "Epoch [6194/10000], Loss: 217.8395\n",
            "Epoch [6195/10000], Loss: 227.7428\n",
            "Epoch [6196/10000], Loss: 219.9658\n",
            "Epoch [6197/10000], Loss: 215.5506\n",
            "Epoch [6198/10000], Loss: 210.9595\n",
            "Epoch [6199/10000], Loss: 219.8162\n",
            "Epoch [6200/10000], Loss: 212.2649\n",
            "Epoch [6201/10000], Loss: 221.4227\n",
            "Epoch [6202/10000], Loss: 222.3831\n",
            "Epoch [6203/10000], Loss: 216.8472\n",
            "Epoch [6204/10000], Loss: 218.8861\n",
            "Epoch [6205/10000], Loss: 222.3260\n",
            "Epoch [6206/10000], Loss: 222.4307\n",
            "Epoch [6207/10000], Loss: 221.8243\n",
            "Epoch [6208/10000], Loss: 216.9384\n",
            "Epoch [6209/10000], Loss: 219.7757\n",
            "Epoch [6210/10000], Loss: 225.3660\n",
            "Epoch [6211/10000], Loss: 208.5834\n",
            "Epoch [6212/10000], Loss: 221.4336\n",
            "Epoch [6213/10000], Loss: 217.2317\n",
            "Epoch [6214/10000], Loss: 208.5456\n",
            "Epoch [6215/10000], Loss: 220.6792\n",
            "Epoch [6216/10000], Loss: 216.8496\n",
            "Epoch [6217/10000], Loss: 214.7940\n",
            "Epoch [6218/10000], Loss: 219.6152\n",
            "Epoch [6219/10000], Loss: 213.9555\n",
            "Epoch [6220/10000], Loss: 215.2104\n",
            "Epoch [6221/10000], Loss: 224.0507\n",
            "Epoch [6222/10000], Loss: 211.3079\n",
            "Epoch [6223/10000], Loss: 217.5179\n",
            "Epoch [6224/10000], Loss: 209.4388\n",
            "Epoch [6225/10000], Loss: 219.3648\n",
            "Epoch [6226/10000], Loss: 210.7450\n",
            "Epoch [6227/10000], Loss: 224.5906\n",
            "Epoch [6228/10000], Loss: 210.3133\n",
            "Epoch [6229/10000], Loss: 209.4778\n",
            "Epoch [6230/10000], Loss: 217.2780\n",
            "Epoch [6231/10000], Loss: 221.3370\n",
            "Epoch [6232/10000], Loss: 212.5813\n",
            "Epoch [6233/10000], Loss: 210.4420\n",
            "Epoch [6234/10000], Loss: 217.1168\n",
            "Epoch [6235/10000], Loss: 216.5536\n",
            "Epoch [6236/10000], Loss: 213.1360\n",
            "Epoch [6237/10000], Loss: 209.0466\n",
            "Epoch [6238/10000], Loss: 217.2137\n",
            "Epoch [6239/10000], Loss: 212.5813\n",
            "Epoch [6240/10000], Loss: 219.3627\n",
            "Epoch [6241/10000], Loss: 217.9667\n",
            "Epoch [6242/10000], Loss: 212.5995\n",
            "Epoch [6243/10000], Loss: 223.0345\n",
            "Epoch [6244/10000], Loss: 219.0921\n",
            "Epoch [6245/10000], Loss: 215.0740\n",
            "Epoch [6246/10000], Loss: 213.1566\n",
            "Epoch [6247/10000], Loss: 206.9231\n",
            "Epoch [6248/10000], Loss: 228.7709\n",
            "Epoch [6249/10000], Loss: 211.6160\n",
            "Epoch [6250/10000], Loss: 207.0813\n",
            "Epoch [6251/10000], Loss: 211.3946\n",
            "Epoch [6252/10000], Loss: 211.4768\n",
            "Epoch [6253/10000], Loss: 213.2550\n",
            "Epoch [6254/10000], Loss: 221.5001\n",
            "Epoch [6255/10000], Loss: 216.4222\n",
            "Epoch [6256/10000], Loss: 215.1627\n",
            "Epoch [6257/10000], Loss: 218.2831\n",
            "Epoch [6258/10000], Loss: 212.2341\n",
            "Epoch [6259/10000], Loss: 214.5850\n",
            "Epoch [6260/10000], Loss: 220.4982\n",
            "Epoch [6261/10000], Loss: 214.5895\n",
            "Epoch [6262/10000], Loss: 207.8347\n",
            "Epoch [6263/10000], Loss: 214.0643\n",
            "Epoch [6264/10000], Loss: 209.1252\n",
            "Epoch [6265/10000], Loss: 208.0351\n",
            "Epoch [6266/10000], Loss: 212.6596\n",
            "Epoch [6267/10000], Loss: 213.3928\n",
            "Epoch [6268/10000], Loss: 208.2596\n",
            "Epoch [6269/10000], Loss: 214.0642\n",
            "Epoch [6270/10000], Loss: 210.4093\n",
            "Epoch [6271/10000], Loss: 206.2535\n",
            "Epoch [6272/10000], Loss: 217.4621\n",
            "Epoch [6273/10000], Loss: 211.8963\n",
            "Epoch [6274/10000], Loss: 216.8881\n",
            "Epoch [6275/10000], Loss: 208.1237\n",
            "Epoch [6276/10000], Loss: 213.4664\n",
            "Epoch [6277/10000], Loss: 219.7800\n",
            "Epoch [6278/10000], Loss: 217.7316\n",
            "Epoch [6279/10000], Loss: 214.4031\n",
            "Epoch [6280/10000], Loss: 200.1936\n",
            "Epoch [6281/10000], Loss: 211.9711\n",
            "Epoch [6282/10000], Loss: 207.4101\n",
            "Epoch [6283/10000], Loss: 219.2572\n",
            "Epoch [6284/10000], Loss: 213.3857\n",
            "Epoch [6285/10000], Loss: 214.7167\n",
            "Epoch [6286/10000], Loss: 213.4748\n",
            "Epoch [6287/10000], Loss: 213.6036\n",
            "Epoch [6288/10000], Loss: 211.9272\n",
            "Epoch [6289/10000], Loss: 201.4585\n",
            "Epoch [6290/10000], Loss: 219.8378\n",
            "Epoch [6291/10000], Loss: 218.6898\n",
            "Epoch [6292/10000], Loss: 196.8631\n",
            "Epoch [6293/10000], Loss: 207.7846\n",
            "Epoch [6294/10000], Loss: 203.8405\n",
            "Epoch [6295/10000], Loss: 206.2379\n",
            "Epoch [6296/10000], Loss: 209.9590\n",
            "Epoch [6297/10000], Loss: 202.8553\n",
            "Epoch [6298/10000], Loss: 211.2211\n",
            "Epoch [6299/10000], Loss: 206.9393\n",
            "Epoch [6300/10000], Loss: 202.4727\n",
            "Epoch [6301/10000], Loss: 213.7599\n",
            "Epoch [6302/10000], Loss: 208.5922\n",
            "Epoch [6303/10000], Loss: 213.6814\n",
            "Epoch [6304/10000], Loss: 209.8794\n",
            "Epoch [6305/10000], Loss: 209.7807\n",
            "Epoch [6306/10000], Loss: 202.6034\n",
            "Epoch [6307/10000], Loss: 200.4997\n",
            "Epoch [6308/10000], Loss: 200.6749\n",
            "Epoch [6309/10000], Loss: 212.0813\n",
            "Epoch [6310/10000], Loss: 200.8073\n",
            "Epoch [6311/10000], Loss: 204.5324\n",
            "Epoch [6312/10000], Loss: 204.2788\n",
            "Epoch [6313/10000], Loss: 204.5394\n",
            "Epoch [6314/10000], Loss: 209.1555\n",
            "Epoch [6315/10000], Loss: 207.4706\n",
            "Epoch [6316/10000], Loss: 205.9752\n",
            "Epoch [6317/10000], Loss: 200.9310\n",
            "Epoch [6318/10000], Loss: 209.0509\n",
            "Epoch [6319/10000], Loss: 204.2146\n",
            "Epoch [6320/10000], Loss: 205.1454\n",
            "Epoch [6321/10000], Loss: 208.6376\n",
            "Epoch [6322/10000], Loss: 213.2182\n",
            "Epoch [6323/10000], Loss: 215.6175\n",
            "Epoch [6324/10000], Loss: 206.5588\n",
            "Epoch [6325/10000], Loss: 208.2341\n",
            "Epoch [6326/10000], Loss: 201.9689\n",
            "Epoch [6327/10000], Loss: 196.4231\n",
            "Epoch [6328/10000], Loss: 212.1981\n",
            "Epoch [6329/10000], Loss: 208.6720\n",
            "Epoch [6330/10000], Loss: 205.1107\n",
            "Epoch [6331/10000], Loss: 210.6192\n",
            "Epoch [6332/10000], Loss: 210.4551\n",
            "Epoch [6333/10000], Loss: 200.2857\n",
            "Epoch [6334/10000], Loss: 202.7491\n",
            "Epoch [6335/10000], Loss: 202.3481\n",
            "Epoch [6336/10000], Loss: 201.9671\n",
            "Epoch [6337/10000], Loss: 207.6486\n",
            "Epoch [6338/10000], Loss: 211.8391\n",
            "Epoch [6339/10000], Loss: 215.8976\n",
            "Epoch [6340/10000], Loss: 203.1584\n",
            "Epoch [6341/10000], Loss: 209.6190\n",
            "Epoch [6342/10000], Loss: 205.9950\n",
            "Epoch [6343/10000], Loss: 202.3683\n",
            "Epoch [6344/10000], Loss: 199.9555\n",
            "Epoch [6345/10000], Loss: 203.2461\n",
            "Epoch [6346/10000], Loss: 206.3761\n",
            "Epoch [6347/10000], Loss: 213.8885\n",
            "Epoch [6348/10000], Loss: 198.3908\n",
            "Epoch [6349/10000], Loss: 209.4145\n",
            "Epoch [6350/10000], Loss: 197.1045\n",
            "Epoch [6351/10000], Loss: 198.1365\n",
            "Epoch [6352/10000], Loss: 203.0003\n",
            "Epoch [6353/10000], Loss: 206.3922\n",
            "Epoch [6354/10000], Loss: 203.7658\n",
            "Epoch [6355/10000], Loss: 205.3322\n",
            "Epoch [6356/10000], Loss: 200.5471\n",
            "Epoch [6357/10000], Loss: 194.3035\n",
            "Epoch [6358/10000], Loss: 209.8107\n",
            "Epoch [6359/10000], Loss: 200.8355\n",
            "Epoch [6360/10000], Loss: 200.7050\n",
            "Epoch [6361/10000], Loss: 199.4259\n",
            "Epoch [6362/10000], Loss: 198.2191\n",
            "Epoch [6363/10000], Loss: 206.8099\n",
            "Epoch [6364/10000], Loss: 212.5460\n",
            "Epoch [6365/10000], Loss: 204.4977\n",
            "Epoch [6366/10000], Loss: 193.8071\n",
            "Epoch [6367/10000], Loss: 203.1584\n",
            "Epoch [6368/10000], Loss: 191.0030\n",
            "Epoch [6369/10000], Loss: 199.2427\n",
            "Epoch [6370/10000], Loss: 207.4926\n",
            "Epoch [6371/10000], Loss: 209.7801\n",
            "Epoch [6372/10000], Loss: 199.6768\n",
            "Epoch [6373/10000], Loss: 203.0791\n",
            "Epoch [6374/10000], Loss: 199.8073\n",
            "Epoch [6375/10000], Loss: 201.9735\n",
            "Epoch [6376/10000], Loss: 198.1799\n",
            "Epoch [6377/10000], Loss: 205.1599\n",
            "Epoch [6378/10000], Loss: 206.2798\n",
            "Epoch [6379/10000], Loss: 207.6341\n",
            "Epoch [6380/10000], Loss: 194.8125\n",
            "Epoch [6381/10000], Loss: 204.7503\n",
            "Epoch [6382/10000], Loss: 210.1567\n",
            "Epoch [6383/10000], Loss: 199.0466\n",
            "Epoch [6384/10000], Loss: 198.4348\n",
            "Epoch [6385/10000], Loss: 205.8003\n",
            "Epoch [6386/10000], Loss: 198.1698\n",
            "Epoch [6387/10000], Loss: 207.5471\n",
            "Epoch [6388/10000], Loss: 196.7709\n",
            "Epoch [6389/10000], Loss: 201.8869\n",
            "Epoch [6390/10000], Loss: 205.1758\n",
            "Epoch [6391/10000], Loss: 197.3184\n",
            "Epoch [6392/10000], Loss: 200.6640\n",
            "Epoch [6393/10000], Loss: 201.6817\n",
            "Epoch [6394/10000], Loss: 203.4281\n",
            "Epoch [6395/10000], Loss: 206.1434\n",
            "Epoch [6396/10000], Loss: 199.8816\n",
            "Epoch [6397/10000], Loss: 198.5596\n",
            "Epoch [6398/10000], Loss: 201.4963\n",
            "Epoch [6399/10000], Loss: 201.0800\n",
            "Epoch [6400/10000], Loss: 206.9226\n",
            "Epoch [6401/10000], Loss: 197.4986\n",
            "Epoch [6402/10000], Loss: 200.0209\n",
            "Epoch [6403/10000], Loss: 196.9755\n",
            "Epoch [6404/10000], Loss: 200.5966\n",
            "Epoch [6405/10000], Loss: 208.0303\n",
            "Epoch [6406/10000], Loss: 191.2301\n",
            "Epoch [6407/10000], Loss: 194.3143\n",
            "Epoch [6408/10000], Loss: 198.9615\n",
            "Epoch [6409/10000], Loss: 200.0793\n",
            "Epoch [6410/10000], Loss: 196.5820\n",
            "Epoch [6411/10000], Loss: 195.4393\n",
            "Epoch [6412/10000], Loss: 199.1951\n",
            "Epoch [6413/10000], Loss: 197.0764\n",
            "Epoch [6414/10000], Loss: 201.5873\n",
            "Epoch [6415/10000], Loss: 188.9688\n",
            "Epoch [6416/10000], Loss: 193.8660\n",
            "Epoch [6417/10000], Loss: 194.4118\n",
            "Epoch [6418/10000], Loss: 198.6987\n",
            "Epoch [6419/10000], Loss: 190.1206\n",
            "Epoch [6420/10000], Loss: 194.6590\n",
            "Epoch [6421/10000], Loss: 194.8228\n",
            "Epoch [6422/10000], Loss: 195.4749\n",
            "Epoch [6423/10000], Loss: 196.8090\n",
            "Epoch [6424/10000], Loss: 196.0635\n",
            "Epoch [6425/10000], Loss: 198.7223\n",
            "Epoch [6426/10000], Loss: 200.2271\n",
            "Epoch [6427/10000], Loss: 199.9967\n",
            "Epoch [6428/10000], Loss: 187.5538\n",
            "Epoch [6429/10000], Loss: 205.1739\n",
            "Epoch [6430/10000], Loss: 198.0000\n",
            "Epoch [6431/10000], Loss: 200.7512\n",
            "Epoch [6432/10000], Loss: 194.9437\n",
            "Epoch [6433/10000], Loss: 188.5334\n",
            "Epoch [6434/10000], Loss: 203.4573\n",
            "Epoch [6435/10000], Loss: 203.5764\n",
            "Epoch [6436/10000], Loss: 194.4294\n",
            "Epoch [6437/10000], Loss: 197.4329\n",
            "Epoch [6438/10000], Loss: 184.6494\n",
            "Epoch [6439/10000], Loss: 203.8350\n",
            "Epoch [6440/10000], Loss: 195.2078\n",
            "Epoch [6441/10000], Loss: 193.7227\n",
            "Epoch [6442/10000], Loss: 204.5283\n",
            "Epoch [6443/10000], Loss: 200.7540\n",
            "Epoch [6444/10000], Loss: 201.4646\n",
            "Epoch [6445/10000], Loss: 188.0828\n",
            "Epoch [6446/10000], Loss: 186.2085\n",
            "Epoch [6447/10000], Loss: 193.9061\n",
            "Epoch [6448/10000], Loss: 200.0757\n",
            "Epoch [6449/10000], Loss: 198.5447\n",
            "Epoch [6450/10000], Loss: 190.4569\n",
            "Epoch [6451/10000], Loss: 192.1167\n",
            "Epoch [6452/10000], Loss: 201.5854\n",
            "Epoch [6453/10000], Loss: 196.4053\n",
            "Epoch [6454/10000], Loss: 199.3871\n",
            "Epoch [6455/10000], Loss: 199.1564\n",
            "Epoch [6456/10000], Loss: 197.3553\n",
            "Epoch [6457/10000], Loss: 194.2115\n",
            "Epoch [6458/10000], Loss: 195.3788\n",
            "Epoch [6459/10000], Loss: 197.6138\n",
            "Epoch [6460/10000], Loss: 196.4608\n",
            "Epoch [6461/10000], Loss: 192.6300\n",
            "Epoch [6462/10000], Loss: 193.2399\n",
            "Epoch [6463/10000], Loss: 206.2240\n",
            "Epoch [6464/10000], Loss: 193.1055\n",
            "Epoch [6465/10000], Loss: 188.6339\n",
            "Epoch [6466/10000], Loss: 188.1604\n",
            "Epoch [6467/10000], Loss: 191.3654\n",
            "Epoch [6468/10000], Loss: 196.3323\n",
            "Epoch [6469/10000], Loss: 194.3430\n",
            "Epoch [6470/10000], Loss: 192.9477\n",
            "Epoch [6471/10000], Loss: 199.2573\n",
            "Epoch [6472/10000], Loss: 193.9954\n",
            "Epoch [6473/10000], Loss: 193.5924\n",
            "Epoch [6474/10000], Loss: 189.7342\n",
            "Epoch [6475/10000], Loss: 192.4198\n",
            "Epoch [6476/10000], Loss: 185.1961\n",
            "Epoch [6477/10000], Loss: 190.8763\n",
            "Epoch [6478/10000], Loss: 187.4729\n",
            "Epoch [6479/10000], Loss: 192.7147\n",
            "Epoch [6480/10000], Loss: 196.1046\n",
            "Epoch [6481/10000], Loss: 196.8768\n",
            "Epoch [6482/10000], Loss: 196.2092\n",
            "Epoch [6483/10000], Loss: 185.0506\n",
            "Epoch [6484/10000], Loss: 193.5385\n",
            "Epoch [6485/10000], Loss: 195.1690\n",
            "Epoch [6486/10000], Loss: 192.3613\n",
            "Epoch [6487/10000], Loss: 193.0713\n",
            "Epoch [6488/10000], Loss: 189.2885\n",
            "Epoch [6489/10000], Loss: 190.1215\n",
            "Epoch [6490/10000], Loss: 184.8338\n",
            "Epoch [6491/10000], Loss: 194.7851\n",
            "Epoch [6492/10000], Loss: 199.3618\n",
            "Epoch [6493/10000], Loss: 188.7845\n",
            "Epoch [6494/10000], Loss: 195.8222\n",
            "Epoch [6495/10000], Loss: 185.2272\n",
            "Epoch [6496/10000], Loss: 194.7096\n",
            "Epoch [6497/10000], Loss: 184.3240\n",
            "Epoch [6498/10000], Loss: 195.0144\n",
            "Epoch [6499/10000], Loss: 191.3914\n",
            "Epoch [6500/10000], Loss: 194.1146\n",
            "Epoch [6501/10000], Loss: 188.9890\n",
            "Epoch [6502/10000], Loss: 179.6955\n",
            "Epoch [6503/10000], Loss: 193.7279\n",
            "Epoch [6504/10000], Loss: 198.2870\n",
            "Epoch [6505/10000], Loss: 196.3607\n",
            "Epoch [6506/10000], Loss: 189.3441\n",
            "Epoch [6507/10000], Loss: 192.8829\n",
            "Epoch [6508/10000], Loss: 181.7394\n",
            "Epoch [6509/10000], Loss: 189.1767\n",
            "Epoch [6510/10000], Loss: 190.9525\n",
            "Epoch [6511/10000], Loss: 187.6331\n",
            "Epoch [6512/10000], Loss: 189.2802\n",
            "Epoch [6513/10000], Loss: 192.7466\n",
            "Epoch [6514/10000], Loss: 190.7525\n",
            "Epoch [6515/10000], Loss: 186.9032\n",
            "Epoch [6516/10000], Loss: 184.2672\n",
            "Epoch [6517/10000], Loss: 189.8389\n",
            "Epoch [6518/10000], Loss: 188.9965\n",
            "Epoch [6519/10000], Loss: 184.7092\n",
            "Epoch [6520/10000], Loss: 186.3670\n",
            "Epoch [6521/10000], Loss: 189.9111\n",
            "Epoch [6522/10000], Loss: 194.5780\n",
            "Epoch [6523/10000], Loss: 190.1506\n",
            "Epoch [6524/10000], Loss: 194.2308\n",
            "Epoch [6525/10000], Loss: 179.8109\n",
            "Epoch [6526/10000], Loss: 185.9155\n",
            "Epoch [6527/10000], Loss: 186.1817\n",
            "Epoch [6528/10000], Loss: 193.0695\n",
            "Epoch [6529/10000], Loss: 190.9468\n",
            "Epoch [6530/10000], Loss: 192.6738\n",
            "Epoch [6531/10000], Loss: 185.1151\n",
            "Epoch [6532/10000], Loss: 197.0895\n",
            "Epoch [6533/10000], Loss: 183.1380\n",
            "Epoch [6534/10000], Loss: 191.2168\n",
            "Epoch [6535/10000], Loss: 182.6018\n",
            "Epoch [6536/10000], Loss: 189.2611\n",
            "Epoch [6537/10000], Loss: 184.0204\n",
            "Epoch [6538/10000], Loss: 202.0386\n",
            "Epoch [6539/10000], Loss: 188.4365\n",
            "Epoch [6540/10000], Loss: 188.8916\n",
            "Epoch [6541/10000], Loss: 181.7052\n",
            "Epoch [6542/10000], Loss: 193.6061\n",
            "Epoch [6543/10000], Loss: 184.3870\n",
            "Epoch [6544/10000], Loss: 192.7784\n",
            "Epoch [6545/10000], Loss: 185.6830\n",
            "Epoch [6546/10000], Loss: 187.6154\n",
            "Epoch [6547/10000], Loss: 183.0450\n",
            "Epoch [6548/10000], Loss: 178.0332\n",
            "Epoch [6549/10000], Loss: 183.3250\n",
            "Epoch [6550/10000], Loss: 190.4850\n",
            "Epoch [6551/10000], Loss: 186.2832\n",
            "Epoch [6552/10000], Loss: 191.8540\n",
            "Epoch [6553/10000], Loss: 184.8060\n",
            "Epoch [6554/10000], Loss: 189.0051\n",
            "Epoch [6555/10000], Loss: 183.8959\n",
            "Epoch [6556/10000], Loss: 182.9711\n",
            "Epoch [6557/10000], Loss: 181.4903\n",
            "Epoch [6558/10000], Loss: 185.3973\n",
            "Epoch [6559/10000], Loss: 182.5987\n",
            "Epoch [6560/10000], Loss: 186.9212\n",
            "Epoch [6561/10000], Loss: 187.4161\n",
            "Epoch [6562/10000], Loss: 177.6987\n",
            "Epoch [6563/10000], Loss: 185.6967\n",
            "Epoch [6564/10000], Loss: 189.9666\n",
            "Epoch [6565/10000], Loss: 188.3057\n",
            "Epoch [6566/10000], Loss: 181.9260\n",
            "Epoch [6567/10000], Loss: 185.8327\n",
            "Epoch [6568/10000], Loss: 184.6732\n",
            "Epoch [6569/10000], Loss: 186.8872\n",
            "Epoch [6570/10000], Loss: 182.2250\n",
            "Epoch [6571/10000], Loss: 179.8740\n",
            "Epoch [6572/10000], Loss: 184.5789\n",
            "Epoch [6573/10000], Loss: 184.2428\n",
            "Epoch [6574/10000], Loss: 188.0103\n",
            "Epoch [6575/10000], Loss: 186.2534\n",
            "Epoch [6576/10000], Loss: 182.9820\n",
            "Epoch [6577/10000], Loss: 189.3254\n",
            "Epoch [6578/10000], Loss: 183.6651\n",
            "Epoch [6579/10000], Loss: 190.5635\n",
            "Epoch [6580/10000], Loss: 193.6237\n",
            "Epoch [6581/10000], Loss: 179.8061\n",
            "Epoch [6582/10000], Loss: 183.8976\n",
            "Epoch [6583/10000], Loss: 190.8852\n",
            "Epoch [6584/10000], Loss: 184.8060\n",
            "Epoch [6585/10000], Loss: 173.2294\n",
            "Epoch [6586/10000], Loss: 191.9077\n",
            "Epoch [6587/10000], Loss: 179.8117\n",
            "Epoch [6588/10000], Loss: 180.0753\n",
            "Epoch [6589/10000], Loss: 180.8699\n",
            "Epoch [6590/10000], Loss: 187.8400\n",
            "Epoch [6591/10000], Loss: 179.0069\n",
            "Epoch [6592/10000], Loss: 182.4137\n",
            "Epoch [6593/10000], Loss: 180.4563\n",
            "Epoch [6594/10000], Loss: 188.2400\n",
            "Epoch [6595/10000], Loss: 177.1790\n",
            "Epoch [6596/10000], Loss: 190.4729\n",
            "Epoch [6597/10000], Loss: 180.6130\n",
            "Epoch [6598/10000], Loss: 175.8469\n",
            "Epoch [6599/10000], Loss: 191.6371\n",
            "Epoch [6600/10000], Loss: 186.3288\n",
            "Epoch [6601/10000], Loss: 180.5913\n",
            "Epoch [6602/10000], Loss: 176.9327\n",
            "Epoch [6603/10000], Loss: 181.8778\n",
            "Epoch [6604/10000], Loss: 184.7714\n",
            "Epoch [6605/10000], Loss: 172.5947\n",
            "Epoch [6606/10000], Loss: 185.5862\n",
            "Epoch [6607/10000], Loss: 175.2130\n",
            "Epoch [6608/10000], Loss: 184.0840\n",
            "Epoch [6609/10000], Loss: 186.0247\n",
            "Epoch [6610/10000], Loss: 188.8304\n",
            "Epoch [6611/10000], Loss: 177.0850\n",
            "Epoch [6612/10000], Loss: 177.7918\n",
            "Epoch [6613/10000], Loss: 176.5231\n",
            "Epoch [6614/10000], Loss: 176.2607\n",
            "Epoch [6615/10000], Loss: 169.8091\n",
            "Epoch [6616/10000], Loss: 179.4566\n",
            "Epoch [6617/10000], Loss: 182.2776\n",
            "Epoch [6618/10000], Loss: 184.9039\n",
            "Epoch [6619/10000], Loss: 177.2227\n",
            "Epoch [6620/10000], Loss: 179.3112\n",
            "Epoch [6621/10000], Loss: 178.0843\n",
            "Epoch [6622/10000], Loss: 172.2588\n",
            "Epoch [6623/10000], Loss: 180.4620\n",
            "Epoch [6624/10000], Loss: 189.8083\n",
            "Epoch [6625/10000], Loss: 186.5906\n",
            "Epoch [6626/10000], Loss: 183.3249\n",
            "Epoch [6627/10000], Loss: 171.6028\n",
            "Epoch [6628/10000], Loss: 178.9880\n",
            "Epoch [6629/10000], Loss: 177.5363\n",
            "Epoch [6630/10000], Loss: 188.2440\n",
            "Epoch [6631/10000], Loss: 177.8661\n",
            "Epoch [6632/10000], Loss: 183.2918\n",
            "Epoch [6633/10000], Loss: 182.5886\n",
            "Epoch [6634/10000], Loss: 178.0305\n",
            "Epoch [6635/10000], Loss: 172.1368\n",
            "Epoch [6636/10000], Loss: 185.6152\n",
            "Epoch [6637/10000], Loss: 182.9799\n",
            "Epoch [6638/10000], Loss: 189.7035\n",
            "Epoch [6639/10000], Loss: 170.7949\n",
            "Epoch [6640/10000], Loss: 176.0022\n",
            "Epoch [6641/10000], Loss: 170.0286\n",
            "Epoch [6642/10000], Loss: 177.9973\n",
            "Epoch [6643/10000], Loss: 173.8056\n",
            "Epoch [6644/10000], Loss: 179.2376\n",
            "Epoch [6645/10000], Loss: 188.0578\n",
            "Epoch [6646/10000], Loss: 173.2663\n",
            "Epoch [6647/10000], Loss: 180.3706\n",
            "Epoch [6648/10000], Loss: 176.2010\n",
            "Epoch [6649/10000], Loss: 176.4234\n",
            "Epoch [6650/10000], Loss: 175.0558\n",
            "Epoch [6651/10000], Loss: 174.2738\n",
            "Epoch [6652/10000], Loss: 169.8887\n",
            "Epoch [6653/10000], Loss: 173.0458\n",
            "Epoch [6654/10000], Loss: 182.5290\n",
            "Epoch [6655/10000], Loss: 170.4016\n",
            "Epoch [6656/10000], Loss: 179.4620\n",
            "Epoch [6657/10000], Loss: 176.3237\n",
            "Epoch [6658/10000], Loss: 175.5157\n",
            "Epoch [6659/10000], Loss: 182.3312\n",
            "Epoch [6660/10000], Loss: 175.6870\n",
            "Epoch [6661/10000], Loss: 182.6193\n",
            "Epoch [6662/10000], Loss: 167.6804\n",
            "Epoch [6663/10000], Loss: 177.5479\n",
            "Epoch [6664/10000], Loss: 180.1641\n",
            "Epoch [6665/10000], Loss: 175.8472\n",
            "Epoch [6666/10000], Loss: 184.9034\n",
            "Epoch [6667/10000], Loss: 185.6411\n",
            "Epoch [6668/10000], Loss: 183.3059\n",
            "Epoch [6669/10000], Loss: 177.1431\n",
            "Epoch [6670/10000], Loss: 176.8662\n",
            "Epoch [6671/10000], Loss: 181.2980\n",
            "Epoch [6672/10000], Loss: 173.9243\n",
            "Epoch [6673/10000], Loss: 167.7534\n",
            "Epoch [6674/10000], Loss: 181.7909\n",
            "Epoch [6675/10000], Loss: 176.6684\n",
            "Epoch [6676/10000], Loss: 171.2723\n",
            "Epoch [6677/10000], Loss: 179.5700\n",
            "Epoch [6678/10000], Loss: 177.0198\n",
            "Epoch [6679/10000], Loss: 174.6531\n",
            "Epoch [6680/10000], Loss: 180.2298\n",
            "Epoch [6681/10000], Loss: 183.7076\n",
            "Epoch [6682/10000], Loss: 174.3374\n",
            "Epoch [6683/10000], Loss: 171.0474\n",
            "Epoch [6684/10000], Loss: 178.9608\n",
            "Epoch [6685/10000], Loss: 178.8664\n",
            "Epoch [6686/10000], Loss: 176.9715\n",
            "Epoch [6687/10000], Loss: 170.7409\n",
            "Epoch [6688/10000], Loss: 176.4753\n",
            "Epoch [6689/10000], Loss: 183.6714\n",
            "Epoch [6690/10000], Loss: 169.7709\n",
            "Epoch [6691/10000], Loss: 176.1294\n",
            "Epoch [6692/10000], Loss: 168.1051\n",
            "Epoch [6693/10000], Loss: 172.6857\n",
            "Epoch [6694/10000], Loss: 171.4731\n",
            "Epoch [6695/10000], Loss: 183.6915\n",
            "Epoch [6696/10000], Loss: 173.9994\n",
            "Epoch [6697/10000], Loss: 180.8003\n",
            "Epoch [6698/10000], Loss: 179.5158\n",
            "Epoch [6699/10000], Loss: 175.1662\n",
            "Epoch [6700/10000], Loss: 176.1367\n",
            "Epoch [6701/10000], Loss: 170.1037\n",
            "Epoch [6702/10000], Loss: 179.8551\n",
            "Epoch [6703/10000], Loss: 172.3307\n",
            "Epoch [6704/10000], Loss: 167.3272\n",
            "Epoch [6705/10000], Loss: 165.4931\n",
            "Epoch [6706/10000], Loss: 171.5311\n",
            "Epoch [6707/10000], Loss: 176.5925\n",
            "Epoch [6708/10000], Loss: 169.5294\n",
            "Epoch [6709/10000], Loss: 176.2413\n",
            "Epoch [6710/10000], Loss: 176.1709\n",
            "Epoch [6711/10000], Loss: 172.7453\n",
            "Epoch [6712/10000], Loss: 175.5875\n",
            "Epoch [6713/10000], Loss: 170.8657\n",
            "Epoch [6714/10000], Loss: 176.8574\n",
            "Epoch [6715/10000], Loss: 178.0643\n",
            "Epoch [6716/10000], Loss: 177.2042\n",
            "Epoch [6717/10000], Loss: 173.2450\n",
            "Epoch [6718/10000], Loss: 175.8197\n",
            "Epoch [6719/10000], Loss: 172.3077\n",
            "Epoch [6720/10000], Loss: 175.5399\n",
            "Epoch [6721/10000], Loss: 176.1684\n",
            "Epoch [6722/10000], Loss: 174.3055\n",
            "Epoch [6723/10000], Loss: 179.3989\n",
            "Epoch [6724/10000], Loss: 176.5042\n",
            "Epoch [6725/10000], Loss: 169.3495\n",
            "Epoch [6726/10000], Loss: 171.6163\n",
            "Epoch [6727/10000], Loss: 173.5553\n",
            "Epoch [6728/10000], Loss: 169.5686\n",
            "Epoch [6729/10000], Loss: 173.6824\n",
            "Epoch [6730/10000], Loss: 172.3361\n",
            "Epoch [6731/10000], Loss: 177.5039\n",
            "Epoch [6732/10000], Loss: 173.4314\n",
            "Epoch [6733/10000], Loss: 164.9910\n",
            "Epoch [6734/10000], Loss: 167.7984\n",
            "Epoch [6735/10000], Loss: 166.9883\n",
            "Epoch [6736/10000], Loss: 176.0210\n",
            "Epoch [6737/10000], Loss: 180.2552\n",
            "Epoch [6738/10000], Loss: 171.1544\n",
            "Epoch [6739/10000], Loss: 173.8923\n",
            "Epoch [6740/10000], Loss: 166.5479\n",
            "Epoch [6741/10000], Loss: 172.9355\n",
            "Epoch [6742/10000], Loss: 166.6985\n",
            "Epoch [6743/10000], Loss: 173.8666\n",
            "Epoch [6744/10000], Loss: 161.7558\n",
            "Epoch [6745/10000], Loss: 169.7796\n",
            "Epoch [6746/10000], Loss: 170.9514\n",
            "Epoch [6747/10000], Loss: 167.6419\n",
            "Epoch [6748/10000], Loss: 170.0148\n",
            "Epoch [6749/10000], Loss: 177.0404\n",
            "Epoch [6750/10000], Loss: 172.2661\n",
            "Epoch [6751/10000], Loss: 166.9704\n",
            "Epoch [6752/10000], Loss: 163.7681\n",
            "Epoch [6753/10000], Loss: 167.9499\n",
            "Epoch [6754/10000], Loss: 173.3512\n",
            "Epoch [6755/10000], Loss: 167.7178\n",
            "Epoch [6756/10000], Loss: 177.5999\n",
            "Epoch [6757/10000], Loss: 165.2901\n",
            "Epoch [6758/10000], Loss: 173.5961\n",
            "Epoch [6759/10000], Loss: 166.2125\n",
            "Epoch [6760/10000], Loss: 168.7538\n",
            "Epoch [6761/10000], Loss: 164.3073\n",
            "Epoch [6762/10000], Loss: 171.4616\n",
            "Epoch [6763/10000], Loss: 178.5780\n",
            "Epoch [6764/10000], Loss: 177.5770\n",
            "Epoch [6765/10000], Loss: 166.4247\n",
            "Epoch [6766/10000], Loss: 171.3793\n",
            "Epoch [6767/10000], Loss: 171.2575\n",
            "Epoch [6768/10000], Loss: 170.6053\n",
            "Epoch [6769/10000], Loss: 172.3282\n",
            "Epoch [6770/10000], Loss: 170.2419\n",
            "Epoch [6771/10000], Loss: 168.7707\n",
            "Epoch [6772/10000], Loss: 167.0810\n",
            "Epoch [6773/10000], Loss: 172.5377\n",
            "Epoch [6774/10000], Loss: 169.0660\n",
            "Epoch [6775/10000], Loss: 167.4626\n",
            "Epoch [6776/10000], Loss: 168.8921\n",
            "Epoch [6777/10000], Loss: 172.2860\n",
            "Epoch [6778/10000], Loss: 168.9930\n",
            "Epoch [6779/10000], Loss: 167.0376\n",
            "Epoch [6780/10000], Loss: 174.3404\n",
            "Epoch [6781/10000], Loss: 167.1349\n",
            "Epoch [6782/10000], Loss: 174.4556\n",
            "Epoch [6783/10000], Loss: 167.1075\n",
            "Epoch [6784/10000], Loss: 176.3697\n",
            "Epoch [6785/10000], Loss: 163.5335\n",
            "Epoch [6786/10000], Loss: 167.3533\n",
            "Epoch [6787/10000], Loss: 168.1424\n",
            "Epoch [6788/10000], Loss: 162.3461\n",
            "Epoch [6789/10000], Loss: 169.4900\n",
            "Epoch [6790/10000], Loss: 168.9055\n",
            "Epoch [6791/10000], Loss: 166.7355\n",
            "Epoch [6792/10000], Loss: 171.1473\n",
            "Epoch [6793/10000], Loss: 167.5907\n",
            "Epoch [6794/10000], Loss: 166.2980\n",
            "Epoch [6795/10000], Loss: 172.0613\n",
            "Epoch [6796/10000], Loss: 162.8191\n",
            "Epoch [6797/10000], Loss: 163.1426\n",
            "Epoch [6798/10000], Loss: 159.1411\n",
            "Epoch [6799/10000], Loss: 166.2058\n",
            "Epoch [6800/10000], Loss: 169.2926\n",
            "Epoch [6801/10000], Loss: 170.9885\n",
            "Epoch [6802/10000], Loss: 171.1033\n",
            "Epoch [6803/10000], Loss: 165.6965\n",
            "Epoch [6804/10000], Loss: 167.9506\n",
            "Epoch [6805/10000], Loss: 170.0769\n",
            "Epoch [6806/10000], Loss: 165.4696\n",
            "Epoch [6807/10000], Loss: 157.3584\n",
            "Epoch [6808/10000], Loss: 163.1747\n",
            "Epoch [6809/10000], Loss: 171.9383\n",
            "Epoch [6810/10000], Loss: 158.8361\n",
            "Epoch [6811/10000], Loss: 165.4868\n",
            "Epoch [6812/10000], Loss: 177.6782\n",
            "Epoch [6813/10000], Loss: 168.9724\n",
            "Epoch [6814/10000], Loss: 167.3960\n",
            "Epoch [6815/10000], Loss: 164.1182\n",
            "Epoch [6816/10000], Loss: 164.0396\n",
            "Epoch [6817/10000], Loss: 164.3262\n",
            "Epoch [6818/10000], Loss: 176.0470\n",
            "Epoch [6819/10000], Loss: 166.6436\n",
            "Epoch [6820/10000], Loss: 162.0412\n",
            "Epoch [6821/10000], Loss: 167.8538\n",
            "Epoch [6822/10000], Loss: 166.2210\n",
            "Epoch [6823/10000], Loss: 173.8715\n",
            "Epoch [6824/10000], Loss: 174.0409\n",
            "Epoch [6825/10000], Loss: 167.2612\n",
            "Epoch [6826/10000], Loss: 165.3296\n",
            "Epoch [6827/10000], Loss: 168.3620\n",
            "Epoch [6828/10000], Loss: 165.8905\n",
            "Epoch [6829/10000], Loss: 160.1268\n",
            "Epoch [6830/10000], Loss: 172.9887\n",
            "Epoch [6831/10000], Loss: 166.7972\n",
            "Epoch [6832/10000], Loss: 169.6403\n",
            "Epoch [6833/10000], Loss: 170.6570\n",
            "Epoch [6834/10000], Loss: 171.6422\n",
            "Epoch [6835/10000], Loss: 169.3529\n",
            "Epoch [6836/10000], Loss: 165.6422\n",
            "Epoch [6837/10000], Loss: 163.3358\n",
            "Epoch [6838/10000], Loss: 170.2488\n",
            "Epoch [6839/10000], Loss: 167.0074\n",
            "Epoch [6840/10000], Loss: 160.0952\n",
            "Epoch [6841/10000], Loss: 167.2495\n",
            "Epoch [6842/10000], Loss: 162.5692\n",
            "Epoch [6843/10000], Loss: 164.2139\n",
            "Epoch [6844/10000], Loss: 166.7907\n",
            "Epoch [6845/10000], Loss: 165.6985\n",
            "Epoch [6846/10000], Loss: 167.2939\n",
            "Epoch [6847/10000], Loss: 163.9537\n",
            "Epoch [6848/10000], Loss: 176.8094\n",
            "Epoch [6849/10000], Loss: 163.4544\n",
            "Epoch [6850/10000], Loss: 164.6842\n",
            "Epoch [6851/10000], Loss: 165.3321\n",
            "Epoch [6852/10000], Loss: 170.9311\n",
            "Epoch [6853/10000], Loss: 163.8201\n",
            "Epoch [6854/10000], Loss: 162.4906\n",
            "Epoch [6855/10000], Loss: 171.7292\n",
            "Epoch [6856/10000], Loss: 164.6803\n",
            "Epoch [6857/10000], Loss: 159.1015\n",
            "Epoch [6858/10000], Loss: 169.0325\n",
            "Epoch [6859/10000], Loss: 161.5933\n",
            "Epoch [6860/10000], Loss: 166.5501\n",
            "Epoch [6861/10000], Loss: 166.0146\n",
            "Epoch [6862/10000], Loss: 159.1160\n",
            "Epoch [6863/10000], Loss: 166.6870\n",
            "Epoch [6864/10000], Loss: 164.9467\n",
            "Epoch [6865/10000], Loss: 155.9123\n",
            "Epoch [6866/10000], Loss: 164.5318\n",
            "Epoch [6867/10000], Loss: 162.8663\n",
            "Epoch [6868/10000], Loss: 170.8563\n",
            "Epoch [6869/10000], Loss: 162.8935\n",
            "Epoch [6870/10000], Loss: 163.3406\n",
            "Epoch [6871/10000], Loss: 154.7213\n",
            "Epoch [6872/10000], Loss: 153.8748\n",
            "Epoch [6873/10000], Loss: 160.1700\n",
            "Epoch [6874/10000], Loss: 161.7599\n",
            "Epoch [6875/10000], Loss: 156.1092\n",
            "Epoch [6876/10000], Loss: 171.3957\n",
            "Epoch [6877/10000], Loss: 161.0700\n",
            "Epoch [6878/10000], Loss: 161.7922\n",
            "Epoch [6879/10000], Loss: 166.4862\n",
            "Epoch [6880/10000], Loss: 157.6913\n",
            "Epoch [6881/10000], Loss: 162.6514\n",
            "Epoch [6882/10000], Loss: 159.5849\n",
            "Epoch [6883/10000], Loss: 164.2046\n",
            "Epoch [6884/10000], Loss: 159.9843\n",
            "Epoch [6885/10000], Loss: 162.8488\n",
            "Epoch [6886/10000], Loss: 165.9988\n",
            "Epoch [6887/10000], Loss: 172.8794\n",
            "Epoch [6888/10000], Loss: 163.6215\n",
            "Epoch [6889/10000], Loss: 167.8123\n",
            "Epoch [6890/10000], Loss: 158.2552\n",
            "Epoch [6891/10000], Loss: 163.4775\n",
            "Epoch [6892/10000], Loss: 159.9708\n",
            "Epoch [6893/10000], Loss: 166.1703\n",
            "Epoch [6894/10000], Loss: 161.8230\n",
            "Epoch [6895/10000], Loss: 158.5165\n",
            "Epoch [6896/10000], Loss: 164.0226\n",
            "Epoch [6897/10000], Loss: 162.1213\n",
            "Epoch [6898/10000], Loss: 162.7530\n",
            "Epoch [6899/10000], Loss: 162.7090\n",
            "Epoch [6900/10000], Loss: 160.5744\n",
            "Epoch [6901/10000], Loss: 170.4613\n",
            "Epoch [6902/10000], Loss: 170.5173\n",
            "Epoch [6903/10000], Loss: 160.8933\n",
            "Epoch [6904/10000], Loss: 164.0018\n",
            "Epoch [6905/10000], Loss: 167.1693\n",
            "Epoch [6906/10000], Loss: 162.5357\n",
            "Epoch [6907/10000], Loss: 156.6075\n",
            "Epoch [6908/10000], Loss: 156.8748\n",
            "Epoch [6909/10000], Loss: 161.4487\n",
            "Epoch [6910/10000], Loss: 157.6348\n",
            "Epoch [6911/10000], Loss: 166.4283\n",
            "Epoch [6912/10000], Loss: 163.6892\n",
            "Epoch [6913/10000], Loss: 162.2676\n",
            "Epoch [6914/10000], Loss: 165.1076\n",
            "Epoch [6915/10000], Loss: 159.7202\n",
            "Epoch [6916/10000], Loss: 157.9893\n",
            "Epoch [6917/10000], Loss: 159.8280\n",
            "Epoch [6918/10000], Loss: 157.2527\n",
            "Epoch [6919/10000], Loss: 163.6857\n",
            "Epoch [6920/10000], Loss: 173.0843\n",
            "Epoch [6921/10000], Loss: 159.1196\n",
            "Epoch [6922/10000], Loss: 166.2382\n",
            "Epoch [6923/10000], Loss: 161.6100\n",
            "Epoch [6924/10000], Loss: 166.2377\n",
            "Epoch [6925/10000], Loss: 160.0562\n",
            "Epoch [6926/10000], Loss: 155.8730\n",
            "Epoch [6927/10000], Loss: 154.5896\n",
            "Epoch [6928/10000], Loss: 169.4663\n",
            "Epoch [6929/10000], Loss: 157.9891\n",
            "Epoch [6930/10000], Loss: 173.4106\n",
            "Epoch [6931/10000], Loss: 156.3550\n",
            "Epoch [6932/10000], Loss: 168.7347\n",
            "Epoch [6933/10000], Loss: 152.9066\n",
            "Epoch [6934/10000], Loss: 155.4651\n",
            "Epoch [6935/10000], Loss: 170.8804\n",
            "Epoch [6936/10000], Loss: 158.5442\n",
            "Epoch [6937/10000], Loss: 155.9613\n",
            "Epoch [6938/10000], Loss: 161.1812\n",
            "Epoch [6939/10000], Loss: 154.6990\n",
            "Epoch [6940/10000], Loss: 165.4033\n",
            "Epoch [6941/10000], Loss: 164.9339\n",
            "Epoch [6942/10000], Loss: 157.6340\n",
            "Epoch [6943/10000], Loss: 155.4473\n",
            "Epoch [6944/10000], Loss: 158.8767\n",
            "Epoch [6945/10000], Loss: 163.5265\n",
            "Epoch [6946/10000], Loss: 159.0770\n",
            "Epoch [6947/10000], Loss: 152.4650\n",
            "Epoch [6948/10000], Loss: 164.5291\n",
            "Epoch [6949/10000], Loss: 155.2194\n",
            "Epoch [6950/10000], Loss: 166.0281\n",
            "Epoch [6951/10000], Loss: 153.8972\n",
            "Epoch [6952/10000], Loss: 151.4681\n",
            "Epoch [6953/10000], Loss: 155.9345\n",
            "Epoch [6954/10000], Loss: 157.6035\n",
            "Epoch [6955/10000], Loss: 165.0949\n",
            "Epoch [6956/10000], Loss: 158.9742\n",
            "Epoch [6957/10000], Loss: 156.4952\n",
            "Epoch [6958/10000], Loss: 159.7789\n",
            "Epoch [6959/10000], Loss: 150.9675\n",
            "Epoch [6960/10000], Loss: 160.1491\n",
            "Epoch [6961/10000], Loss: 159.0859\n",
            "Epoch [6962/10000], Loss: 162.5260\n",
            "Epoch [6963/10000], Loss: 157.6938\n",
            "Epoch [6964/10000], Loss: 171.2068\n",
            "Epoch [6965/10000], Loss: 151.5050\n",
            "Epoch [6966/10000], Loss: 161.3584\n",
            "Epoch [6967/10000], Loss: 151.2576\n",
            "Epoch [6968/10000], Loss: 156.3464\n",
            "Epoch [6969/10000], Loss: 162.3431\n",
            "Epoch [6970/10000], Loss: 154.0562\n",
            "Epoch [6971/10000], Loss: 169.9059\n",
            "Epoch [6972/10000], Loss: 156.3769\n",
            "Epoch [6973/10000], Loss: 154.8110\n",
            "Epoch [6974/10000], Loss: 156.7065\n",
            "Epoch [6975/10000], Loss: 163.9416\n",
            "Epoch [6976/10000], Loss: 153.9738\n",
            "Epoch [6977/10000], Loss: 159.5867\n",
            "Epoch [6978/10000], Loss: 151.7220\n",
            "Epoch [6979/10000], Loss: 154.1638\n",
            "Epoch [6980/10000], Loss: 161.0482\n",
            "Epoch [6981/10000], Loss: 156.9353\n",
            "Epoch [6982/10000], Loss: 153.0869\n",
            "Epoch [6983/10000], Loss: 158.2643\n",
            "Epoch [6984/10000], Loss: 163.8968\n",
            "Epoch [6985/10000], Loss: 153.7476\n",
            "Epoch [6986/10000], Loss: 160.4670\n",
            "Epoch [6987/10000], Loss: 162.6281\n",
            "Epoch [6988/10000], Loss: 152.3378\n",
            "Epoch [6989/10000], Loss: 156.0099\n",
            "Epoch [6990/10000], Loss: 154.9189\n",
            "Epoch [6991/10000], Loss: 154.7137\n",
            "Epoch [6992/10000], Loss: 161.5920\n",
            "Epoch [6993/10000], Loss: 156.1240\n",
            "Epoch [6994/10000], Loss: 154.3490\n",
            "Epoch [6995/10000], Loss: 153.8434\n",
            "Epoch [6996/10000], Loss: 155.6813\n",
            "Epoch [6997/10000], Loss: 161.8170\n",
            "Epoch [6998/10000], Loss: 153.2734\n",
            "Epoch [6999/10000], Loss: 147.6909\n",
            "Epoch [7000/10000], Loss: 156.9684\n",
            "Epoch [7001/10000], Loss: 150.6649\n",
            "Epoch [7002/10000], Loss: 156.3387\n",
            "Epoch [7003/10000], Loss: 165.1576\n",
            "Epoch [7004/10000], Loss: 154.1669\n",
            "Epoch [7005/10000], Loss: 153.6780\n",
            "Epoch [7006/10000], Loss: 155.7349\n",
            "Epoch [7007/10000], Loss: 158.2386\n",
            "Epoch [7008/10000], Loss: 156.9117\n",
            "Epoch [7009/10000], Loss: 152.4192\n",
            "Epoch [7010/10000], Loss: 153.7936\n",
            "Epoch [7011/10000], Loss: 150.7148\n",
            "Epoch [7012/10000], Loss: 152.5405\n",
            "Epoch [7013/10000], Loss: 153.3178\n",
            "Epoch [7014/10000], Loss: 151.6258\n",
            "Epoch [7015/10000], Loss: 150.6734\n",
            "Epoch [7016/10000], Loss: 155.5203\n",
            "Epoch [7017/10000], Loss: 160.4734\n",
            "Epoch [7018/10000], Loss: 149.8415\n",
            "Epoch [7019/10000], Loss: 153.1976\n",
            "Epoch [7020/10000], Loss: 152.9303\n",
            "Epoch [7021/10000], Loss: 153.5797\n",
            "Epoch [7022/10000], Loss: 156.6733\n",
            "Epoch [7023/10000], Loss: 154.9117\n",
            "Epoch [7024/10000], Loss: 153.6614\n",
            "Epoch [7025/10000], Loss: 157.4444\n",
            "Epoch [7026/10000], Loss: 163.3695\n",
            "Epoch [7027/10000], Loss: 149.2467\n",
            "Epoch [7028/10000], Loss: 154.6142\n",
            "Epoch [7029/10000], Loss: 160.7806\n",
            "Epoch [7030/10000], Loss: 153.6527\n",
            "Epoch [7031/10000], Loss: 158.0100\n",
            "Epoch [7032/10000], Loss: 147.4425\n",
            "Epoch [7033/10000], Loss: 150.0744\n",
            "Epoch [7034/10000], Loss: 153.1721\n",
            "Epoch [7035/10000], Loss: 149.1931\n",
            "Epoch [7036/10000], Loss: 153.5192\n",
            "Epoch [7037/10000], Loss: 146.8149\n",
            "Epoch [7038/10000], Loss: 155.2201\n",
            "Epoch [7039/10000], Loss: 155.7761\n",
            "Epoch [7040/10000], Loss: 157.6208\n",
            "Epoch [7041/10000], Loss: 149.7973\n",
            "Epoch [7042/10000], Loss: 153.3818\n",
            "Epoch [7043/10000], Loss: 156.2153\n",
            "Epoch [7044/10000], Loss: 151.1654\n",
            "Epoch [7045/10000], Loss: 148.4604\n",
            "Epoch [7046/10000], Loss: 159.7196\n",
            "Epoch [7047/10000], Loss: 150.6941\n",
            "Epoch [7048/10000], Loss: 154.2702\n",
            "Epoch [7049/10000], Loss: 156.7404\n",
            "Epoch [7050/10000], Loss: 152.3460\n",
            "Epoch [7051/10000], Loss: 152.4983\n",
            "Epoch [7052/10000], Loss: 154.0548\n",
            "Epoch [7053/10000], Loss: 155.8219\n",
            "Epoch [7054/10000], Loss: 145.0656\n",
            "Epoch [7055/10000], Loss: 153.2386\n",
            "Epoch [7056/10000], Loss: 156.5965\n",
            "Epoch [7057/10000], Loss: 161.1022\n",
            "Epoch [7058/10000], Loss: 149.9360\n",
            "Epoch [7059/10000], Loss: 148.7228\n",
            "Epoch [7060/10000], Loss: 153.0646\n",
            "Epoch [7061/10000], Loss: 152.4404\n",
            "Epoch [7062/10000], Loss: 155.8872\n",
            "Epoch [7063/10000], Loss: 154.6921\n",
            "Epoch [7064/10000], Loss: 163.3292\n",
            "Epoch [7065/10000], Loss: 157.4638\n",
            "Epoch [7066/10000], Loss: 154.8730\n",
            "Epoch [7067/10000], Loss: 148.7256\n",
            "Epoch [7068/10000], Loss: 161.7654\n",
            "Epoch [7069/10000], Loss: 158.5625\n",
            "Epoch [7070/10000], Loss: 157.2004\n",
            "Epoch [7071/10000], Loss: 155.6068\n",
            "Epoch [7072/10000], Loss: 154.5974\n",
            "Epoch [7073/10000], Loss: 148.0821\n",
            "Epoch [7074/10000], Loss: 157.2072\n",
            "Epoch [7075/10000], Loss: 145.7310\n",
            "Epoch [7076/10000], Loss: 148.3812\n",
            "Epoch [7077/10000], Loss: 155.0390\n",
            "Epoch [7078/10000], Loss: 151.3522\n",
            "Epoch [7079/10000], Loss: 150.2157\n",
            "Epoch [7080/10000], Loss: 156.3674\n",
            "Epoch [7081/10000], Loss: 152.7402\n",
            "Epoch [7082/10000], Loss: 152.1735\n",
            "Epoch [7083/10000], Loss: 143.8568\n",
            "Epoch [7084/10000], Loss: 150.5270\n",
            "Epoch [7085/10000], Loss: 154.5464\n",
            "Epoch [7086/10000], Loss: 155.9910\n",
            "Epoch [7087/10000], Loss: 154.9234\n",
            "Epoch [7088/10000], Loss: 163.5551\n",
            "Epoch [7089/10000], Loss: 155.0405\n",
            "Epoch [7090/10000], Loss: 150.3873\n",
            "Epoch [7091/10000], Loss: 156.1584\n",
            "Epoch [7092/10000], Loss: 154.0620\n",
            "Epoch [7093/10000], Loss: 156.1382\n",
            "Epoch [7094/10000], Loss: 158.3306\n",
            "Epoch [7095/10000], Loss: 150.7970\n",
            "Epoch [7096/10000], Loss: 145.8980\n",
            "Epoch [7097/10000], Loss: 155.6462\n",
            "Epoch [7098/10000], Loss: 148.5743\n",
            "Epoch [7099/10000], Loss: 148.7929\n",
            "Epoch [7100/10000], Loss: 154.2390\n",
            "Epoch [7101/10000], Loss: 147.4963\n",
            "Epoch [7102/10000], Loss: 151.4243\n",
            "Epoch [7103/10000], Loss: 152.2323\n",
            "Epoch [7104/10000], Loss: 148.8051\n",
            "Epoch [7105/10000], Loss: 155.1953\n",
            "Epoch [7106/10000], Loss: 149.8788\n",
            "Epoch [7107/10000], Loss: 152.3885\n",
            "Epoch [7108/10000], Loss: 150.9345\n",
            "Epoch [7109/10000], Loss: 145.1679\n",
            "Epoch [7110/10000], Loss: 154.4033\n",
            "Epoch [7111/10000], Loss: 146.0066\n",
            "Epoch [7112/10000], Loss: 147.5914\n",
            "Epoch [7113/10000], Loss: 153.5495\n",
            "Epoch [7114/10000], Loss: 150.9662\n",
            "Epoch [7115/10000], Loss: 150.6314\n",
            "Epoch [7116/10000], Loss: 154.8232\n",
            "Epoch [7117/10000], Loss: 142.5198\n",
            "Epoch [7118/10000], Loss: 148.3500\n",
            "Epoch [7119/10000], Loss: 149.8988\n",
            "Epoch [7120/10000], Loss: 152.3089\n",
            "Epoch [7121/10000], Loss: 152.5819\n",
            "Epoch [7122/10000], Loss: 151.9361\n",
            "Epoch [7123/10000], Loss: 155.2633\n",
            "Epoch [7124/10000], Loss: 152.0695\n",
            "Epoch [7125/10000], Loss: 147.6455\n",
            "Epoch [7126/10000], Loss: 149.6205\n",
            "Epoch [7127/10000], Loss: 145.8577\n",
            "Epoch [7128/10000], Loss: 150.2872\n",
            "Epoch [7129/10000], Loss: 152.7299\n",
            "Epoch [7130/10000], Loss: 154.1345\n",
            "Epoch [7131/10000], Loss: 155.8863\n",
            "Epoch [7132/10000], Loss: 150.7511\n",
            "Epoch [7133/10000], Loss: 147.8707\n",
            "Epoch [7134/10000], Loss: 149.6994\n",
            "Epoch [7135/10000], Loss: 147.8724\n",
            "Epoch [7136/10000], Loss: 144.4545\n",
            "Epoch [7137/10000], Loss: 154.2202\n",
            "Epoch [7138/10000], Loss: 154.6313\n",
            "Epoch [7139/10000], Loss: 146.0157\n",
            "Epoch [7140/10000], Loss: 151.5580\n",
            "Epoch [7141/10000], Loss: 145.3999\n",
            "Epoch [7142/10000], Loss: 153.2297\n",
            "Epoch [7143/10000], Loss: 146.2162\n",
            "Epoch [7144/10000], Loss: 140.1665\n",
            "Epoch [7145/10000], Loss: 153.9182\n",
            "Epoch [7146/10000], Loss: 147.3464\n",
            "Epoch [7147/10000], Loss: 152.6454\n",
            "Epoch [7148/10000], Loss: 145.3647\n",
            "Epoch [7149/10000], Loss: 145.8094\n",
            "Epoch [7150/10000], Loss: 148.6584\n",
            "Epoch [7151/10000], Loss: 147.9090\n",
            "Epoch [7152/10000], Loss: 148.9314\n",
            "Epoch [7153/10000], Loss: 156.1940\n",
            "Epoch [7154/10000], Loss: 155.0280\n",
            "Epoch [7155/10000], Loss: 147.0392\n",
            "Epoch [7156/10000], Loss: 151.4308\n",
            "Epoch [7157/10000], Loss: 146.4987\n",
            "Epoch [7158/10000], Loss: 145.7709\n",
            "Epoch [7159/10000], Loss: 147.8632\n",
            "Epoch [7160/10000], Loss: 138.1624\n",
            "Epoch [7161/10000], Loss: 155.1499\n",
            "Epoch [7162/10000], Loss: 136.7215\n",
            "Epoch [7163/10000], Loss: 152.3163\n",
            "Epoch [7164/10000], Loss: 150.2407\n",
            "Epoch [7165/10000], Loss: 151.8054\n",
            "Epoch [7166/10000], Loss: 145.3990\n",
            "Epoch [7167/10000], Loss: 139.5271\n",
            "Epoch [7168/10000], Loss: 152.3555\n",
            "Epoch [7169/10000], Loss: 147.1607\n",
            "Epoch [7170/10000], Loss: 151.1445\n",
            "Epoch [7171/10000], Loss: 149.9810\n",
            "Epoch [7172/10000], Loss: 150.9478\n",
            "Epoch [7173/10000], Loss: 148.6917\n",
            "Epoch [7174/10000], Loss: 141.4175\n",
            "Epoch [7175/10000], Loss: 141.7991\n",
            "Epoch [7176/10000], Loss: 154.7937\n",
            "Epoch [7177/10000], Loss: 150.2515\n",
            "Epoch [7178/10000], Loss: 143.4555\n",
            "Epoch [7179/10000], Loss: 144.2265\n",
            "Epoch [7180/10000], Loss: 145.1487\n",
            "Epoch [7181/10000], Loss: 150.5877\n",
            "Epoch [7182/10000], Loss: 149.5737\n",
            "Epoch [7183/10000], Loss: 154.4479\n",
            "Epoch [7184/10000], Loss: 148.0785\n",
            "Epoch [7185/10000], Loss: 149.7125\n",
            "Epoch [7186/10000], Loss: 142.7326\n",
            "Epoch [7187/10000], Loss: 142.2464\n",
            "Epoch [7188/10000], Loss: 147.7839\n",
            "Epoch [7189/10000], Loss: 139.0691\n",
            "Epoch [7190/10000], Loss: 155.1158\n",
            "Epoch [7191/10000], Loss: 145.1702\n",
            "Epoch [7192/10000], Loss: 143.8635\n",
            "Epoch [7193/10000], Loss: 151.9312\n",
            "Epoch [7194/10000], Loss: 147.3274\n",
            "Epoch [7195/10000], Loss: 145.6537\n",
            "Epoch [7196/10000], Loss: 150.4300\n",
            "Epoch [7197/10000], Loss: 141.4452\n",
            "Epoch [7198/10000], Loss: 159.2461\n",
            "Epoch [7199/10000], Loss: 144.5514\n",
            "Epoch [7200/10000], Loss: 142.3522\n",
            "Epoch [7201/10000], Loss: 141.4201\n",
            "Epoch [7202/10000], Loss: 147.9020\n",
            "Epoch [7203/10000], Loss: 149.9908\n",
            "Epoch [7204/10000], Loss: 149.2120\n",
            "Epoch [7205/10000], Loss: 148.5393\n",
            "Epoch [7206/10000], Loss: 143.0165\n",
            "Epoch [7207/10000], Loss: 144.1615\n",
            "Epoch [7208/10000], Loss: 138.4014\n",
            "Epoch [7209/10000], Loss: 144.7548\n",
            "Epoch [7210/10000], Loss: 148.0096\n",
            "Epoch [7211/10000], Loss: 141.5309\n",
            "Epoch [7212/10000], Loss: 144.6858\n",
            "Epoch [7213/10000], Loss: 148.0248\n",
            "Epoch [7214/10000], Loss: 141.4319\n",
            "Epoch [7215/10000], Loss: 137.4518\n",
            "Epoch [7216/10000], Loss: 145.3556\n",
            "Epoch [7217/10000], Loss: 150.8895\n",
            "Epoch [7218/10000], Loss: 143.7540\n",
            "Epoch [7219/10000], Loss: 144.8372\n",
            "Epoch [7220/10000], Loss: 150.7464\n",
            "Epoch [7221/10000], Loss: 148.6191\n",
            "Epoch [7222/10000], Loss: 144.8139\n",
            "Epoch [7223/10000], Loss: 144.9895\n",
            "Epoch [7224/10000], Loss: 147.0406\n",
            "Epoch [7225/10000], Loss: 149.9633\n",
            "Epoch [7226/10000], Loss: 149.1484\n",
            "Epoch [7227/10000], Loss: 144.4822\n",
            "Epoch [7228/10000], Loss: 150.0626\n",
            "Epoch [7229/10000], Loss: 146.8728\n",
            "Epoch [7230/10000], Loss: 150.5074\n",
            "Epoch [7231/10000], Loss: 140.4793\n",
            "Epoch [7232/10000], Loss: 146.1568\n",
            "Epoch [7233/10000], Loss: 144.8869\n",
            "Epoch [7234/10000], Loss: 146.2808\n",
            "Epoch [7235/10000], Loss: 147.9582\n",
            "Epoch [7236/10000], Loss: 143.3775\n",
            "Epoch [7237/10000], Loss: 154.2800\n",
            "Epoch [7238/10000], Loss: 148.1692\n",
            "Epoch [7239/10000], Loss: 147.7763\n",
            "Epoch [7240/10000], Loss: 150.1503\n",
            "Epoch [7241/10000], Loss: 139.2906\n",
            "Epoch [7242/10000], Loss: 142.5660\n",
            "Epoch [7243/10000], Loss: 148.0870\n",
            "Epoch [7244/10000], Loss: 141.6814\n",
            "Epoch [7245/10000], Loss: 148.2382\n",
            "Epoch [7246/10000], Loss: 141.6888\n",
            "Epoch [7247/10000], Loss: 136.8055\n",
            "Epoch [7248/10000], Loss: 143.5721\n",
            "Epoch [7249/10000], Loss: 143.1006\n",
            "Epoch [7250/10000], Loss: 147.9178\n",
            "Epoch [7251/10000], Loss: 139.9240\n",
            "Epoch [7252/10000], Loss: 145.5440\n",
            "Epoch [7253/10000], Loss: 140.4655\n",
            "Epoch [7254/10000], Loss: 140.4792\n",
            "Epoch [7255/10000], Loss: 149.3423\n",
            "Epoch [7256/10000], Loss: 150.0110\n",
            "Epoch [7257/10000], Loss: 138.4243\n",
            "Epoch [7258/10000], Loss: 138.0238\n",
            "Epoch [7259/10000], Loss: 143.8081\n",
            "Epoch [7260/10000], Loss: 139.2198\n",
            "Epoch [7261/10000], Loss: 141.3518\n",
            "Epoch [7262/10000], Loss: 143.6462\n",
            "Epoch [7263/10000], Loss: 141.4724\n",
            "Epoch [7264/10000], Loss: 142.7262\n",
            "Epoch [7265/10000], Loss: 145.2233\n",
            "Epoch [7266/10000], Loss: 149.8276\n",
            "Epoch [7267/10000], Loss: 143.2805\n",
            "Epoch [7268/10000], Loss: 142.8731\n",
            "Epoch [7269/10000], Loss: 145.9443\n",
            "Epoch [7270/10000], Loss: 142.5238\n",
            "Epoch [7271/10000], Loss: 140.7383\n",
            "Epoch [7272/10000], Loss: 148.3786\n",
            "Epoch [7273/10000], Loss: 145.0148\n",
            "Epoch [7274/10000], Loss: 145.4782\n",
            "Epoch [7275/10000], Loss: 145.7269\n",
            "Epoch [7276/10000], Loss: 141.2931\n",
            "Epoch [7277/10000], Loss: 145.2748\n",
            "Epoch [7278/10000], Loss: 149.1477\n",
            "Epoch [7279/10000], Loss: 136.3458\n",
            "Epoch [7280/10000], Loss: 139.7654\n",
            "Epoch [7281/10000], Loss: 140.0067\n",
            "Epoch [7282/10000], Loss: 149.3611\n",
            "Epoch [7283/10000], Loss: 136.5765\n",
            "Epoch [7284/10000], Loss: 150.3454\n",
            "Epoch [7285/10000], Loss: 147.1222\n",
            "Epoch [7286/10000], Loss: 139.4809\n",
            "Epoch [7287/10000], Loss: 141.8020\n",
            "Epoch [7288/10000], Loss: 146.0800\n",
            "Epoch [7289/10000], Loss: 144.2720\n",
            "Epoch [7290/10000], Loss: 146.5448\n",
            "Epoch [7291/10000], Loss: 137.3666\n",
            "Epoch [7292/10000], Loss: 141.6134\n",
            "Epoch [7293/10000], Loss: 146.2972\n",
            "Epoch [7294/10000], Loss: 143.1372\n",
            "Epoch [7295/10000], Loss: 141.4519\n",
            "Epoch [7296/10000], Loss: 144.3888\n",
            "Epoch [7297/10000], Loss: 135.2568\n",
            "Epoch [7298/10000], Loss: 142.0479\n",
            "Epoch [7299/10000], Loss: 147.6069\n",
            "Epoch [7300/10000], Loss: 139.9604\n",
            "Epoch [7301/10000], Loss: 147.2777\n",
            "Epoch [7302/10000], Loss: 141.6833\n",
            "Epoch [7303/10000], Loss: 137.6424\n",
            "Epoch [7304/10000], Loss: 144.8029\n",
            "Epoch [7305/10000], Loss: 143.1198\n",
            "Epoch [7306/10000], Loss: 144.3578\n",
            "Epoch [7307/10000], Loss: 145.3260\n",
            "Epoch [7308/10000], Loss: 148.2970\n",
            "Epoch [7309/10000], Loss: 146.4826\n",
            "Epoch [7310/10000], Loss: 132.6906\n",
            "Epoch [7311/10000], Loss: 146.9187\n",
            "Epoch [7312/10000], Loss: 140.3157\n",
            "Epoch [7313/10000], Loss: 146.3717\n",
            "Epoch [7314/10000], Loss: 150.0428\n",
            "Epoch [7315/10000], Loss: 140.3271\n",
            "Epoch [7316/10000], Loss: 143.0528\n",
            "Epoch [7317/10000], Loss: 143.4365\n",
            "Epoch [7318/10000], Loss: 140.0311\n",
            "Epoch [7319/10000], Loss: 147.7762\n",
            "Epoch [7320/10000], Loss: 138.5929\n",
            "Epoch [7321/10000], Loss: 138.8625\n",
            "Epoch [7322/10000], Loss: 138.0890\n",
            "Epoch [7323/10000], Loss: 141.6747\n",
            "Epoch [7324/10000], Loss: 140.2428\n",
            "Epoch [7325/10000], Loss: 144.1952\n",
            "Epoch [7326/10000], Loss: 144.7164\n",
            "Epoch [7327/10000], Loss: 144.1463\n",
            "Epoch [7328/10000], Loss: 145.9657\n",
            "Epoch [7329/10000], Loss: 144.1563\n",
            "Epoch [7330/10000], Loss: 140.5934\n",
            "Epoch [7331/10000], Loss: 142.9784\n",
            "Epoch [7332/10000], Loss: 142.8884\n",
            "Epoch [7333/10000], Loss: 132.5644\n",
            "Epoch [7334/10000], Loss: 145.6810\n",
            "Epoch [7335/10000], Loss: 142.0573\n",
            "Epoch [7336/10000], Loss: 135.0872\n",
            "Epoch [7337/10000], Loss: 139.8534\n",
            "Epoch [7338/10000], Loss: 138.4924\n",
            "Epoch [7339/10000], Loss: 142.1889\n",
            "Epoch [7340/10000], Loss: 137.8334\n",
            "Epoch [7341/10000], Loss: 142.7078\n",
            "Epoch [7342/10000], Loss: 139.2177\n",
            "Epoch [7343/10000], Loss: 146.3677\n",
            "Epoch [7344/10000], Loss: 138.7492\n",
            "Epoch [7345/10000], Loss: 143.5812\n",
            "Epoch [7346/10000], Loss: 134.6324\n",
            "Epoch [7347/10000], Loss: 144.6143\n",
            "Epoch [7348/10000], Loss: 142.8543\n",
            "Epoch [7349/10000], Loss: 137.6134\n",
            "Epoch [7350/10000], Loss: 140.0825\n",
            "Epoch [7351/10000], Loss: 139.5486\n",
            "Epoch [7352/10000], Loss: 136.3481\n",
            "Epoch [7353/10000], Loss: 136.2614\n",
            "Epoch [7354/10000], Loss: 146.6816\n",
            "Epoch [7355/10000], Loss: 142.4400\n",
            "Epoch [7356/10000], Loss: 141.4343\n",
            "Epoch [7357/10000], Loss: 138.1217\n",
            "Epoch [7358/10000], Loss: 138.6821\n",
            "Epoch [7359/10000], Loss: 144.5691\n",
            "Epoch [7360/10000], Loss: 144.4212\n",
            "Epoch [7361/10000], Loss: 134.8621\n",
            "Epoch [7362/10000], Loss: 147.5261\n",
            "Epoch [7363/10000], Loss: 139.0441\n",
            "Epoch [7364/10000], Loss: 136.6858\n",
            "Epoch [7365/10000], Loss: 139.9879\n",
            "Epoch [7366/10000], Loss: 140.3249\n",
            "Epoch [7367/10000], Loss: 136.1657\n",
            "Epoch [7368/10000], Loss: 141.4687\n",
            "Epoch [7369/10000], Loss: 143.4253\n",
            "Epoch [7370/10000], Loss: 139.1439\n",
            "Epoch [7371/10000], Loss: 140.4363\n",
            "Epoch [7372/10000], Loss: 134.4069\n",
            "Epoch [7373/10000], Loss: 130.2665\n",
            "Epoch [7374/10000], Loss: 139.3280\n",
            "Epoch [7375/10000], Loss: 142.6572\n",
            "Epoch [7376/10000], Loss: 143.8793\n",
            "Epoch [7377/10000], Loss: 134.8448\n",
            "Epoch [7378/10000], Loss: 136.8462\n",
            "Epoch [7379/10000], Loss: 137.0627\n",
            "Epoch [7380/10000], Loss: 136.9801\n",
            "Epoch [7381/10000], Loss: 140.3745\n",
            "Epoch [7382/10000], Loss: 141.4825\n",
            "Epoch [7383/10000], Loss: 136.2169\n",
            "Epoch [7384/10000], Loss: 136.2234\n",
            "Epoch [7385/10000], Loss: 150.9854\n",
            "Epoch [7386/10000], Loss: 137.1936\n",
            "Epoch [7387/10000], Loss: 141.9203\n",
            "Epoch [7388/10000], Loss: 137.3316\n",
            "Epoch [7389/10000], Loss: 135.0270\n",
            "Epoch [7390/10000], Loss: 135.9310\n",
            "Epoch [7391/10000], Loss: 142.5547\n",
            "Epoch [7392/10000], Loss: 145.9738\n",
            "Epoch [7393/10000], Loss: 138.5649\n",
            "Epoch [7394/10000], Loss: 134.9350\n",
            "Epoch [7395/10000], Loss: 137.5892\n",
            "Epoch [7396/10000], Loss: 132.9905\n",
            "Epoch [7397/10000], Loss: 140.1658\n",
            "Epoch [7398/10000], Loss: 139.9185\n",
            "Epoch [7399/10000], Loss: 141.2561\n",
            "Epoch [7400/10000], Loss: 141.4530\n",
            "Epoch [7401/10000], Loss: 138.3780\n",
            "Epoch [7402/10000], Loss: 140.2706\n",
            "Epoch [7403/10000], Loss: 134.1027\n",
            "Epoch [7404/10000], Loss: 141.7204\n",
            "Epoch [7405/10000], Loss: 139.6285\n",
            "Epoch [7406/10000], Loss: 132.7678\n",
            "Epoch [7407/10000], Loss: 139.4657\n",
            "Epoch [7408/10000], Loss: 136.6537\n",
            "Epoch [7409/10000], Loss: 133.2418\n",
            "Epoch [7410/10000], Loss: 133.8251\n",
            "Epoch [7411/10000], Loss: 135.2222\n",
            "Epoch [7412/10000], Loss: 144.2312\n",
            "Epoch [7413/10000], Loss: 137.4653\n",
            "Epoch [7414/10000], Loss: 146.6750\n",
            "Epoch [7415/10000], Loss: 138.7947\n",
            "Epoch [7416/10000], Loss: 137.9280\n",
            "Epoch [7417/10000], Loss: 135.5284\n",
            "Epoch [7418/10000], Loss: 140.7685\n",
            "Epoch [7419/10000], Loss: 139.5860\n",
            "Epoch [7420/10000], Loss: 138.9139\n",
            "Epoch [7421/10000], Loss: 140.0869\n",
            "Epoch [7422/10000], Loss: 141.5652\n",
            "Epoch [7423/10000], Loss: 139.5891\n",
            "Epoch [7424/10000], Loss: 130.7808\n",
            "Epoch [7425/10000], Loss: 145.5599\n",
            "Epoch [7426/10000], Loss: 137.2639\n",
            "Epoch [7427/10000], Loss: 137.9610\n",
            "Epoch [7428/10000], Loss: 135.0240\n",
            "Epoch [7429/10000], Loss: 141.0758\n",
            "Epoch [7430/10000], Loss: 133.9846\n",
            "Epoch [7431/10000], Loss: 138.4656\n",
            "Epoch [7432/10000], Loss: 134.2917\n",
            "Epoch [7433/10000], Loss: 135.8008\n",
            "Epoch [7434/10000], Loss: 138.4315\n",
            "Epoch [7435/10000], Loss: 138.2158\n",
            "Epoch [7436/10000], Loss: 139.6632\n",
            "Epoch [7437/10000], Loss: 134.2307\n",
            "Epoch [7438/10000], Loss: 130.3940\n",
            "Epoch [7439/10000], Loss: 143.3017\n",
            "Epoch [7440/10000], Loss: 137.4394\n",
            "Epoch [7441/10000], Loss: 136.8209\n",
            "Epoch [7442/10000], Loss: 135.4642\n",
            "Epoch [7443/10000], Loss: 138.8799\n",
            "Epoch [7444/10000], Loss: 137.0512\n",
            "Epoch [7445/10000], Loss: 134.7212\n",
            "Epoch [7446/10000], Loss: 139.2564\n",
            "Epoch [7447/10000], Loss: 136.1618\n",
            "Epoch [7448/10000], Loss: 130.9365\n",
            "Epoch [7449/10000], Loss: 135.1106\n",
            "Epoch [7450/10000], Loss: 134.2327\n",
            "Epoch [7451/10000], Loss: 132.3770\n",
            "Epoch [7452/10000], Loss: 134.8619\n",
            "Epoch [7453/10000], Loss: 138.8497\n",
            "Epoch [7454/10000], Loss: 135.2829\n",
            "Epoch [7455/10000], Loss: 132.1296\n",
            "Epoch [7456/10000], Loss: 139.7433\n",
            "Epoch [7457/10000], Loss: 140.1322\n",
            "Epoch [7458/10000], Loss: 133.4960\n",
            "Epoch [7459/10000], Loss: 132.8802\n",
            "Epoch [7460/10000], Loss: 138.0930\n",
            "Epoch [7461/10000], Loss: 140.9731\n",
            "Epoch [7462/10000], Loss: 130.9257\n",
            "Epoch [7463/10000], Loss: 133.2124\n",
            "Epoch [7464/10000], Loss: 145.3684\n",
            "Epoch [7465/10000], Loss: 130.5709\n",
            "Epoch [7466/10000], Loss: 146.8102\n",
            "Epoch [7467/10000], Loss: 144.1721\n",
            "Epoch [7468/10000], Loss: 136.8304\n",
            "Epoch [7469/10000], Loss: 136.0043\n",
            "Epoch [7470/10000], Loss: 135.5299\n",
            "Epoch [7471/10000], Loss: 139.9480\n",
            "Epoch [7472/10000], Loss: 136.8371\n",
            "Epoch [7473/10000], Loss: 133.9393\n",
            "Epoch [7474/10000], Loss: 139.8354\n",
            "Epoch [7475/10000], Loss: 132.8694\n",
            "Epoch [7476/10000], Loss: 134.0747\n",
            "Epoch [7477/10000], Loss: 137.6532\n",
            "Epoch [7478/10000], Loss: 143.5322\n",
            "Epoch [7479/10000], Loss: 140.7709\n",
            "Epoch [7480/10000], Loss: 140.7077\n",
            "Epoch [7481/10000], Loss: 140.6108\n",
            "Epoch [7482/10000], Loss: 138.5556\n",
            "Epoch [7483/10000], Loss: 136.8648\n",
            "Epoch [7484/10000], Loss: 139.2821\n",
            "Epoch [7485/10000], Loss: 143.7112\n",
            "Epoch [7486/10000], Loss: 140.7198\n",
            "Epoch [7487/10000], Loss: 131.0506\n",
            "Epoch [7488/10000], Loss: 135.4879\n",
            "Epoch [7489/10000], Loss: 138.7122\n",
            "Epoch [7490/10000], Loss: 140.3718\n",
            "Epoch [7491/10000], Loss: 134.4278\n",
            "Epoch [7492/10000], Loss: 132.1975\n",
            "Epoch [7493/10000], Loss: 135.4170\n",
            "Epoch [7494/10000], Loss: 137.5264\n",
            "Epoch [7495/10000], Loss: 138.0179\n",
            "Epoch [7496/10000], Loss: 139.4587\n",
            "Epoch [7497/10000], Loss: 129.1669\n",
            "Epoch [7498/10000], Loss: 139.1767\n",
            "Epoch [7499/10000], Loss: 130.5010\n",
            "Epoch [7500/10000], Loss: 136.4154\n",
            "Epoch [7501/10000], Loss: 144.0069\n",
            "Epoch [7502/10000], Loss: 137.2221\n",
            "Epoch [7503/10000], Loss: 134.7754\n",
            "Epoch [7504/10000], Loss: 141.6272\n",
            "Epoch [7505/10000], Loss: 132.9708\n",
            "Epoch [7506/10000], Loss: 141.9603\n",
            "Epoch [7507/10000], Loss: 135.9929\n",
            "Epoch [7508/10000], Loss: 135.1596\n",
            "Epoch [7509/10000], Loss: 134.5803\n",
            "Epoch [7510/10000], Loss: 128.1603\n",
            "Epoch [7511/10000], Loss: 129.8334\n",
            "Epoch [7512/10000], Loss: 131.2538\n",
            "Epoch [7513/10000], Loss: 134.5725\n",
            "Epoch [7514/10000], Loss: 127.1857\n",
            "Epoch [7515/10000], Loss: 130.0447\n",
            "Epoch [7516/10000], Loss: 131.7391\n",
            "Epoch [7517/10000], Loss: 136.8478\n",
            "Epoch [7518/10000], Loss: 137.9006\n",
            "Epoch [7519/10000], Loss: 134.6100\n",
            "Epoch [7520/10000], Loss: 135.1636\n",
            "Epoch [7521/10000], Loss: 130.5045\n",
            "Epoch [7522/10000], Loss: 131.0730\n",
            "Epoch [7523/10000], Loss: 132.5692\n",
            "Epoch [7524/10000], Loss: 138.0518\n",
            "Epoch [7525/10000], Loss: 135.8485\n",
            "Epoch [7526/10000], Loss: 137.8527\n",
            "Epoch [7527/10000], Loss: 133.0274\n",
            "Epoch [7528/10000], Loss: 131.0484\n",
            "Epoch [7529/10000], Loss: 128.6073\n",
            "Epoch [7530/10000], Loss: 134.8209\n",
            "Epoch [7531/10000], Loss: 140.6366\n",
            "Epoch [7532/10000], Loss: 131.4854\n",
            "Epoch [7533/10000], Loss: 134.9519\n",
            "Epoch [7534/10000], Loss: 138.4777\n",
            "Epoch [7535/10000], Loss: 126.7433\n",
            "Epoch [7536/10000], Loss: 135.3592\n",
            "Epoch [7537/10000], Loss: 136.0547\n",
            "Epoch [7538/10000], Loss: 135.7560\n",
            "Epoch [7539/10000], Loss: 132.5912\n",
            "Epoch [7540/10000], Loss: 134.7624\n",
            "Epoch [7541/10000], Loss: 126.3987\n",
            "Epoch [7542/10000], Loss: 132.7310\n",
            "Epoch [7543/10000], Loss: 139.9155\n",
            "Epoch [7544/10000], Loss: 132.2896\n",
            "Epoch [7545/10000], Loss: 137.9832\n",
            "Epoch [7546/10000], Loss: 137.5354\n",
            "Epoch [7547/10000], Loss: 131.2844\n",
            "Epoch [7548/10000], Loss: 138.6991\n",
            "Epoch [7549/10000], Loss: 135.1922\n",
            "Epoch [7550/10000], Loss: 129.6304\n",
            "Epoch [7551/10000], Loss: 130.6881\n",
            "Epoch [7552/10000], Loss: 134.7638\n",
            "Epoch [7553/10000], Loss: 128.3309\n",
            "Epoch [7554/10000], Loss: 133.3976\n",
            "Epoch [7555/10000], Loss: 128.5172\n",
            "Epoch [7556/10000], Loss: 129.0124\n",
            "Epoch [7557/10000], Loss: 137.9677\n",
            "Epoch [7558/10000], Loss: 134.2359\n",
            "Epoch [7559/10000], Loss: 135.7273\n",
            "Epoch [7560/10000], Loss: 128.4154\n",
            "Epoch [7561/10000], Loss: 129.8764\n",
            "Epoch [7562/10000], Loss: 127.7158\n",
            "Epoch [7563/10000], Loss: 132.0217\n",
            "Epoch [7564/10000], Loss: 127.5838\n",
            "Epoch [7565/10000], Loss: 127.9662\n",
            "Epoch [7566/10000], Loss: 133.2440\n",
            "Epoch [7567/10000], Loss: 138.0842\n",
            "Epoch [7568/10000], Loss: 130.7857\n",
            "Epoch [7569/10000], Loss: 132.5746\n",
            "Epoch [7570/10000], Loss: 130.9577\n",
            "Epoch [7571/10000], Loss: 143.4899\n",
            "Epoch [7572/10000], Loss: 123.5441\n",
            "Epoch [7573/10000], Loss: 130.0253\n",
            "Epoch [7574/10000], Loss: 139.6248\n",
            "Epoch [7575/10000], Loss: 128.0808\n",
            "Epoch [7576/10000], Loss: 135.2402\n",
            "Epoch [7577/10000], Loss: 128.0694\n",
            "Epoch [7578/10000], Loss: 135.5999\n",
            "Epoch [7579/10000], Loss: 137.6129\n",
            "Epoch [7580/10000], Loss: 136.8084\n",
            "Epoch [7581/10000], Loss: 132.2779\n",
            "Epoch [7582/10000], Loss: 141.5020\n",
            "Epoch [7583/10000], Loss: 136.4540\n",
            "Epoch [7584/10000], Loss: 131.3004\n",
            "Epoch [7585/10000], Loss: 135.7162\n",
            "Epoch [7586/10000], Loss: 131.7927\n",
            "Epoch [7587/10000], Loss: 133.0014\n",
            "Epoch [7588/10000], Loss: 134.0277\n",
            "Epoch [7589/10000], Loss: 131.6030\n",
            "Epoch [7590/10000], Loss: 133.6083\n",
            "Epoch [7591/10000], Loss: 143.4487\n",
            "Epoch [7592/10000], Loss: 126.7429\n",
            "Epoch [7593/10000], Loss: 140.7155\n",
            "Epoch [7594/10000], Loss: 134.6640\n",
            "Epoch [7595/10000], Loss: 132.8773\n",
            "Epoch [7596/10000], Loss: 134.7816\n",
            "Epoch [7597/10000], Loss: 128.5512\n",
            "Epoch [7598/10000], Loss: 129.7707\n",
            "Epoch [7599/10000], Loss: 127.4410\n",
            "Epoch [7600/10000], Loss: 128.6322\n",
            "Epoch [7601/10000], Loss: 134.3524\n",
            "Epoch [7602/10000], Loss: 130.5269\n",
            "Epoch [7603/10000], Loss: 130.7425\n",
            "Epoch [7604/10000], Loss: 126.0454\n",
            "Epoch [7605/10000], Loss: 132.3045\n",
            "Epoch [7606/10000], Loss: 133.6885\n",
            "Epoch [7607/10000], Loss: 134.9620\n",
            "Epoch [7608/10000], Loss: 127.0944\n",
            "Epoch [7609/10000], Loss: 132.8089\n",
            "Epoch [7610/10000], Loss: 131.6799\n",
            "Epoch [7611/10000], Loss: 132.1715\n",
            "Epoch [7612/10000], Loss: 130.4112\n",
            "Epoch [7613/10000], Loss: 124.5298\n",
            "Epoch [7614/10000], Loss: 131.6246\n",
            "Epoch [7615/10000], Loss: 126.1819\n",
            "Epoch [7616/10000], Loss: 125.9378\n",
            "Epoch [7617/10000], Loss: 125.7669\n",
            "Epoch [7618/10000], Loss: 130.6501\n",
            "Epoch [7619/10000], Loss: 133.5646\n",
            "Epoch [7620/10000], Loss: 129.0302\n",
            "Epoch [7621/10000], Loss: 138.2070\n",
            "Epoch [7622/10000], Loss: 130.6753\n",
            "Epoch [7623/10000], Loss: 132.4539\n",
            "Epoch [7624/10000], Loss: 137.9182\n",
            "Epoch [7625/10000], Loss: 130.1534\n",
            "Epoch [7626/10000], Loss: 126.2375\n",
            "Epoch [7627/10000], Loss: 127.8761\n",
            "Epoch [7628/10000], Loss: 133.4886\n",
            "Epoch [7629/10000], Loss: 138.3160\n",
            "Epoch [7630/10000], Loss: 133.1860\n",
            "Epoch [7631/10000], Loss: 131.4350\n",
            "Epoch [7632/10000], Loss: 128.7914\n",
            "Epoch [7633/10000], Loss: 126.1034\n",
            "Epoch [7634/10000], Loss: 133.7004\n",
            "Epoch [7635/10000], Loss: 130.6947\n",
            "Epoch [7636/10000], Loss: 135.0937\n",
            "Epoch [7637/10000], Loss: 129.8845\n",
            "Epoch [7638/10000], Loss: 126.1735\n",
            "Epoch [7639/10000], Loss: 129.5849\n",
            "Epoch [7640/10000], Loss: 132.2728\n",
            "Epoch [7641/10000], Loss: 128.3358\n",
            "Epoch [7642/10000], Loss: 122.9942\n",
            "Epoch [7643/10000], Loss: 129.1215\n",
            "Epoch [7644/10000], Loss: 127.2007\n",
            "Epoch [7645/10000], Loss: 131.4413\n",
            "Epoch [7646/10000], Loss: 133.0880\n",
            "Epoch [7647/10000], Loss: 130.0164\n",
            "Epoch [7648/10000], Loss: 134.9141\n",
            "Epoch [7649/10000], Loss: 130.0762\n",
            "Epoch [7650/10000], Loss: 135.5524\n",
            "Epoch [7651/10000], Loss: 136.9054\n",
            "Epoch [7652/10000], Loss: 131.0248\n",
            "Epoch [7653/10000], Loss: 131.9209\n",
            "Epoch [7654/10000], Loss: 124.0700\n",
            "Epoch [7655/10000], Loss: 126.7328\n",
            "Epoch [7656/10000], Loss: 131.8834\n",
            "Epoch [7657/10000], Loss: 125.6392\n",
            "Epoch [7658/10000], Loss: 122.2606\n",
            "Epoch [7659/10000], Loss: 122.8494\n",
            "Epoch [7660/10000], Loss: 127.8269\n",
            "Epoch [7661/10000], Loss: 136.1665\n",
            "Epoch [7662/10000], Loss: 133.9529\n",
            "Epoch [7663/10000], Loss: 130.3344\n",
            "Epoch [7664/10000], Loss: 125.7494\n",
            "Epoch [7665/10000], Loss: 126.5728\n",
            "Epoch [7666/10000], Loss: 124.5323\n",
            "Epoch [7667/10000], Loss: 134.6530\n",
            "Epoch [7668/10000], Loss: 127.2934\n",
            "Epoch [7669/10000], Loss: 136.4913\n",
            "Epoch [7670/10000], Loss: 139.0818\n",
            "Epoch [7671/10000], Loss: 130.4359\n",
            "Epoch [7672/10000], Loss: 128.0263\n",
            "Epoch [7673/10000], Loss: 130.8926\n",
            "Epoch [7674/10000], Loss: 129.7116\n",
            "Epoch [7675/10000], Loss: 130.5198\n",
            "Epoch [7676/10000], Loss: 129.0185\n",
            "Epoch [7677/10000], Loss: 132.2397\n",
            "Epoch [7678/10000], Loss: 123.6387\n",
            "Epoch [7679/10000], Loss: 127.1650\n",
            "Epoch [7680/10000], Loss: 128.5083\n",
            "Epoch [7681/10000], Loss: 130.9592\n",
            "Epoch [7682/10000], Loss: 130.4764\n",
            "Epoch [7683/10000], Loss: 126.2265\n",
            "Epoch [7684/10000], Loss: 128.5332\n",
            "Epoch [7685/10000], Loss: 129.2376\n",
            "Epoch [7686/10000], Loss: 122.9154\n",
            "Epoch [7687/10000], Loss: 136.9563\n",
            "Epoch [7688/10000], Loss: 125.9911\n",
            "Epoch [7689/10000], Loss: 129.0093\n",
            "Epoch [7690/10000], Loss: 127.0176\n",
            "Epoch [7691/10000], Loss: 128.9977\n",
            "Epoch [7692/10000], Loss: 134.0097\n",
            "Epoch [7693/10000], Loss: 125.1687\n",
            "Epoch [7694/10000], Loss: 125.9431\n",
            "Epoch [7695/10000], Loss: 120.7275\n",
            "Epoch [7696/10000], Loss: 124.8700\n",
            "Epoch [7697/10000], Loss: 134.8210\n",
            "Epoch [7698/10000], Loss: 125.5137\n",
            "Epoch [7699/10000], Loss: 134.2264\n",
            "Epoch [7700/10000], Loss: 133.0266\n",
            "Epoch [7701/10000], Loss: 121.9270\n",
            "Epoch [7702/10000], Loss: 120.0913\n",
            "Epoch [7703/10000], Loss: 124.3273\n",
            "Epoch [7704/10000], Loss: 123.1570\n",
            "Epoch [7705/10000], Loss: 125.8842\n",
            "Epoch [7706/10000], Loss: 131.0730\n",
            "Epoch [7707/10000], Loss: 133.9638\n",
            "Epoch [7708/10000], Loss: 129.4976\n",
            "Epoch [7709/10000], Loss: 125.2133\n",
            "Epoch [7710/10000], Loss: 127.7120\n",
            "Epoch [7711/10000], Loss: 132.9459\n",
            "Epoch [7712/10000], Loss: 124.2769\n",
            "Epoch [7713/10000], Loss: 123.5883\n",
            "Epoch [7714/10000], Loss: 127.8292\n",
            "Epoch [7715/10000], Loss: 126.2595\n",
            "Epoch [7716/10000], Loss: 131.5294\n",
            "Epoch [7717/10000], Loss: 133.0005\n",
            "Epoch [7718/10000], Loss: 126.3129\n",
            "Epoch [7719/10000], Loss: 123.5957\n",
            "Epoch [7720/10000], Loss: 128.1100\n",
            "Epoch [7721/10000], Loss: 127.3958\n",
            "Epoch [7722/10000], Loss: 128.1377\n",
            "Epoch [7723/10000], Loss: 129.6218\n",
            "Epoch [7724/10000], Loss: 133.4364\n",
            "Epoch [7725/10000], Loss: 130.2378\n",
            "Epoch [7726/10000], Loss: 126.2146\n",
            "Epoch [7727/10000], Loss: 122.0293\n",
            "Epoch [7728/10000], Loss: 127.9444\n",
            "Epoch [7729/10000], Loss: 123.1801\n",
            "Epoch [7730/10000], Loss: 128.5115\n",
            "Epoch [7731/10000], Loss: 133.9053\n",
            "Epoch [7732/10000], Loss: 134.0815\n",
            "Epoch [7733/10000], Loss: 123.7900\n",
            "Epoch [7734/10000], Loss: 130.1439\n",
            "Epoch [7735/10000], Loss: 131.5799\n",
            "Epoch [7736/10000], Loss: 121.4485\n",
            "Epoch [7737/10000], Loss: 122.9958\n",
            "Epoch [7738/10000], Loss: 132.7820\n",
            "Epoch [7739/10000], Loss: 134.1527\n",
            "Epoch [7740/10000], Loss: 136.2423\n",
            "Epoch [7741/10000], Loss: 129.6752\n",
            "Epoch [7742/10000], Loss: 133.4608\n",
            "Epoch [7743/10000], Loss: 122.9155\n",
            "Epoch [7744/10000], Loss: 130.9093\n",
            "Epoch [7745/10000], Loss: 124.7880\n",
            "Epoch [7746/10000], Loss: 124.7225\n",
            "Epoch [7747/10000], Loss: 126.4243\n",
            "Epoch [7748/10000], Loss: 129.6939\n",
            "Epoch [7749/10000], Loss: 131.0483\n",
            "Epoch [7750/10000], Loss: 122.8429\n",
            "Epoch [7751/10000], Loss: 123.3973\n",
            "Epoch [7752/10000], Loss: 124.4446\n",
            "Epoch [7753/10000], Loss: 131.6673\n",
            "Epoch [7754/10000], Loss: 123.9732\n",
            "Epoch [7755/10000], Loss: 126.8095\n",
            "Epoch [7756/10000], Loss: 127.0809\n",
            "Epoch [7757/10000], Loss: 126.8071\n",
            "Epoch [7758/10000], Loss: 125.1692\n",
            "Epoch [7759/10000], Loss: 126.0592\n",
            "Epoch [7760/10000], Loss: 123.6555\n",
            "Epoch [7761/10000], Loss: 119.6690\n",
            "Epoch [7762/10000], Loss: 127.5598\n",
            "Epoch [7763/10000], Loss: 124.8877\n",
            "Epoch [7764/10000], Loss: 124.9258\n",
            "Epoch [7765/10000], Loss: 127.8633\n",
            "Epoch [7766/10000], Loss: 132.2377\n",
            "Epoch [7767/10000], Loss: 125.9471\n",
            "Epoch [7768/10000], Loss: 124.2839\n",
            "Epoch [7769/10000], Loss: 129.3150\n",
            "Epoch [7770/10000], Loss: 128.8377\n",
            "Epoch [7771/10000], Loss: 122.1180\n",
            "Epoch [7772/10000], Loss: 122.5408\n",
            "Epoch [7773/10000], Loss: 130.8583\n",
            "Epoch [7774/10000], Loss: 134.0587\n",
            "Epoch [7775/10000], Loss: 131.0822\n",
            "Epoch [7776/10000], Loss: 127.6944\n",
            "Epoch [7777/10000], Loss: 126.3006\n",
            "Epoch [7778/10000], Loss: 118.6437\n",
            "Epoch [7779/10000], Loss: 127.1770\n",
            "Epoch [7780/10000], Loss: 130.3552\n",
            "Epoch [7781/10000], Loss: 133.6441\n",
            "Epoch [7782/10000], Loss: 122.1856\n",
            "Epoch [7783/10000], Loss: 127.5488\n",
            "Epoch [7784/10000], Loss: 128.3065\n",
            "Epoch [7785/10000], Loss: 129.2116\n",
            "Epoch [7786/10000], Loss: 125.7690\n",
            "Epoch [7787/10000], Loss: 125.3773\n",
            "Epoch [7788/10000], Loss: 119.5509\n",
            "Epoch [7789/10000], Loss: 125.7380\n",
            "Epoch [7790/10000], Loss: 126.6084\n",
            "Epoch [7791/10000], Loss: 128.8137\n",
            "Epoch [7792/10000], Loss: 123.3611\n",
            "Epoch [7793/10000], Loss: 124.1110\n",
            "Epoch [7794/10000], Loss: 126.9683\n",
            "Epoch [7795/10000], Loss: 126.7476\n",
            "Epoch [7796/10000], Loss: 127.8945\n",
            "Epoch [7797/10000], Loss: 128.3627\n",
            "Epoch [7798/10000], Loss: 119.1736\n",
            "Epoch [7799/10000], Loss: 125.8155\n",
            "Epoch [7800/10000], Loss: 124.3635\n",
            "Epoch [7801/10000], Loss: 122.6716\n",
            "Epoch [7802/10000], Loss: 126.6623\n",
            "Epoch [7803/10000], Loss: 124.5603\n",
            "Epoch [7804/10000], Loss: 127.6270\n",
            "Epoch [7805/10000], Loss: 131.4225\n",
            "Epoch [7806/10000], Loss: 123.8748\n",
            "Epoch [7807/10000], Loss: 134.6619\n",
            "Epoch [7808/10000], Loss: 132.3385\n",
            "Epoch [7809/10000], Loss: 124.9309\n",
            "Epoch [7810/10000], Loss: 118.1289\n",
            "Epoch [7811/10000], Loss: 123.0637\n",
            "Epoch [7812/10000], Loss: 126.9608\n",
            "Epoch [7813/10000], Loss: 133.6652\n",
            "Epoch [7814/10000], Loss: 124.6490\n",
            "Epoch [7815/10000], Loss: 127.6672\n",
            "Epoch [7816/10000], Loss: 134.7034\n",
            "Epoch [7817/10000], Loss: 126.2844\n",
            "Epoch [7818/10000], Loss: 124.4799\n",
            "Epoch [7819/10000], Loss: 123.6338\n",
            "Epoch [7820/10000], Loss: 130.9199\n",
            "Epoch [7821/10000], Loss: 126.0603\n",
            "Epoch [7822/10000], Loss: 123.1511\n",
            "Epoch [7823/10000], Loss: 119.2232\n",
            "Epoch [7824/10000], Loss: 129.5526\n",
            "Epoch [7825/10000], Loss: 119.1602\n",
            "Epoch [7826/10000], Loss: 129.1826\n",
            "Epoch [7827/10000], Loss: 124.9489\n",
            "Epoch [7828/10000], Loss: 125.3471\n",
            "Epoch [7829/10000], Loss: 127.3130\n",
            "Epoch [7830/10000], Loss: 124.0073\n",
            "Epoch [7831/10000], Loss: 126.5578\n",
            "Epoch [7832/10000], Loss: 127.8962\n",
            "Epoch [7833/10000], Loss: 117.0270\n",
            "Epoch [7834/10000], Loss: 127.9160\n",
            "Epoch [7835/10000], Loss: 123.2747\n",
            "Epoch [7836/10000], Loss: 123.5555\n",
            "Epoch [7837/10000], Loss: 125.3329\n",
            "Epoch [7838/10000], Loss: 123.0192\n",
            "Epoch [7839/10000], Loss: 123.1549\n",
            "Epoch [7840/10000], Loss: 125.6454\n",
            "Epoch [7841/10000], Loss: 133.6582\n",
            "Epoch [7842/10000], Loss: 117.7303\n",
            "Epoch [7843/10000], Loss: 119.7193\n",
            "Epoch [7844/10000], Loss: 125.0106\n",
            "Epoch [7845/10000], Loss: 128.1192\n",
            "Epoch [7846/10000], Loss: 127.6475\n",
            "Epoch [7847/10000], Loss: 127.7646\n",
            "Epoch [7848/10000], Loss: 128.3603\n",
            "Epoch [7849/10000], Loss: 121.0226\n",
            "Epoch [7850/10000], Loss: 131.1589\n",
            "Epoch [7851/10000], Loss: 122.6641\n",
            "Epoch [7852/10000], Loss: 131.3185\n",
            "Epoch [7853/10000], Loss: 129.7114\n",
            "Epoch [7854/10000], Loss: 130.1496\n",
            "Epoch [7855/10000], Loss: 126.4566\n",
            "Epoch [7856/10000], Loss: 120.3077\n",
            "Epoch [7857/10000], Loss: 127.0712\n",
            "Epoch [7858/10000], Loss: 129.1194\n",
            "Epoch [7859/10000], Loss: 133.4101\n",
            "Epoch [7860/10000], Loss: 125.9411\n",
            "Epoch [7861/10000], Loss: 121.0219\n",
            "Epoch [7862/10000], Loss: 124.8002\n",
            "Epoch [7863/10000], Loss: 122.6861\n",
            "Epoch [7864/10000], Loss: 125.1561\n",
            "Epoch [7865/10000], Loss: 123.9778\n",
            "Epoch [7866/10000], Loss: 125.5064\n",
            "Epoch [7867/10000], Loss: 124.6683\n",
            "Epoch [7868/10000], Loss: 118.0970\n",
            "Epoch [7869/10000], Loss: 120.7656\n",
            "Epoch [7870/10000], Loss: 128.1232\n",
            "Epoch [7871/10000], Loss: 127.1983\n",
            "Epoch [7872/10000], Loss: 124.7075\n",
            "Epoch [7873/10000], Loss: 129.0785\n",
            "Epoch [7874/10000], Loss: 119.8855\n",
            "Epoch [7875/10000], Loss: 122.4151\n",
            "Epoch [7876/10000], Loss: 120.5935\n",
            "Epoch [7877/10000], Loss: 122.8012\n",
            "Epoch [7878/10000], Loss: 127.0750\n",
            "Epoch [7879/10000], Loss: 123.0824\n",
            "Epoch [7880/10000], Loss: 123.4147\n",
            "Epoch [7881/10000], Loss: 121.9609\n",
            "Epoch [7882/10000], Loss: 126.1015\n",
            "Epoch [7883/10000], Loss: 122.1826\n",
            "Epoch [7884/10000], Loss: 124.8208\n",
            "Epoch [7885/10000], Loss: 119.8272\n",
            "Epoch [7886/10000], Loss: 121.9752\n",
            "Epoch [7887/10000], Loss: 117.3998\n",
            "Epoch [7888/10000], Loss: 125.6598\n",
            "Epoch [7889/10000], Loss: 117.1514\n",
            "Epoch [7890/10000], Loss: 121.7962\n",
            "Epoch [7891/10000], Loss: 116.0727\n",
            "Epoch [7892/10000], Loss: 121.5137\n",
            "Epoch [7893/10000], Loss: 120.7281\n",
            "Epoch [7894/10000], Loss: 122.1231\n",
            "Epoch [7895/10000], Loss: 132.8823\n",
            "Epoch [7896/10000], Loss: 123.9970\n",
            "Epoch [7897/10000], Loss: 123.8514\n",
            "Epoch [7898/10000], Loss: 120.6327\n",
            "Epoch [7899/10000], Loss: 125.2058\n",
            "Epoch [7900/10000], Loss: 121.2257\n",
            "Epoch [7901/10000], Loss: 120.2131\n",
            "Epoch [7902/10000], Loss: 120.8594\n",
            "Epoch [7903/10000], Loss: 123.4581\n",
            "Epoch [7904/10000], Loss: 120.6085\n",
            "Epoch [7905/10000], Loss: 127.7575\n",
            "Epoch [7906/10000], Loss: 121.4265\n",
            "Epoch [7907/10000], Loss: 121.4775\n",
            "Epoch [7908/10000], Loss: 126.4475\n",
            "Epoch [7909/10000], Loss: 117.6715\n",
            "Epoch [7910/10000], Loss: 127.7504\n",
            "Epoch [7911/10000], Loss: 115.9322\n",
            "Epoch [7912/10000], Loss: 117.4285\n",
            "Epoch [7913/10000], Loss: 124.9920\n",
            "Epoch [7914/10000], Loss: 119.4868\n",
            "Epoch [7915/10000], Loss: 124.9731\n",
            "Epoch [7916/10000], Loss: 129.4183\n",
            "Epoch [7917/10000], Loss: 125.7580\n",
            "Epoch [7918/10000], Loss: 126.9540\n",
            "Epoch [7919/10000], Loss: 126.5664\n",
            "Epoch [7920/10000], Loss: 119.6070\n",
            "Epoch [7921/10000], Loss: 124.1418\n",
            "Epoch [7922/10000], Loss: 136.3451\n",
            "Epoch [7923/10000], Loss: 121.2661\n",
            "Epoch [7924/10000], Loss: 120.4305\n",
            "Epoch [7925/10000], Loss: 114.6148\n",
            "Epoch [7926/10000], Loss: 120.4142\n",
            "Epoch [7927/10000], Loss: 127.9058\n",
            "Epoch [7928/10000], Loss: 119.9203\n",
            "Epoch [7929/10000], Loss: 131.5417\n",
            "Epoch [7930/10000], Loss: 119.2377\n",
            "Epoch [7931/10000], Loss: 120.4144\n",
            "Epoch [7932/10000], Loss: 121.4456\n",
            "Epoch [7933/10000], Loss: 119.3653\n",
            "Epoch [7934/10000], Loss: 123.9102\n",
            "Epoch [7935/10000], Loss: 118.7087\n",
            "Epoch [7936/10000], Loss: 124.7792\n",
            "Epoch [7937/10000], Loss: 123.5248\n",
            "Epoch [7938/10000], Loss: 118.1342\n",
            "Epoch [7939/10000], Loss: 131.6108\n",
            "Epoch [7940/10000], Loss: 129.7684\n",
            "Epoch [7941/10000], Loss: 131.2554\n",
            "Epoch [7942/10000], Loss: 133.2495\n",
            "Epoch [7943/10000], Loss: 118.3052\n",
            "Epoch [7944/10000], Loss: 127.8314\n",
            "Epoch [7945/10000], Loss: 120.5209\n",
            "Epoch [7946/10000], Loss: 119.5364\n",
            "Epoch [7947/10000], Loss: 123.3519\n",
            "Epoch [7948/10000], Loss: 129.9432\n",
            "Epoch [7949/10000], Loss: 120.9928\n",
            "Epoch [7950/10000], Loss: 117.2953\n",
            "Epoch [7951/10000], Loss: 123.5158\n",
            "Epoch [7952/10000], Loss: 127.7778\n",
            "Epoch [7953/10000], Loss: 124.2174\n",
            "Epoch [7954/10000], Loss: 126.3655\n",
            "Epoch [7955/10000], Loss: 125.6843\n",
            "Epoch [7956/10000], Loss: 124.3262\n",
            "Epoch [7957/10000], Loss: 121.6811\n",
            "Epoch [7958/10000], Loss: 118.9452\n",
            "Epoch [7959/10000], Loss: 121.3012\n",
            "Epoch [7960/10000], Loss: 118.8915\n",
            "Epoch [7961/10000], Loss: 122.6737\n",
            "Epoch [7962/10000], Loss: 119.9613\n",
            "Epoch [7963/10000], Loss: 118.5962\n",
            "Epoch [7964/10000], Loss: 124.1875\n",
            "Epoch [7965/10000], Loss: 123.1858\n",
            "Epoch [7966/10000], Loss: 116.5212\n",
            "Epoch [7967/10000], Loss: 121.1387\n",
            "Epoch [7968/10000], Loss: 114.5611\n",
            "Epoch [7969/10000], Loss: 116.2270\n",
            "Epoch [7970/10000], Loss: 123.0125\n",
            "Epoch [7971/10000], Loss: 119.2502\n",
            "Epoch [7972/10000], Loss: 125.4245\n",
            "Epoch [7973/10000], Loss: 118.7798\n",
            "Epoch [7974/10000], Loss: 121.9686\n",
            "Epoch [7975/10000], Loss: 117.1314\n",
            "Epoch [7976/10000], Loss: 120.5866\n",
            "Epoch [7977/10000], Loss: 123.4491\n",
            "Epoch [7978/10000], Loss: 125.7612\n",
            "Epoch [7979/10000], Loss: 120.3595\n",
            "Epoch [7980/10000], Loss: 124.2432\n",
            "Epoch [7981/10000], Loss: 118.7044\n",
            "Epoch [7982/10000], Loss: 131.2855\n",
            "Epoch [7983/10000], Loss: 128.6415\n",
            "Epoch [7984/10000], Loss: 116.4293\n",
            "Epoch [7985/10000], Loss: 118.9809\n",
            "Epoch [7986/10000], Loss: 122.1969\n",
            "Epoch [7987/10000], Loss: 124.1610\n",
            "Epoch [7988/10000], Loss: 124.3190\n",
            "Epoch [7989/10000], Loss: 115.6781\n",
            "Epoch [7990/10000], Loss: 114.5648\n",
            "Epoch [7991/10000], Loss: 124.2292\n",
            "Epoch [7992/10000], Loss: 120.3145\n",
            "Epoch [7993/10000], Loss: 126.5364\n",
            "Epoch [7994/10000], Loss: 122.3251\n",
            "Epoch [7995/10000], Loss: 121.2972\n",
            "Epoch [7996/10000], Loss: 123.8463\n",
            "Epoch [7997/10000], Loss: 124.1531\n",
            "Epoch [7998/10000], Loss: 124.9416\n",
            "Epoch [7999/10000], Loss: 117.4258\n",
            "Epoch [8000/10000], Loss: 120.9151\n",
            "Epoch [8001/10000], Loss: 123.3535\n",
            "Epoch [8002/10000], Loss: 120.2735\n",
            "Epoch [8003/10000], Loss: 126.6809\n",
            "Epoch [8004/10000], Loss: 123.7180\n",
            "Epoch [8005/10000], Loss: 118.0460\n",
            "Epoch [8006/10000], Loss: 132.0595\n",
            "Epoch [8007/10000], Loss: 122.5185\n",
            "Epoch [8008/10000], Loss: 120.1048\n",
            "Epoch [8009/10000], Loss: 123.0449\n",
            "Epoch [8010/10000], Loss: 122.3852\n",
            "Epoch [8011/10000], Loss: 119.0293\n",
            "Epoch [8012/10000], Loss: 119.0396\n",
            "Epoch [8013/10000], Loss: 121.6495\n",
            "Epoch [8014/10000], Loss: 120.2630\n",
            "Epoch [8015/10000], Loss: 120.9361\n",
            "Epoch [8016/10000], Loss: 123.0522\n",
            "Epoch [8017/10000], Loss: 122.9971\n",
            "Epoch [8018/10000], Loss: 122.4242\n",
            "Epoch [8019/10000], Loss: 113.7433\n",
            "Epoch [8020/10000], Loss: 124.1074\n",
            "Epoch [8021/10000], Loss: 123.7395\n",
            "Epoch [8022/10000], Loss: 123.7559\n",
            "Epoch [8023/10000], Loss: 119.4724\n",
            "Epoch [8024/10000], Loss: 116.9942\n",
            "Epoch [8025/10000], Loss: 125.2398\n",
            "Epoch [8026/10000], Loss: 115.2119\n",
            "Epoch [8027/10000], Loss: 127.3323\n",
            "Epoch [8028/10000], Loss: 123.1299\n",
            "Epoch [8029/10000], Loss: 117.0931\n",
            "Epoch [8030/10000], Loss: 120.2845\n",
            "Epoch [8031/10000], Loss: 116.0040\n",
            "Epoch [8032/10000], Loss: 121.2096\n",
            "Epoch [8033/10000], Loss: 116.4119\n",
            "Epoch [8034/10000], Loss: 122.3629\n",
            "Epoch [8035/10000], Loss: 122.9214\n",
            "Epoch [8036/10000], Loss: 123.5342\n",
            "Epoch [8037/10000], Loss: 120.8839\n",
            "Epoch [8038/10000], Loss: 119.3727\n",
            "Epoch [8039/10000], Loss: 125.7782\n",
            "Epoch [8040/10000], Loss: 115.9526\n",
            "Epoch [8041/10000], Loss: 114.6183\n",
            "Epoch [8042/10000], Loss: 124.3960\n",
            "Epoch [8043/10000], Loss: 120.9138\n",
            "Epoch [8044/10000], Loss: 118.5730\n",
            "Epoch [8045/10000], Loss: 121.6772\n",
            "Epoch [8046/10000], Loss: 119.5749\n",
            "Epoch [8047/10000], Loss: 115.4238\n",
            "Epoch [8048/10000], Loss: 115.6546\n",
            "Epoch [8049/10000], Loss: 118.3286\n",
            "Epoch [8050/10000], Loss: 128.2280\n",
            "Epoch [8051/10000], Loss: 114.0982\n",
            "Epoch [8052/10000], Loss: 119.2194\n",
            "Epoch [8053/10000], Loss: 117.9877\n",
            "Epoch [8054/10000], Loss: 120.2649\n",
            "Epoch [8055/10000], Loss: 121.2651\n",
            "Epoch [8056/10000], Loss: 123.8195\n",
            "Epoch [8057/10000], Loss: 122.4382\n",
            "Epoch [8058/10000], Loss: 127.9508\n",
            "Epoch [8059/10000], Loss: 122.0479\n",
            "Epoch [8060/10000], Loss: 120.2024\n",
            "Epoch [8061/10000], Loss: 119.6911\n",
            "Epoch [8062/10000], Loss: 114.6453\n",
            "Epoch [8063/10000], Loss: 128.8386\n",
            "Epoch [8064/10000], Loss: 119.9438\n",
            "Epoch [8065/10000], Loss: 126.8932\n",
            "Epoch [8066/10000], Loss: 121.1815\n",
            "Epoch [8067/10000], Loss: 124.2823\n",
            "Epoch [8068/10000], Loss: 121.3668\n",
            "Epoch [8069/10000], Loss: 122.4752\n",
            "Epoch [8070/10000], Loss: 122.5947\n",
            "Epoch [8071/10000], Loss: 119.5160\n",
            "Epoch [8072/10000], Loss: 118.5393\n",
            "Epoch [8073/10000], Loss: 122.4196\n",
            "Epoch [8074/10000], Loss: 113.7876\n",
            "Epoch [8075/10000], Loss: 114.8193\n",
            "Epoch [8076/10000], Loss: 119.5970\n",
            "Epoch [8077/10000], Loss: 120.3561\n",
            "Epoch [8078/10000], Loss: 121.0954\n",
            "Epoch [8079/10000], Loss: 118.9311\n",
            "Epoch [8080/10000], Loss: 120.0217\n",
            "Epoch [8081/10000], Loss: 124.6364\n",
            "Epoch [8082/10000], Loss: 116.1591\n",
            "Epoch [8083/10000], Loss: 113.8003\n",
            "Epoch [8084/10000], Loss: 116.7181\n",
            "Epoch [8085/10000], Loss: 116.9597\n",
            "Epoch [8086/10000], Loss: 116.5583\n",
            "Epoch [8087/10000], Loss: 123.6387\n",
            "Epoch [8088/10000], Loss: 125.0060\n",
            "Epoch [8089/10000], Loss: 119.1298\n",
            "Epoch [8090/10000], Loss: 115.7261\n",
            "Epoch [8091/10000], Loss: 117.2696\n",
            "Epoch [8092/10000], Loss: 118.5229\n",
            "Epoch [8093/10000], Loss: 115.4049\n",
            "Epoch [8094/10000], Loss: 125.0890\n",
            "Epoch [8095/10000], Loss: 112.3848\n",
            "Epoch [8096/10000], Loss: 115.8210\n",
            "Epoch [8097/10000], Loss: 125.7012\n",
            "Epoch [8098/10000], Loss: 119.4573\n",
            "Epoch [8099/10000], Loss: 115.4442\n",
            "Epoch [8100/10000], Loss: 117.9544\n",
            "Epoch [8101/10000], Loss: 112.9683\n",
            "Epoch [8102/10000], Loss: 117.2129\n",
            "Epoch [8103/10000], Loss: 116.8303\n",
            "Epoch [8104/10000], Loss: 115.0348\n",
            "Epoch [8105/10000], Loss: 119.8941\n",
            "Epoch [8106/10000], Loss: 111.3256\n",
            "Epoch [8107/10000], Loss: 118.4100\n",
            "Epoch [8108/10000], Loss: 122.7962\n",
            "Epoch [8109/10000], Loss: 117.8762\n",
            "Epoch [8110/10000], Loss: 123.3570\n",
            "Epoch [8111/10000], Loss: 123.0492\n",
            "Epoch [8112/10000], Loss: 115.8500\n",
            "Epoch [8113/10000], Loss: 119.3606\n",
            "Epoch [8114/10000], Loss: 123.6622\n",
            "Epoch [8115/10000], Loss: 110.0867\n",
            "Epoch [8116/10000], Loss: 122.7425\n",
            "Epoch [8117/10000], Loss: 125.8370\n",
            "Epoch [8118/10000], Loss: 122.6795\n",
            "Epoch [8119/10000], Loss: 120.9335\n",
            "Epoch [8120/10000], Loss: 121.5749\n",
            "Epoch [8121/10000], Loss: 115.9252\n",
            "Epoch [8122/10000], Loss: 118.9638\n",
            "Epoch [8123/10000], Loss: 119.9685\n",
            "Epoch [8124/10000], Loss: 123.2856\n",
            "Epoch [8125/10000], Loss: 116.4817\n",
            "Epoch [8126/10000], Loss: 121.5945\n",
            "Epoch [8127/10000], Loss: 113.9593\n",
            "Epoch [8128/10000], Loss: 127.7073\n",
            "Epoch [8129/10000], Loss: 118.3465\n",
            "Epoch [8130/10000], Loss: 118.5354\n",
            "Epoch [8131/10000], Loss: 116.4527\n",
            "Epoch [8132/10000], Loss: 123.0673\n",
            "Epoch [8133/10000], Loss: 111.8699\n",
            "Epoch [8134/10000], Loss: 113.5581\n",
            "Epoch [8135/10000], Loss: 114.7413\n",
            "Epoch [8136/10000], Loss: 113.2650\n",
            "Epoch [8137/10000], Loss: 120.5224\n",
            "Epoch [8138/10000], Loss: 115.9061\n",
            "Epoch [8139/10000], Loss: 115.4497\n",
            "Epoch [8140/10000], Loss: 119.4245\n",
            "Epoch [8141/10000], Loss: 123.5156\n",
            "Epoch [8142/10000], Loss: 118.2598\n",
            "Epoch [8143/10000], Loss: 117.6614\n",
            "Epoch [8144/10000], Loss: 118.6301\n",
            "Epoch [8145/10000], Loss: 114.4040\n",
            "Epoch [8146/10000], Loss: 123.1908\n",
            "Epoch [8147/10000], Loss: 125.7158\n",
            "Epoch [8148/10000], Loss: 111.1397\n",
            "Epoch [8149/10000], Loss: 111.1208\n",
            "Epoch [8150/10000], Loss: 115.2474\n",
            "Epoch [8151/10000], Loss: 111.7703\n",
            "Epoch [8152/10000], Loss: 119.7059\n",
            "Epoch [8153/10000], Loss: 121.3737\n",
            "Epoch [8154/10000], Loss: 114.0863\n",
            "Epoch [8155/10000], Loss: 115.3408\n",
            "Epoch [8156/10000], Loss: 113.9302\n",
            "Epoch [8157/10000], Loss: 124.0464\n",
            "Epoch [8158/10000], Loss: 120.1472\n",
            "Epoch [8159/10000], Loss: 112.8795\n",
            "Epoch [8160/10000], Loss: 116.1757\n",
            "Epoch [8161/10000], Loss: 121.7182\n",
            "Epoch [8162/10000], Loss: 116.2945\n",
            "Epoch [8163/10000], Loss: 108.7531\n",
            "Epoch [8164/10000], Loss: 117.6914\n",
            "Epoch [8165/10000], Loss: 121.4047\n",
            "Epoch [8166/10000], Loss: 119.0908\n",
            "Epoch [8167/10000], Loss: 115.3538\n",
            "Epoch [8168/10000], Loss: 119.7891\n",
            "Epoch [8169/10000], Loss: 108.3800\n",
            "Epoch [8170/10000], Loss: 117.1240\n",
            "Epoch [8171/10000], Loss: 120.3058\n",
            "Epoch [8172/10000], Loss: 122.4948\n",
            "Epoch [8173/10000], Loss: 117.9855\n",
            "Epoch [8174/10000], Loss: 110.3272\n",
            "Epoch [8175/10000], Loss: 117.8995\n",
            "Epoch [8176/10000], Loss: 111.2050\n",
            "Epoch [8177/10000], Loss: 121.8226\n",
            "Epoch [8178/10000], Loss: 121.0240\n",
            "Epoch [8179/10000], Loss: 116.8797\n",
            "Epoch [8180/10000], Loss: 118.3241\n",
            "Epoch [8181/10000], Loss: 117.5281\n",
            "Epoch [8182/10000], Loss: 120.9525\n",
            "Epoch [8183/10000], Loss: 115.4831\n",
            "Epoch [8184/10000], Loss: 117.0717\n",
            "Epoch [8185/10000], Loss: 114.0412\n",
            "Epoch [8186/10000], Loss: 117.9239\n",
            "Epoch [8187/10000], Loss: 116.0208\n",
            "Epoch [8188/10000], Loss: 113.5622\n",
            "Epoch [8189/10000], Loss: 118.1471\n",
            "Epoch [8190/10000], Loss: 124.9454\n",
            "Epoch [8191/10000], Loss: 120.9593\n",
            "Epoch [8192/10000], Loss: 115.8753\n",
            "Epoch [8193/10000], Loss: 111.9748\n",
            "Epoch [8194/10000], Loss: 122.7562\n",
            "Epoch [8195/10000], Loss: 118.3175\n",
            "Epoch [8196/10000], Loss: 109.9091\n",
            "Epoch [8197/10000], Loss: 118.0286\n",
            "Epoch [8198/10000], Loss: 119.0816\n",
            "Epoch [8199/10000], Loss: 111.8754\n",
            "Epoch [8200/10000], Loss: 121.7327\n",
            "Epoch [8201/10000], Loss: 112.0960\n",
            "Epoch [8202/10000], Loss: 121.9166\n",
            "Epoch [8203/10000], Loss: 114.9301\n",
            "Epoch [8204/10000], Loss: 115.8295\n",
            "Epoch [8205/10000], Loss: 122.4336\n",
            "Epoch [8206/10000], Loss: 116.6754\n",
            "Epoch [8207/10000], Loss: 114.0319\n",
            "Epoch [8208/10000], Loss: 116.0861\n",
            "Epoch [8209/10000], Loss: 116.7337\n",
            "Epoch [8210/10000], Loss: 115.5104\n",
            "Epoch [8211/10000], Loss: 120.5277\n",
            "Epoch [8212/10000], Loss: 118.7634\n",
            "Epoch [8213/10000], Loss: 114.9146\n",
            "Epoch [8214/10000], Loss: 117.8684\n",
            "Epoch [8215/10000], Loss: 118.0848\n",
            "Epoch [8216/10000], Loss: 119.9947\n",
            "Epoch [8217/10000], Loss: 117.0733\n",
            "Epoch [8218/10000], Loss: 118.3527\n",
            "Epoch [8219/10000], Loss: 119.4812\n",
            "Epoch [8220/10000], Loss: 117.8469\n",
            "Epoch [8221/10000], Loss: 116.1308\n",
            "Epoch [8222/10000], Loss: 115.4054\n",
            "Epoch [8223/10000], Loss: 122.3056\n",
            "Epoch [8224/10000], Loss: 119.0225\n",
            "Epoch [8225/10000], Loss: 118.6068\n",
            "Epoch [8226/10000], Loss: 117.2115\n",
            "Epoch [8227/10000], Loss: 117.7145\n",
            "Epoch [8228/10000], Loss: 123.8582\n",
            "Epoch [8229/10000], Loss: 113.2142\n",
            "Epoch [8230/10000], Loss: 116.6567\n",
            "Epoch [8231/10000], Loss: 115.2825\n",
            "Epoch [8232/10000], Loss: 110.4841\n",
            "Epoch [8233/10000], Loss: 114.1226\n",
            "Epoch [8234/10000], Loss: 117.9948\n",
            "Epoch [8235/10000], Loss: 115.6734\n",
            "Epoch [8236/10000], Loss: 113.2306\n",
            "Epoch [8237/10000], Loss: 114.4498\n",
            "Epoch [8238/10000], Loss: 111.8750\n",
            "Epoch [8239/10000], Loss: 117.1398\n",
            "Epoch [8240/10000], Loss: 117.6378\n",
            "Epoch [8241/10000], Loss: 118.6503\n",
            "Epoch [8242/10000], Loss: 108.9955\n",
            "Epoch [8243/10000], Loss: 116.8279\n",
            "Epoch [8244/10000], Loss: 113.4089\n",
            "Epoch [8245/10000], Loss: 117.6208\n",
            "Epoch [8246/10000], Loss: 123.5922\n",
            "Epoch [8247/10000], Loss: 120.5915\n",
            "Epoch [8248/10000], Loss: 111.0567\n",
            "Epoch [8249/10000], Loss: 117.6050\n",
            "Epoch [8250/10000], Loss: 119.1390\n",
            "Epoch [8251/10000], Loss: 117.9920\n",
            "Epoch [8252/10000], Loss: 116.8586\n",
            "Epoch [8253/10000], Loss: 119.6716\n",
            "Epoch [8254/10000], Loss: 116.0706\n",
            "Epoch [8255/10000], Loss: 113.5602\n",
            "Epoch [8256/10000], Loss: 114.2544\n",
            "Epoch [8257/10000], Loss: 119.6220\n",
            "Epoch [8258/10000], Loss: 117.2083\n",
            "Epoch [8259/10000], Loss: 120.3049\n",
            "Epoch [8260/10000], Loss: 113.4086\n",
            "Epoch [8261/10000], Loss: 115.3215\n",
            "Epoch [8262/10000], Loss: 115.5515\n",
            "Epoch [8263/10000], Loss: 120.7549\n",
            "Epoch [8264/10000], Loss: 109.9902\n",
            "Epoch [8265/10000], Loss: 116.0744\n",
            "Epoch [8266/10000], Loss: 116.1384\n",
            "Epoch [8267/10000], Loss: 118.4182\n",
            "Epoch [8268/10000], Loss: 115.0016\n",
            "Epoch [8269/10000], Loss: 118.0156\n",
            "Epoch [8270/10000], Loss: 110.6181\n",
            "Epoch [8271/10000], Loss: 119.6574\n",
            "Epoch [8272/10000], Loss: 120.3768\n",
            "Epoch [8273/10000], Loss: 119.3500\n",
            "Epoch [8274/10000], Loss: 117.4864\n",
            "Epoch [8275/10000], Loss: 116.6761\n",
            "Epoch [8276/10000], Loss: 112.9301\n",
            "Epoch [8277/10000], Loss: 114.0979\n",
            "Epoch [8278/10000], Loss: 115.9327\n",
            "Epoch [8279/10000], Loss: 115.1561\n",
            "Epoch [8280/10000], Loss: 112.1053\n",
            "Epoch [8281/10000], Loss: 115.2529\n",
            "Epoch [8282/10000], Loss: 113.1335\n",
            "Epoch [8283/10000], Loss: 117.0321\n",
            "Epoch [8284/10000], Loss: 112.7675\n",
            "Epoch [8285/10000], Loss: 113.1930\n",
            "Epoch [8286/10000], Loss: 120.5820\n",
            "Epoch [8287/10000], Loss: 116.9894\n",
            "Epoch [8288/10000], Loss: 113.1869\n",
            "Epoch [8289/10000], Loss: 116.1523\n",
            "Epoch [8290/10000], Loss: 116.1505\n",
            "Epoch [8291/10000], Loss: 120.0736\n",
            "Epoch [8292/10000], Loss: 118.3404\n",
            "Epoch [8293/10000], Loss: 116.4456\n",
            "Epoch [8294/10000], Loss: 122.8548\n",
            "Epoch [8295/10000], Loss: 113.8024\n",
            "Epoch [8296/10000], Loss: 123.7567\n",
            "Epoch [8297/10000], Loss: 116.9165\n",
            "Epoch [8298/10000], Loss: 116.7825\n",
            "Epoch [8299/10000], Loss: 115.5621\n",
            "Epoch [8300/10000], Loss: 113.1586\n",
            "Epoch [8301/10000], Loss: 114.5467\n",
            "Epoch [8302/10000], Loss: 109.4305\n",
            "Epoch [8303/10000], Loss: 118.2464\n",
            "Epoch [8304/10000], Loss: 117.1088\n",
            "Epoch [8305/10000], Loss: 111.9050\n",
            "Epoch [8306/10000], Loss: 121.6440\n",
            "Epoch [8307/10000], Loss: 113.5715\n",
            "Epoch [8308/10000], Loss: 116.3504\n",
            "Epoch [8309/10000], Loss: 109.0215\n",
            "Epoch [8310/10000], Loss: 118.2762\n",
            "Epoch [8311/10000], Loss: 115.8905\n",
            "Epoch [8312/10000], Loss: 120.6950\n",
            "Epoch [8313/10000], Loss: 115.5336\n",
            "Epoch [8314/10000], Loss: 114.0069\n",
            "Epoch [8315/10000], Loss: 112.9197\n",
            "Epoch [8316/10000], Loss: 111.3814\n",
            "Epoch [8317/10000], Loss: 116.5534\n",
            "Epoch [8318/10000], Loss: 112.6469\n",
            "Epoch [8319/10000], Loss: 112.4809\n",
            "Epoch [8320/10000], Loss: 114.2054\n",
            "Epoch [8321/10000], Loss: 112.3980\n",
            "Epoch [8322/10000], Loss: 111.4983\n",
            "Epoch [8323/10000], Loss: 116.7233\n",
            "Epoch [8324/10000], Loss: 118.1981\n",
            "Epoch [8325/10000], Loss: 115.7870\n",
            "Epoch [8326/10000], Loss: 114.7555\n",
            "Epoch [8327/10000], Loss: 111.5212\n",
            "Epoch [8328/10000], Loss: 113.9155\n",
            "Epoch [8329/10000], Loss: 112.2742\n",
            "Epoch [8330/10000], Loss: 115.6304\n",
            "Epoch [8331/10000], Loss: 115.3967\n",
            "Epoch [8332/10000], Loss: 108.3714\n",
            "Epoch [8333/10000], Loss: 115.1692\n",
            "Epoch [8334/10000], Loss: 111.9998\n",
            "Epoch [8335/10000], Loss: 117.1047\n",
            "Epoch [8336/10000], Loss: 110.1828\n",
            "Epoch [8337/10000], Loss: 112.8307\n",
            "Epoch [8338/10000], Loss: 124.4439\n",
            "Epoch [8339/10000], Loss: 121.5011\n",
            "Epoch [8340/10000], Loss: 112.4563\n",
            "Epoch [8341/10000], Loss: 119.0731\n",
            "Epoch [8342/10000], Loss: 118.3046\n",
            "Epoch [8343/10000], Loss: 114.5751\n",
            "Epoch [8344/10000], Loss: 114.5113\n",
            "Epoch [8345/10000], Loss: 116.0036\n",
            "Epoch [8346/10000], Loss: 108.3945\n",
            "Epoch [8347/10000], Loss: 120.1345\n",
            "Epoch [8348/10000], Loss: 110.9679\n",
            "Epoch [8349/10000], Loss: 114.3829\n",
            "Epoch [8350/10000], Loss: 115.5320\n",
            "Epoch [8351/10000], Loss: 116.0564\n",
            "Epoch [8352/10000], Loss: 123.0069\n",
            "Epoch [8353/10000], Loss: 114.9806\n",
            "Epoch [8354/10000], Loss: 109.8376\n",
            "Epoch [8355/10000], Loss: 118.3810\n",
            "Epoch [8356/10000], Loss: 114.1008\n",
            "Epoch [8357/10000], Loss: 117.7637\n",
            "Epoch [8358/10000], Loss: 112.4994\n",
            "Epoch [8359/10000], Loss: 111.2184\n",
            "Epoch [8360/10000], Loss: 109.9482\n",
            "Epoch [8361/10000], Loss: 109.4215\n",
            "Epoch [8362/10000], Loss: 119.6175\n",
            "Epoch [8363/10000], Loss: 114.1380\n",
            "Epoch [8364/10000], Loss: 117.1866\n",
            "Epoch [8365/10000], Loss: 116.5922\n",
            "Epoch [8366/10000], Loss: 118.6917\n",
            "Epoch [8367/10000], Loss: 110.8676\n",
            "Epoch [8368/10000], Loss: 114.8400\n",
            "Epoch [8369/10000], Loss: 112.0158\n",
            "Epoch [8370/10000], Loss: 118.8096\n",
            "Epoch [8371/10000], Loss: 116.7362\n",
            "Epoch [8372/10000], Loss: 110.9623\n",
            "Epoch [8373/10000], Loss: 114.0362\n",
            "Epoch [8374/10000], Loss: 112.0602\n",
            "Epoch [8375/10000], Loss: 113.4232\n",
            "Epoch [8376/10000], Loss: 111.4264\n",
            "Epoch [8377/10000], Loss: 116.2572\n",
            "Epoch [8378/10000], Loss: 111.5740\n",
            "Epoch [8379/10000], Loss: 116.5934\n",
            "Epoch [8380/10000], Loss: 115.1490\n",
            "Epoch [8381/10000], Loss: 112.8064\n",
            "Epoch [8382/10000], Loss: 112.7866\n",
            "Epoch [8383/10000], Loss: 114.6692\n",
            "Epoch [8384/10000], Loss: 102.7542\n",
            "Epoch [8385/10000], Loss: 114.9380\n",
            "Epoch [8386/10000], Loss: 115.7428\n",
            "Epoch [8387/10000], Loss: 117.0289\n",
            "Epoch [8388/10000], Loss: 119.3420\n",
            "Epoch [8389/10000], Loss: 114.7351\n",
            "Epoch [8390/10000], Loss: 111.5108\n",
            "Epoch [8391/10000], Loss: 113.4145\n",
            "Epoch [8392/10000], Loss: 116.3895\n",
            "Epoch [8393/10000], Loss: 120.0337\n",
            "Epoch [8394/10000], Loss: 114.6561\n",
            "Epoch [8395/10000], Loss: 119.2384\n",
            "Epoch [8396/10000], Loss: 106.7945\n",
            "Epoch [8397/10000], Loss: 112.3195\n",
            "Epoch [8398/10000], Loss: 116.2442\n",
            "Epoch [8399/10000], Loss: 110.2331\n",
            "Epoch [8400/10000], Loss: 110.9497\n",
            "Epoch [8401/10000], Loss: 117.6255\n",
            "Epoch [8402/10000], Loss: 117.1129\n",
            "Epoch [8403/10000], Loss: 109.3267\n",
            "Epoch [8404/10000], Loss: 116.5180\n",
            "Epoch [8405/10000], Loss: 118.6930\n",
            "Epoch [8406/10000], Loss: 111.7466\n",
            "Epoch [8407/10000], Loss: 110.6376\n",
            "Epoch [8408/10000], Loss: 112.4036\n",
            "Epoch [8409/10000], Loss: 113.3747\n",
            "Epoch [8410/10000], Loss: 112.1208\n",
            "Epoch [8411/10000], Loss: 111.5661\n",
            "Epoch [8412/10000], Loss: 110.9251\n",
            "Epoch [8413/10000], Loss: 114.2007\n",
            "Epoch [8414/10000], Loss: 116.7395\n",
            "Epoch [8415/10000], Loss: 112.2683\n",
            "Epoch [8416/10000], Loss: 112.3548\n",
            "Epoch [8417/10000], Loss: 116.3574\n",
            "Epoch [8418/10000], Loss: 115.3545\n",
            "Epoch [8419/10000], Loss: 110.5853\n",
            "Epoch [8420/10000], Loss: 112.7301\n",
            "Epoch [8421/10000], Loss: 120.5280\n",
            "Epoch [8422/10000], Loss: 108.8847\n",
            "Epoch [8423/10000], Loss: 111.2645\n",
            "Epoch [8424/10000], Loss: 107.0190\n",
            "Epoch [8425/10000], Loss: 113.1831\n",
            "Epoch [8426/10000], Loss: 114.3464\n",
            "Epoch [8427/10000], Loss: 107.2399\n",
            "Epoch [8428/10000], Loss: 104.1436\n",
            "Epoch [8429/10000], Loss: 110.6551\n",
            "Epoch [8430/10000], Loss: 113.2968\n",
            "Epoch [8431/10000], Loss: 114.1773\n",
            "Epoch [8432/10000], Loss: 112.9536\n",
            "Epoch [8433/10000], Loss: 114.9836\n",
            "Epoch [8434/10000], Loss: 114.7652\n",
            "Epoch [8435/10000], Loss: 120.5252\n",
            "Epoch [8436/10000], Loss: 114.0201\n",
            "Epoch [8437/10000], Loss: 111.8310\n",
            "Epoch [8438/10000], Loss: 113.1634\n",
            "Epoch [8439/10000], Loss: 119.5818\n",
            "Epoch [8440/10000], Loss: 115.7651\n",
            "Epoch [8441/10000], Loss: 109.5254\n",
            "Epoch [8442/10000], Loss: 111.3835\n",
            "Epoch [8443/10000], Loss: 107.9748\n",
            "Epoch [8444/10000], Loss: 115.8627\n",
            "Epoch [8445/10000], Loss: 118.6286\n",
            "Epoch [8446/10000], Loss: 113.3914\n",
            "Epoch [8447/10000], Loss: 117.6108\n",
            "Epoch [8448/10000], Loss: 107.6993\n",
            "Epoch [8449/10000], Loss: 109.0133\n",
            "Epoch [8450/10000], Loss: 112.1038\n",
            "Epoch [8451/10000], Loss: 111.4557\n",
            "Epoch [8452/10000], Loss: 117.1129\n",
            "Epoch [8453/10000], Loss: 111.4947\n",
            "Epoch [8454/10000], Loss: 105.2816\n",
            "Epoch [8455/10000], Loss: 114.3144\n",
            "Epoch [8456/10000], Loss: 115.2002\n",
            "Epoch [8457/10000], Loss: 113.4371\n",
            "Epoch [8458/10000], Loss: 114.1210\n",
            "Epoch [8459/10000], Loss: 113.8255\n",
            "Epoch [8460/10000], Loss: 113.7049\n",
            "Epoch [8461/10000], Loss: 114.0859\n",
            "Epoch [8462/10000], Loss: 116.0250\n",
            "Epoch [8463/10000], Loss: 112.6921\n",
            "Epoch [8464/10000], Loss: 111.8929\n",
            "Epoch [8465/10000], Loss: 116.6494\n",
            "Epoch [8466/10000], Loss: 110.7539\n",
            "Epoch [8467/10000], Loss: 105.8760\n",
            "Epoch [8468/10000], Loss: 116.4201\n",
            "Epoch [8469/10000], Loss: 112.3576\n",
            "Epoch [8470/10000], Loss: 115.4959\n",
            "Epoch [8471/10000], Loss: 112.6864\n",
            "Epoch [8472/10000], Loss: 115.5103\n",
            "Epoch [8473/10000], Loss: 114.5193\n",
            "Epoch [8474/10000], Loss: 113.1446\n",
            "Epoch [8475/10000], Loss: 118.1760\n",
            "Epoch [8476/10000], Loss: 113.2229\n",
            "Epoch [8477/10000], Loss: 111.6863\n",
            "Epoch [8478/10000], Loss: 116.4611\n",
            "Epoch [8479/10000], Loss: 112.6342\n",
            "Epoch [8480/10000], Loss: 107.1465\n",
            "Epoch [8481/10000], Loss: 104.3674\n",
            "Epoch [8482/10000], Loss: 103.3003\n",
            "Epoch [8483/10000], Loss: 109.4488\n",
            "Epoch [8484/10000], Loss: 110.5466\n",
            "Epoch [8485/10000], Loss: 114.9803\n",
            "Epoch [8486/10000], Loss: 113.6039\n",
            "Epoch [8487/10000], Loss: 117.4814\n",
            "Epoch [8488/10000], Loss: 109.6170\n",
            "Epoch [8489/10000], Loss: 109.4052\n",
            "Epoch [8490/10000], Loss: 111.2447\n",
            "Epoch [8491/10000], Loss: 112.7892\n",
            "Epoch [8492/10000], Loss: 107.4392\n",
            "Epoch [8493/10000], Loss: 117.0742\n",
            "Epoch [8494/10000], Loss: 107.8775\n",
            "Epoch [8495/10000], Loss: 114.5332\n",
            "Epoch [8496/10000], Loss: 117.2064\n",
            "Epoch [8497/10000], Loss: 111.8242\n",
            "Epoch [8498/10000], Loss: 111.1241\n",
            "Epoch [8499/10000], Loss: 108.5259\n",
            "Epoch [8500/10000], Loss: 106.1776\n",
            "Epoch [8501/10000], Loss: 110.9312\n",
            "Epoch [8502/10000], Loss: 109.8366\n",
            "Epoch [8503/10000], Loss: 108.1464\n",
            "Epoch [8504/10000], Loss: 113.5328\n",
            "Epoch [8505/10000], Loss: 110.3825\n",
            "Epoch [8506/10000], Loss: 113.8097\n",
            "Epoch [8507/10000], Loss: 106.9220\n",
            "Epoch [8508/10000], Loss: 116.7111\n",
            "Epoch [8509/10000], Loss: 111.5896\n",
            "Epoch [8510/10000], Loss: 115.0675\n",
            "Epoch [8511/10000], Loss: 111.2525\n",
            "Epoch [8512/10000], Loss: 115.1464\n",
            "Epoch [8513/10000], Loss: 112.4769\n",
            "Epoch [8514/10000], Loss: 111.4907\n",
            "Epoch [8515/10000], Loss: 106.6046\n",
            "Epoch [8516/10000], Loss: 113.8248\n",
            "Epoch [8517/10000], Loss: 111.1235\n",
            "Epoch [8518/10000], Loss: 107.1582\n",
            "Epoch [8519/10000], Loss: 110.4825\n",
            "Epoch [8520/10000], Loss: 115.4504\n",
            "Epoch [8521/10000], Loss: 108.3559\n",
            "Epoch [8522/10000], Loss: 113.1372\n",
            "Epoch [8523/10000], Loss: 110.3857\n",
            "Epoch [8524/10000], Loss: 109.1506\n",
            "Epoch [8525/10000], Loss: 102.2808\n",
            "Epoch [8526/10000], Loss: 107.6007\n",
            "Epoch [8527/10000], Loss: 107.9642\n",
            "Epoch [8528/10000], Loss: 116.3064\n",
            "Epoch [8529/10000], Loss: 112.8359\n",
            "Epoch [8530/10000], Loss: 111.3367\n",
            "Epoch [8531/10000], Loss: 110.4175\n",
            "Epoch [8532/10000], Loss: 118.6075\n",
            "Epoch [8533/10000], Loss: 113.2419\n",
            "Epoch [8534/10000], Loss: 113.4660\n",
            "Epoch [8535/10000], Loss: 104.4541\n",
            "Epoch [8536/10000], Loss: 111.8450\n",
            "Epoch [8537/10000], Loss: 109.4631\n",
            "Epoch [8538/10000], Loss: 113.5449\n",
            "Epoch [8539/10000], Loss: 121.8826\n",
            "Epoch [8540/10000], Loss: 108.0713\n",
            "Epoch [8541/10000], Loss: 113.0418\n",
            "Epoch [8542/10000], Loss: 111.5601\n",
            "Epoch [8543/10000], Loss: 115.3757\n",
            "Epoch [8544/10000], Loss: 109.1932\n",
            "Epoch [8545/10000], Loss: 106.8594\n",
            "Epoch [8546/10000], Loss: 107.8587\n",
            "Epoch [8547/10000], Loss: 112.2789\n",
            "Epoch [8548/10000], Loss: 112.6983\n",
            "Epoch [8549/10000], Loss: 113.8357\n",
            "Epoch [8550/10000], Loss: 107.1849\n",
            "Epoch [8551/10000], Loss: 108.8289\n",
            "Epoch [8552/10000], Loss: 114.4845\n",
            "Epoch [8553/10000], Loss: 114.1429\n",
            "Epoch [8554/10000], Loss: 104.5599\n",
            "Epoch [8555/10000], Loss: 112.5502\n",
            "Epoch [8556/10000], Loss: 111.9558\n",
            "Epoch [8557/10000], Loss: 112.3477\n",
            "Epoch [8558/10000], Loss: 108.0614\n",
            "Epoch [8559/10000], Loss: 110.6858\n",
            "Epoch [8560/10000], Loss: 116.2690\n",
            "Epoch [8561/10000], Loss: 110.9432\n",
            "Epoch [8562/10000], Loss: 120.0358\n",
            "Epoch [8563/10000], Loss: 106.2981\n",
            "Epoch [8564/10000], Loss: 111.3373\n",
            "Epoch [8565/10000], Loss: 109.6470\n",
            "Epoch [8566/10000], Loss: 105.8061\n",
            "Epoch [8567/10000], Loss: 104.5573\n",
            "Epoch [8568/10000], Loss: 109.3988\n",
            "Epoch [8569/10000], Loss: 109.9222\n",
            "Epoch [8570/10000], Loss: 115.2848\n",
            "Epoch [8571/10000], Loss: 110.8896\n",
            "Epoch [8572/10000], Loss: 107.8866\n",
            "Epoch [8573/10000], Loss: 112.4699\n",
            "Epoch [8574/10000], Loss: 117.3013\n",
            "Epoch [8575/10000], Loss: 104.2665\n",
            "Epoch [8576/10000], Loss: 112.8265\n",
            "Epoch [8577/10000], Loss: 112.7491\n",
            "Epoch [8578/10000], Loss: 112.0642\n",
            "Epoch [8579/10000], Loss: 110.4240\n",
            "Epoch [8580/10000], Loss: 113.4036\n",
            "Epoch [8581/10000], Loss: 104.6098\n",
            "Epoch [8582/10000], Loss: 111.9718\n",
            "Epoch [8583/10000], Loss: 111.8666\n",
            "Epoch [8584/10000], Loss: 114.5402\n",
            "Epoch [8585/10000], Loss: 118.8236\n",
            "Epoch [8586/10000], Loss: 112.3951\n",
            "Epoch [8587/10000], Loss: 111.5789\n",
            "Epoch [8588/10000], Loss: 105.2667\n",
            "Epoch [8589/10000], Loss: 111.1937\n",
            "Epoch [8590/10000], Loss: 118.9146\n",
            "Epoch [8591/10000], Loss: 109.2215\n",
            "Epoch [8592/10000], Loss: 111.9948\n",
            "Epoch [8593/10000], Loss: 113.2166\n",
            "Epoch [8594/10000], Loss: 118.1062\n",
            "Epoch [8595/10000], Loss: 112.6136\n",
            "Epoch [8596/10000], Loss: 114.4071\n",
            "Epoch [8597/10000], Loss: 107.5558\n",
            "Epoch [8598/10000], Loss: 117.1332\n",
            "Epoch [8599/10000], Loss: 115.2091\n",
            "Epoch [8600/10000], Loss: 112.0303\n",
            "Epoch [8601/10000], Loss: 112.9971\n",
            "Epoch [8602/10000], Loss: 112.7293\n",
            "Epoch [8603/10000], Loss: 118.8929\n",
            "Epoch [8604/10000], Loss: 119.1519\n",
            "Epoch [8605/10000], Loss: 106.9853\n",
            "Epoch [8606/10000], Loss: 109.0290\n",
            "Epoch [8607/10000], Loss: 111.1699\n",
            "Epoch [8608/10000], Loss: 107.8947\n",
            "Epoch [8609/10000], Loss: 113.8988\n",
            "Epoch [8610/10000], Loss: 106.1707\n",
            "Epoch [8611/10000], Loss: 107.5833\n",
            "Epoch [8612/10000], Loss: 111.0926\n",
            "Epoch [8613/10000], Loss: 114.0768\n",
            "Epoch [8614/10000], Loss: 110.4867\n",
            "Epoch [8615/10000], Loss: 110.4559\n",
            "Epoch [8616/10000], Loss: 112.5657\n",
            "Epoch [8617/10000], Loss: 104.4057\n",
            "Epoch [8618/10000], Loss: 109.9776\n",
            "Epoch [8619/10000], Loss: 109.1164\n",
            "Epoch [8620/10000], Loss: 106.8824\n",
            "Epoch [8621/10000], Loss: 105.8492\n",
            "Epoch [8622/10000], Loss: 114.4758\n",
            "Epoch [8623/10000], Loss: 111.9517\n",
            "Epoch [8624/10000], Loss: 106.4265\n",
            "Epoch [8625/10000], Loss: 110.9692\n",
            "Epoch [8626/10000], Loss: 110.0784\n",
            "Epoch [8627/10000], Loss: 112.5867\n",
            "Epoch [8628/10000], Loss: 118.1258\n",
            "Epoch [8629/10000], Loss: 110.5841\n",
            "Epoch [8630/10000], Loss: 109.7500\n",
            "Epoch [8631/10000], Loss: 109.0381\n",
            "Epoch [8632/10000], Loss: 107.7779\n",
            "Epoch [8633/10000], Loss: 116.0465\n",
            "Epoch [8634/10000], Loss: 110.7106\n",
            "Epoch [8635/10000], Loss: 108.4086\n",
            "Epoch [8636/10000], Loss: 115.3918\n",
            "Epoch [8637/10000], Loss: 111.1347\n",
            "Epoch [8638/10000], Loss: 111.7929\n",
            "Epoch [8639/10000], Loss: 104.0071\n",
            "Epoch [8640/10000], Loss: 110.6191\n",
            "Epoch [8641/10000], Loss: 114.0854\n",
            "Epoch [8642/10000], Loss: 116.4734\n",
            "Epoch [8643/10000], Loss: 108.5392\n",
            "Epoch [8644/10000], Loss: 105.5270\n",
            "Epoch [8645/10000], Loss: 109.8007\n",
            "Epoch [8646/10000], Loss: 115.7419\n",
            "Epoch [8647/10000], Loss: 114.3706\n",
            "Epoch [8648/10000], Loss: 105.9246\n",
            "Epoch [8649/10000], Loss: 114.2972\n",
            "Epoch [8650/10000], Loss: 115.3415\n",
            "Epoch [8651/10000], Loss: 107.1964\n",
            "Epoch [8652/10000], Loss: 108.1538\n",
            "Epoch [8653/10000], Loss: 107.4972\n",
            "Epoch [8654/10000], Loss: 112.8959\n",
            "Epoch [8655/10000], Loss: 110.6112\n",
            "Epoch [8656/10000], Loss: 113.7146\n",
            "Epoch [8657/10000], Loss: 111.4463\n",
            "Epoch [8658/10000], Loss: 110.1897\n",
            "Epoch [8659/10000], Loss: 109.3008\n",
            "Epoch [8660/10000], Loss: 108.2092\n",
            "Epoch [8661/10000], Loss: 109.0276\n",
            "Epoch [8662/10000], Loss: 109.6965\n",
            "Epoch [8663/10000], Loss: 107.9036\n",
            "Epoch [8664/10000], Loss: 105.5085\n",
            "Epoch [8665/10000], Loss: 104.4596\n",
            "Epoch [8666/10000], Loss: 110.3481\n",
            "Epoch [8667/10000], Loss: 107.4140\n",
            "Epoch [8668/10000], Loss: 107.9255\n",
            "Epoch [8669/10000], Loss: 112.8361\n",
            "Epoch [8670/10000], Loss: 111.2301\n",
            "Epoch [8671/10000], Loss: 109.5320\n",
            "Epoch [8672/10000], Loss: 108.4270\n",
            "Epoch [8673/10000], Loss: 110.1775\n",
            "Epoch [8674/10000], Loss: 105.8243\n",
            "Epoch [8675/10000], Loss: 111.1014\n",
            "Epoch [8676/10000], Loss: 110.2853\n",
            "Epoch [8677/10000], Loss: 104.7734\n",
            "Epoch [8678/10000], Loss: 102.1762\n",
            "Epoch [8679/10000], Loss: 109.0518\n",
            "Epoch [8680/10000], Loss: 106.1702\n",
            "Epoch [8681/10000], Loss: 107.6693\n",
            "Epoch [8682/10000], Loss: 106.8958\n",
            "Epoch [8683/10000], Loss: 105.7645\n",
            "Epoch [8684/10000], Loss: 115.4204\n",
            "Epoch [8685/10000], Loss: 107.8793\n",
            "Epoch [8686/10000], Loss: 113.5283\n",
            "Epoch [8687/10000], Loss: 115.1098\n",
            "Epoch [8688/10000], Loss: 113.9668\n",
            "Epoch [8689/10000], Loss: 113.1613\n",
            "Epoch [8690/10000], Loss: 103.5049\n",
            "Epoch [8691/10000], Loss: 108.4898\n",
            "Epoch [8692/10000], Loss: 113.9289\n",
            "Epoch [8693/10000], Loss: 107.4451\n",
            "Epoch [8694/10000], Loss: 109.2289\n",
            "Epoch [8695/10000], Loss: 111.2833\n",
            "Epoch [8696/10000], Loss: 109.7171\n",
            "Epoch [8697/10000], Loss: 111.5458\n",
            "Epoch [8698/10000], Loss: 108.1903\n",
            "Epoch [8699/10000], Loss: 110.7498\n",
            "Epoch [8700/10000], Loss: 110.1963\n",
            "Epoch [8701/10000], Loss: 111.5171\n",
            "Epoch [8702/10000], Loss: 115.0808\n",
            "Epoch [8703/10000], Loss: 110.8848\n",
            "Epoch [8704/10000], Loss: 110.9694\n",
            "Epoch [8705/10000], Loss: 113.7137\n",
            "Epoch [8706/10000], Loss: 112.8750\n",
            "Epoch [8707/10000], Loss: 108.9284\n",
            "Epoch [8708/10000], Loss: 108.8240\n",
            "Epoch [8709/10000], Loss: 106.5625\n",
            "Epoch [8710/10000], Loss: 111.0563\n",
            "Epoch [8711/10000], Loss: 106.4875\n",
            "Epoch [8712/10000], Loss: 109.0363\n",
            "Epoch [8713/10000], Loss: 110.9318\n",
            "Epoch [8714/10000], Loss: 112.9261\n",
            "Epoch [8715/10000], Loss: 114.5626\n",
            "Epoch [8716/10000], Loss: 109.8298\n",
            "Epoch [8717/10000], Loss: 106.9811\n",
            "Epoch [8718/10000], Loss: 104.5657\n",
            "Epoch [8719/10000], Loss: 109.4408\n",
            "Epoch [8720/10000], Loss: 108.9106\n",
            "Epoch [8721/10000], Loss: 108.5720\n",
            "Epoch [8722/10000], Loss: 111.1833\n",
            "Epoch [8723/10000], Loss: 110.7789\n",
            "Epoch [8724/10000], Loss: 114.1285\n",
            "Epoch [8725/10000], Loss: 113.2032\n",
            "Epoch [8726/10000], Loss: 108.7307\n",
            "Epoch [8727/10000], Loss: 111.0860\n",
            "Epoch [8728/10000], Loss: 109.0761\n",
            "Epoch [8729/10000], Loss: 110.4131\n",
            "Epoch [8730/10000], Loss: 113.6139\n",
            "Epoch [8731/10000], Loss: 110.8275\n",
            "Epoch [8732/10000], Loss: 109.2992\n",
            "Epoch [8733/10000], Loss: 108.8324\n",
            "Epoch [8734/10000], Loss: 113.2989\n",
            "Epoch [8735/10000], Loss: 109.8755\n",
            "Epoch [8736/10000], Loss: 114.1959\n",
            "Epoch [8737/10000], Loss: 105.7296\n",
            "Epoch [8738/10000], Loss: 111.2848\n",
            "Epoch [8739/10000], Loss: 103.6441\n",
            "Epoch [8740/10000], Loss: 110.1162\n",
            "Epoch [8741/10000], Loss: 109.8866\n",
            "Epoch [8742/10000], Loss: 109.5009\n",
            "Epoch [8743/10000], Loss: 116.3976\n",
            "Epoch [8744/10000], Loss: 107.0787\n",
            "Epoch [8745/10000], Loss: 110.4462\n",
            "Epoch [8746/10000], Loss: 117.2470\n",
            "Epoch [8747/10000], Loss: 104.9898\n",
            "Epoch [8748/10000], Loss: 108.0178\n",
            "Epoch [8749/10000], Loss: 102.6029\n",
            "Epoch [8750/10000], Loss: 107.3979\n",
            "Epoch [8751/10000], Loss: 108.3470\n",
            "Epoch [8752/10000], Loss: 105.4431\n",
            "Epoch [8753/10000], Loss: 111.9484\n",
            "Epoch [8754/10000], Loss: 110.8753\n",
            "Epoch [8755/10000], Loss: 114.1003\n",
            "Epoch [8756/10000], Loss: 104.1132\n",
            "Epoch [8757/10000], Loss: 110.2727\n",
            "Epoch [8758/10000], Loss: 109.2250\n",
            "Epoch [8759/10000], Loss: 111.1467\n",
            "Epoch [8760/10000], Loss: 109.4755\n",
            "Epoch [8761/10000], Loss: 110.5634\n",
            "Epoch [8762/10000], Loss: 111.3884\n",
            "Epoch [8763/10000], Loss: 107.4913\n",
            "Epoch [8764/10000], Loss: 106.9850\n",
            "Epoch [8765/10000], Loss: 109.8459\n",
            "Epoch [8766/10000], Loss: 115.3961\n",
            "Epoch [8767/10000], Loss: 112.9927\n",
            "Epoch [8768/10000], Loss: 112.5755\n",
            "Epoch [8769/10000], Loss: 107.6358\n",
            "Epoch [8770/10000], Loss: 115.9225\n",
            "Epoch [8771/10000], Loss: 108.8169\n",
            "Epoch [8772/10000], Loss: 112.9205\n",
            "Epoch [8773/10000], Loss: 105.8640\n",
            "Epoch [8774/10000], Loss: 108.6234\n",
            "Epoch [8775/10000], Loss: 107.4905\n",
            "Epoch [8776/10000], Loss: 109.0388\n",
            "Epoch [8777/10000], Loss: 100.5104\n",
            "Epoch [8778/10000], Loss: 111.7703\n",
            "Epoch [8779/10000], Loss: 103.3911\n",
            "Epoch [8780/10000], Loss: 113.4585\n",
            "Epoch [8781/10000], Loss: 111.8566\n",
            "Epoch [8782/10000], Loss: 103.8357\n",
            "Epoch [8783/10000], Loss: 104.3198\n",
            "Epoch [8784/10000], Loss: 103.7969\n",
            "Epoch [8785/10000], Loss: 109.9195\n",
            "Epoch [8786/10000], Loss: 104.6672\n",
            "Epoch [8787/10000], Loss: 105.8212\n",
            "Epoch [8788/10000], Loss: 108.9390\n",
            "Epoch [8789/10000], Loss: 103.3710\n",
            "Epoch [8790/10000], Loss: 115.2444\n",
            "Epoch [8791/10000], Loss: 109.1065\n",
            "Epoch [8792/10000], Loss: 114.7105\n",
            "Epoch [8793/10000], Loss: 113.9371\n",
            "Epoch [8794/10000], Loss: 112.8346\n",
            "Epoch [8795/10000], Loss: 112.5922\n",
            "Epoch [8796/10000], Loss: 104.0703\n",
            "Epoch [8797/10000], Loss: 115.5765\n",
            "Epoch [8798/10000], Loss: 113.1128\n",
            "Epoch [8799/10000], Loss: 103.0649\n",
            "Epoch [8800/10000], Loss: 108.2245\n",
            "Epoch [8801/10000], Loss: 108.8577\n",
            "Epoch [8802/10000], Loss: 106.9738\n",
            "Epoch [8803/10000], Loss: 107.5633\n",
            "Epoch [8804/10000], Loss: 103.1887\n",
            "Epoch [8805/10000], Loss: 108.6742\n",
            "Epoch [8806/10000], Loss: 111.6462\n",
            "Epoch [8807/10000], Loss: 109.1148\n",
            "Epoch [8808/10000], Loss: 109.4173\n",
            "Epoch [8809/10000], Loss: 105.9062\n",
            "Epoch [8810/10000], Loss: 106.4748\n",
            "Epoch [8811/10000], Loss: 109.1667\n",
            "Epoch [8812/10000], Loss: 107.1332\n",
            "Epoch [8813/10000], Loss: 110.7974\n",
            "Epoch [8814/10000], Loss: 109.3399\n",
            "Epoch [8815/10000], Loss: 110.4047\n",
            "Epoch [8816/10000], Loss: 108.2159\n",
            "Epoch [8817/10000], Loss: 110.2595\n",
            "Epoch [8818/10000], Loss: 106.6476\n",
            "Epoch [8819/10000], Loss: 107.8112\n",
            "Epoch [8820/10000], Loss: 104.6052\n",
            "Epoch [8821/10000], Loss: 107.8466\n",
            "Epoch [8822/10000], Loss: 111.2795\n",
            "Epoch [8823/10000], Loss: 106.4988\n",
            "Epoch [8824/10000], Loss: 105.2262\n",
            "Epoch [8825/10000], Loss: 109.1560\n",
            "Epoch [8826/10000], Loss: 109.9695\n",
            "Epoch [8827/10000], Loss: 111.6322\n",
            "Epoch [8828/10000], Loss: 111.8302\n",
            "Epoch [8829/10000], Loss: 110.9869\n",
            "Epoch [8830/10000], Loss: 106.8418\n",
            "Epoch [8831/10000], Loss: 111.3402\n",
            "Epoch [8832/10000], Loss: 116.4239\n",
            "Epoch [8833/10000], Loss: 109.7409\n",
            "Epoch [8834/10000], Loss: 115.2414\n",
            "Epoch [8835/10000], Loss: 100.2628\n",
            "Epoch [8836/10000], Loss: 107.2851\n",
            "Epoch [8837/10000], Loss: 105.1230\n",
            "Epoch [8838/10000], Loss: 109.1182\n",
            "Epoch [8839/10000], Loss: 111.6181\n",
            "Epoch [8840/10000], Loss: 106.4067\n",
            "Epoch [8841/10000], Loss: 107.2021\n",
            "Epoch [8842/10000], Loss: 107.4620\n",
            "Epoch [8843/10000], Loss: 102.1262\n",
            "Epoch [8844/10000], Loss: 105.8041\n",
            "Epoch [8845/10000], Loss: 108.2008\n",
            "Epoch [8846/10000], Loss: 106.9281\n",
            "Epoch [8847/10000], Loss: 103.7596\n",
            "Epoch [8848/10000], Loss: 112.6500\n",
            "Epoch [8849/10000], Loss: 105.6906\n",
            "Epoch [8850/10000], Loss: 107.6222\n",
            "Epoch [8851/10000], Loss: 109.2695\n",
            "Epoch [8852/10000], Loss: 112.5156\n",
            "Epoch [8853/10000], Loss: 111.6428\n",
            "Epoch [8854/10000], Loss: 107.6058\n",
            "Epoch [8855/10000], Loss: 108.3245\n",
            "Epoch [8856/10000], Loss: 112.2436\n",
            "Epoch [8857/10000], Loss: 106.9554\n",
            "Epoch [8858/10000], Loss: 106.5704\n",
            "Epoch [8859/10000], Loss: 105.9497\n",
            "Epoch [8860/10000], Loss: 103.6190\n",
            "Epoch [8861/10000], Loss: 108.9655\n",
            "Epoch [8862/10000], Loss: 106.6771\n",
            "Epoch [8863/10000], Loss: 111.5969\n",
            "Epoch [8864/10000], Loss: 98.4525\n",
            "Epoch [8865/10000], Loss: 103.8922\n",
            "Epoch [8866/10000], Loss: 111.4794\n",
            "Epoch [8867/10000], Loss: 102.9568\n",
            "Epoch [8868/10000], Loss: 108.9701\n",
            "Epoch [8869/10000], Loss: 107.3361\n",
            "Epoch [8870/10000], Loss: 104.1226\n",
            "Epoch [8871/10000], Loss: 108.1835\n",
            "Epoch [8872/10000], Loss: 107.3370\n",
            "Epoch [8873/10000], Loss: 112.3391\n",
            "Epoch [8874/10000], Loss: 111.2839\n",
            "Epoch [8875/10000], Loss: 104.5352\n",
            "Epoch [8876/10000], Loss: 106.0728\n",
            "Epoch [8877/10000], Loss: 108.0550\n",
            "Epoch [8878/10000], Loss: 110.5775\n",
            "Epoch [8879/10000], Loss: 101.4970\n",
            "Epoch [8880/10000], Loss: 104.4748\n",
            "Epoch [8881/10000], Loss: 110.7108\n",
            "Epoch [8882/10000], Loss: 101.7929\n",
            "Epoch [8883/10000], Loss: 106.8773\n",
            "Epoch [8884/10000], Loss: 107.1302\n",
            "Epoch [8885/10000], Loss: 104.9333\n",
            "Epoch [8886/10000], Loss: 108.1306\n",
            "Epoch [8887/10000], Loss: 106.3891\n",
            "Epoch [8888/10000], Loss: 111.3762\n",
            "Epoch [8889/10000], Loss: 115.1489\n",
            "Epoch [8890/10000], Loss: 105.4145\n",
            "Epoch [8891/10000], Loss: 104.9496\n",
            "Epoch [8892/10000], Loss: 109.2693\n",
            "Epoch [8893/10000], Loss: 105.8453\n",
            "Epoch [8894/10000], Loss: 108.6798\n",
            "Epoch [8895/10000], Loss: 108.0050\n",
            "Epoch [8896/10000], Loss: 108.9928\n",
            "Epoch [8897/10000], Loss: 106.4193\n",
            "Epoch [8898/10000], Loss: 107.8762\n",
            "Epoch [8899/10000], Loss: 115.5899\n",
            "Epoch [8900/10000], Loss: 105.2333\n",
            "Epoch [8901/10000], Loss: 103.8343\n",
            "Epoch [8902/10000], Loss: 106.5969\n",
            "Epoch [8903/10000], Loss: 105.5036\n",
            "Epoch [8904/10000], Loss: 99.5120\n",
            "Epoch [8905/10000], Loss: 109.7644\n",
            "Epoch [8906/10000], Loss: 103.6435\n",
            "Epoch [8907/10000], Loss: 104.8377\n",
            "Epoch [8908/10000], Loss: 107.1697\n",
            "Epoch [8909/10000], Loss: 107.9678\n",
            "Epoch [8910/10000], Loss: 104.2018\n",
            "Epoch [8911/10000], Loss: 107.2168\n",
            "Epoch [8912/10000], Loss: 106.4909\n",
            "Epoch [8913/10000], Loss: 109.9833\n",
            "Epoch [8914/10000], Loss: 111.9612\n",
            "Epoch [8915/10000], Loss: 107.1744\n",
            "Epoch [8916/10000], Loss: 105.2865\n",
            "Epoch [8917/10000], Loss: 109.0093\n",
            "Epoch [8918/10000], Loss: 112.5166\n",
            "Epoch [8919/10000], Loss: 103.7864\n",
            "Epoch [8920/10000], Loss: 103.9722\n",
            "Epoch [8921/10000], Loss: 112.4632\n",
            "Epoch [8922/10000], Loss: 103.0098\n",
            "Epoch [8923/10000], Loss: 112.1529\n",
            "Epoch [8924/10000], Loss: 107.3897\n",
            "Epoch [8925/10000], Loss: 108.3526\n",
            "Epoch [8926/10000], Loss: 110.3380\n",
            "Epoch [8927/10000], Loss: 104.6396\n",
            "Epoch [8928/10000], Loss: 108.3457\n",
            "Epoch [8929/10000], Loss: 111.0650\n",
            "Epoch [8930/10000], Loss: 103.8319\n",
            "Epoch [8931/10000], Loss: 114.1526\n",
            "Epoch [8932/10000], Loss: 109.2530\n",
            "Epoch [8933/10000], Loss: 106.8790\n",
            "Epoch [8934/10000], Loss: 103.0029\n",
            "Epoch [8935/10000], Loss: 106.9402\n",
            "Epoch [8936/10000], Loss: 105.0576\n",
            "Epoch [8937/10000], Loss: 104.0332\n",
            "Epoch [8938/10000], Loss: 110.2333\n",
            "Epoch [8939/10000], Loss: 107.2480\n",
            "Epoch [8940/10000], Loss: 107.8519\n",
            "Epoch [8941/10000], Loss: 111.0738\n",
            "Epoch [8942/10000], Loss: 109.1675\n",
            "Epoch [8943/10000], Loss: 109.3367\n",
            "Epoch [8944/10000], Loss: 104.2483\n",
            "Epoch [8945/10000], Loss: 105.5535\n",
            "Epoch [8946/10000], Loss: 108.0272\n",
            "Epoch [8947/10000], Loss: 106.6996\n",
            "Epoch [8948/10000], Loss: 103.4426\n",
            "Epoch [8949/10000], Loss: 109.8934\n",
            "Epoch [8950/10000], Loss: 111.6318\n",
            "Epoch [8951/10000], Loss: 103.9863\n",
            "Epoch [8952/10000], Loss: 110.7762\n",
            "Epoch [8953/10000], Loss: 103.4753\n",
            "Epoch [8954/10000], Loss: 108.6877\n",
            "Epoch [8955/10000], Loss: 108.9142\n",
            "Epoch [8956/10000], Loss: 106.7967\n",
            "Epoch [8957/10000], Loss: 102.7052\n",
            "Epoch [8958/10000], Loss: 106.4721\n",
            "Epoch [8959/10000], Loss: 103.2975\n",
            "Epoch [8960/10000], Loss: 105.7801\n",
            "Epoch [8961/10000], Loss: 106.4308\n",
            "Epoch [8962/10000], Loss: 106.5112\n",
            "Epoch [8963/10000], Loss: 107.5149\n",
            "Epoch [8964/10000], Loss: 107.3361\n",
            "Epoch [8965/10000], Loss: 107.3789\n",
            "Epoch [8966/10000], Loss: 107.3082\n",
            "Epoch [8967/10000], Loss: 104.5956\n",
            "Epoch [8968/10000], Loss: 104.4007\n",
            "Epoch [8969/10000], Loss: 113.5269\n",
            "Epoch [8970/10000], Loss: 114.1655\n",
            "Epoch [8971/10000], Loss: 110.8897\n",
            "Epoch [8972/10000], Loss: 105.6437\n",
            "Epoch [8973/10000], Loss: 104.4663\n",
            "Epoch [8974/10000], Loss: 110.0635\n",
            "Epoch [8975/10000], Loss: 102.3727\n",
            "Epoch [8976/10000], Loss: 108.1487\n",
            "Epoch [8977/10000], Loss: 105.6861\n",
            "Epoch [8978/10000], Loss: 104.8706\n",
            "Epoch [8979/10000], Loss: 106.2221\n",
            "Epoch [8980/10000], Loss: 109.7925\n",
            "Epoch [8981/10000], Loss: 107.5215\n",
            "Epoch [8982/10000], Loss: 106.1554\n",
            "Epoch [8983/10000], Loss: 103.2316\n",
            "Epoch [8984/10000], Loss: 104.4141\n",
            "Epoch [8985/10000], Loss: 102.2158\n",
            "Epoch [8986/10000], Loss: 111.5402\n",
            "Epoch [8987/10000], Loss: 110.6767\n",
            "Epoch [8988/10000], Loss: 108.5278\n",
            "Epoch [8989/10000], Loss: 103.6798\n",
            "Epoch [8990/10000], Loss: 109.8888\n",
            "Epoch [8991/10000], Loss: 103.4795\n",
            "Epoch [8992/10000], Loss: 103.4956\n",
            "Epoch [8993/10000], Loss: 102.8877\n",
            "Epoch [8994/10000], Loss: 110.4504\n",
            "Epoch [8995/10000], Loss: 105.2499\n",
            "Epoch [8996/10000], Loss: 107.6727\n",
            "Epoch [8997/10000], Loss: 103.3831\n",
            "Epoch [8998/10000], Loss: 103.8776\n",
            "Epoch [8999/10000], Loss: 107.2202\n",
            "Epoch [9000/10000], Loss: 106.5226\n",
            "Epoch [9001/10000], Loss: 106.0913\n",
            "Epoch [9002/10000], Loss: 105.1973\n",
            "Epoch [9003/10000], Loss: 101.1798\n",
            "Epoch [9004/10000], Loss: 112.1397\n",
            "Epoch [9005/10000], Loss: 109.6422\n",
            "Epoch [9006/10000], Loss: 101.3722\n",
            "Epoch [9007/10000], Loss: 109.1007\n",
            "Epoch [9008/10000], Loss: 105.1754\n",
            "Epoch [9009/10000], Loss: 109.5459\n",
            "Epoch [9010/10000], Loss: 106.1869\n",
            "Epoch [9011/10000], Loss: 103.0592\n",
            "Epoch [9012/10000], Loss: 115.3506\n",
            "Epoch [9013/10000], Loss: 103.3357\n",
            "Epoch [9014/10000], Loss: 103.8805\n",
            "Epoch [9015/10000], Loss: 108.4803\n",
            "Epoch [9016/10000], Loss: 103.2585\n",
            "Epoch [9017/10000], Loss: 113.8653\n",
            "Epoch [9018/10000], Loss: 106.8000\n",
            "Epoch [9019/10000], Loss: 102.8338\n",
            "Epoch [9020/10000], Loss: 110.0434\n",
            "Epoch [9021/10000], Loss: 106.1005\n",
            "Epoch [9022/10000], Loss: 106.1485\n",
            "Epoch [9023/10000], Loss: 101.3458\n",
            "Epoch [9024/10000], Loss: 106.1390\n",
            "Epoch [9025/10000], Loss: 108.9802\n",
            "Epoch [9026/10000], Loss: 105.6619\n",
            "Epoch [9027/10000], Loss: 106.8972\n",
            "Epoch [9028/10000], Loss: 101.1557\n",
            "Epoch [9029/10000], Loss: 106.2734\n",
            "Epoch [9030/10000], Loss: 108.0226\n",
            "Epoch [9031/10000], Loss: 107.5345\n",
            "Epoch [9032/10000], Loss: 105.1270\n",
            "Epoch [9033/10000], Loss: 116.5593\n",
            "Epoch [9034/10000], Loss: 98.8808\n",
            "Epoch [9035/10000], Loss: 107.9245\n",
            "Epoch [9036/10000], Loss: 102.6006\n",
            "Epoch [9037/10000], Loss: 104.4029\n",
            "Epoch [9038/10000], Loss: 104.7054\n",
            "Epoch [9039/10000], Loss: 102.4587\n",
            "Epoch [9040/10000], Loss: 113.3557\n",
            "Epoch [9041/10000], Loss: 108.0199\n",
            "Epoch [9042/10000], Loss: 106.1582\n",
            "Epoch [9043/10000], Loss: 110.4407\n",
            "Epoch [9044/10000], Loss: 99.8946\n",
            "Epoch [9045/10000], Loss: 106.7037\n",
            "Epoch [9046/10000], Loss: 105.7667\n",
            "Epoch [9047/10000], Loss: 108.9805\n",
            "Epoch [9048/10000], Loss: 102.7033\n",
            "Epoch [9049/10000], Loss: 103.2789\n",
            "Epoch [9050/10000], Loss: 102.2176\n",
            "Epoch [9051/10000], Loss: 106.7499\n",
            "Epoch [9052/10000], Loss: 105.9010\n",
            "Epoch [9053/10000], Loss: 109.5319\n",
            "Epoch [9054/10000], Loss: 103.3783\n",
            "Epoch [9055/10000], Loss: 99.6852\n",
            "Epoch [9056/10000], Loss: 108.0089\n",
            "Epoch [9057/10000], Loss: 106.4779\n",
            "Epoch [9058/10000], Loss: 105.5122\n",
            "Epoch [9059/10000], Loss: 102.8240\n",
            "Epoch [9060/10000], Loss: 107.8446\n",
            "Epoch [9061/10000], Loss: 114.4289\n",
            "Epoch [9062/10000], Loss: 101.6883\n",
            "Epoch [9063/10000], Loss: 106.4397\n",
            "Epoch [9064/10000], Loss: 107.9291\n",
            "Epoch [9065/10000], Loss: 106.3639\n",
            "Epoch [9066/10000], Loss: 107.8390\n",
            "Epoch [9067/10000], Loss: 103.2825\n",
            "Epoch [9068/10000], Loss: 102.7825\n",
            "Epoch [9069/10000], Loss: 104.8850\n",
            "Epoch [9070/10000], Loss: 102.2996\n",
            "Epoch [9071/10000], Loss: 107.5908\n",
            "Epoch [9072/10000], Loss: 104.5266\n",
            "Epoch [9073/10000], Loss: 106.6533\n",
            "Epoch [9074/10000], Loss: 102.7287\n",
            "Epoch [9075/10000], Loss: 106.5812\n",
            "Epoch [9076/10000], Loss: 100.5240\n",
            "Epoch [9077/10000], Loss: 100.8986\n",
            "Epoch [9078/10000], Loss: 106.0686\n",
            "Epoch [9079/10000], Loss: 106.9398\n",
            "Epoch [9080/10000], Loss: 106.0413\n",
            "Epoch [9081/10000], Loss: 105.8521\n",
            "Epoch [9082/10000], Loss: 106.8244\n",
            "Epoch [9083/10000], Loss: 107.0600\n",
            "Epoch [9084/10000], Loss: 105.5140\n",
            "Epoch [9085/10000], Loss: 103.9058\n",
            "Epoch [9086/10000], Loss: 105.4878\n",
            "Epoch [9087/10000], Loss: 113.3210\n",
            "Epoch [9088/10000], Loss: 108.0512\n",
            "Epoch [9089/10000], Loss: 99.7976\n",
            "Epoch [9090/10000], Loss: 104.4370\n",
            "Epoch [9091/10000], Loss: 102.0021\n",
            "Epoch [9092/10000], Loss: 101.3767\n",
            "Epoch [9093/10000], Loss: 105.0613\n",
            "Epoch [9094/10000], Loss: 103.7257\n",
            "Epoch [9095/10000], Loss: 104.6283\n",
            "Epoch [9096/10000], Loss: 105.5770\n",
            "Epoch [9097/10000], Loss: 105.2074\n",
            "Epoch [9098/10000], Loss: 99.6301\n",
            "Epoch [9099/10000], Loss: 106.7727\n",
            "Epoch [9100/10000], Loss: 104.6418\n",
            "Epoch [9101/10000], Loss: 106.5380\n",
            "Epoch [9102/10000], Loss: 104.0641\n",
            "Epoch [9103/10000], Loss: 107.9207\n",
            "Epoch [9104/10000], Loss: 104.6936\n",
            "Epoch [9105/10000], Loss: 106.8942\n",
            "Epoch [9106/10000], Loss: 105.1201\n",
            "Epoch [9107/10000], Loss: 109.9761\n",
            "Epoch [9108/10000], Loss: 101.6251\n",
            "Epoch [9109/10000], Loss: 104.3999\n",
            "Epoch [9110/10000], Loss: 103.9237\n",
            "Epoch [9111/10000], Loss: 104.2891\n",
            "Epoch [9112/10000], Loss: 112.0311\n",
            "Epoch [9113/10000], Loss: 105.7011\n",
            "Epoch [9114/10000], Loss: 104.2675\n",
            "Epoch [9115/10000], Loss: 100.3611\n",
            "Epoch [9116/10000], Loss: 101.1544\n",
            "Epoch [9117/10000], Loss: 109.4103\n",
            "Epoch [9118/10000], Loss: 99.0776\n",
            "Epoch [9119/10000], Loss: 105.5147\n",
            "Epoch [9120/10000], Loss: 102.9636\n",
            "Epoch [9121/10000], Loss: 103.3586\n",
            "Epoch [9122/10000], Loss: 112.1155\n",
            "Epoch [9123/10000], Loss: 103.0926\n",
            "Epoch [9124/10000], Loss: 96.3004\n",
            "Epoch [9125/10000], Loss: 107.6312\n",
            "Epoch [9126/10000], Loss: 104.3198\n",
            "Epoch [9127/10000], Loss: 107.0003\n",
            "Epoch [9128/10000], Loss: 110.4712\n",
            "Epoch [9129/10000], Loss: 100.0562\n",
            "Epoch [9130/10000], Loss: 100.1740\n",
            "Epoch [9131/10000], Loss: 102.4667\n",
            "Epoch [9132/10000], Loss: 103.7012\n",
            "Epoch [9133/10000], Loss: 104.0249\n",
            "Epoch [9134/10000], Loss: 109.7463\n",
            "Epoch [9135/10000], Loss: 107.6757\n",
            "Epoch [9136/10000], Loss: 101.0559\n",
            "Epoch [9137/10000], Loss: 104.3306\n",
            "Epoch [9138/10000], Loss: 103.9761\n",
            "Epoch [9139/10000], Loss: 104.1147\n",
            "Epoch [9140/10000], Loss: 109.4018\n",
            "Epoch [9141/10000], Loss: 104.7337\n",
            "Epoch [9142/10000], Loss: 101.7041\n",
            "Epoch [9143/10000], Loss: 104.5384\n",
            "Epoch [9144/10000], Loss: 103.0097\n",
            "Epoch [9145/10000], Loss: 106.6750\n",
            "Epoch [9146/10000], Loss: 108.0283\n",
            "Epoch [9147/10000], Loss: 104.0442\n",
            "Epoch [9148/10000], Loss: 100.6656\n",
            "Epoch [9149/10000], Loss: 108.2487\n",
            "Epoch [9150/10000], Loss: 107.6530\n",
            "Epoch [9151/10000], Loss: 106.7927\n",
            "Epoch [9152/10000], Loss: 106.7279\n",
            "Epoch [9153/10000], Loss: 105.1789\n",
            "Epoch [9154/10000], Loss: 102.2010\n",
            "Epoch [9155/10000], Loss: 107.3563\n",
            "Epoch [9156/10000], Loss: 102.3607\n",
            "Epoch [9157/10000], Loss: 107.9712\n",
            "Epoch [9158/10000], Loss: 104.0225\n",
            "Epoch [9159/10000], Loss: 105.4174\n",
            "Epoch [9160/10000], Loss: 107.4804\n",
            "Epoch [9161/10000], Loss: 108.4505\n",
            "Epoch [9162/10000], Loss: 101.1732\n",
            "Epoch [9163/10000], Loss: 112.0018\n",
            "Epoch [9164/10000], Loss: 106.3114\n",
            "Epoch [9165/10000], Loss: 103.7252\n",
            "Epoch [9166/10000], Loss: 110.2271\n",
            "Epoch [9167/10000], Loss: 106.3015\n",
            "Epoch [9168/10000], Loss: 108.1190\n",
            "Epoch [9169/10000], Loss: 109.3025\n",
            "Epoch [9170/10000], Loss: 100.3032\n",
            "Epoch [9171/10000], Loss: 106.1109\n",
            "Epoch [9172/10000], Loss: 103.8627\n",
            "Epoch [9173/10000], Loss: 109.7301\n",
            "Epoch [9174/10000], Loss: 109.7341\n",
            "Epoch [9175/10000], Loss: 105.6407\n",
            "Epoch [9176/10000], Loss: 108.0563\n",
            "Epoch [9177/10000], Loss: 102.1617\n",
            "Epoch [9178/10000], Loss: 103.0157\n",
            "Epoch [9179/10000], Loss: 107.2209\n",
            "Epoch [9180/10000], Loss: 97.8692\n",
            "Epoch [9181/10000], Loss: 103.9815\n",
            "Epoch [9182/10000], Loss: 104.0723\n",
            "Epoch [9183/10000], Loss: 104.3489\n",
            "Epoch [9184/10000], Loss: 105.9658\n",
            "Epoch [9185/10000], Loss: 105.9974\n",
            "Epoch [9186/10000], Loss: 104.8768\n",
            "Epoch [9187/10000], Loss: 107.4169\n",
            "Epoch [9188/10000], Loss: 101.7244\n",
            "Epoch [9189/10000], Loss: 104.0663\n",
            "Epoch [9190/10000], Loss: 102.3105\n",
            "Epoch [9191/10000], Loss: 104.3298\n",
            "Epoch [9192/10000], Loss: 103.8234\n",
            "Epoch [9193/10000], Loss: 106.0006\n",
            "Epoch [9194/10000], Loss: 100.5811\n",
            "Epoch [9195/10000], Loss: 98.0997\n",
            "Epoch [9196/10000], Loss: 102.4557\n",
            "Epoch [9197/10000], Loss: 109.9847\n",
            "Epoch [9198/10000], Loss: 101.6651\n",
            "Epoch [9199/10000], Loss: 107.3229\n",
            "Epoch [9200/10000], Loss: 108.0835\n",
            "Epoch [9201/10000], Loss: 108.9334\n",
            "Epoch [9202/10000], Loss: 109.0835\n",
            "Epoch [9203/10000], Loss: 108.5461\n",
            "Epoch [9204/10000], Loss: 110.8468\n",
            "Epoch [9205/10000], Loss: 97.8119\n",
            "Epoch [9206/10000], Loss: 106.3906\n",
            "Epoch [9207/10000], Loss: 108.4348\n",
            "Epoch [9208/10000], Loss: 105.0337\n",
            "Epoch [9209/10000], Loss: 104.9558\n",
            "Epoch [9210/10000], Loss: 102.2494\n",
            "Epoch [9211/10000], Loss: 100.9743\n",
            "Epoch [9212/10000], Loss: 108.4067\n",
            "Epoch [9213/10000], Loss: 104.9710\n",
            "Epoch [9214/10000], Loss: 105.6137\n",
            "Epoch [9215/10000], Loss: 100.9831\n",
            "Epoch [9216/10000], Loss: 102.7872\n",
            "Epoch [9217/10000], Loss: 104.7473\n",
            "Epoch [9218/10000], Loss: 104.1279\n",
            "Epoch [9219/10000], Loss: 102.4549\n",
            "Epoch [9220/10000], Loss: 105.5192\n",
            "Epoch [9221/10000], Loss: 111.0588\n",
            "Epoch [9222/10000], Loss: 100.4213\n",
            "Epoch [9223/10000], Loss: 106.9380\n",
            "Epoch [9224/10000], Loss: 102.0392\n",
            "Epoch [9225/10000], Loss: 100.7716\n",
            "Epoch [9226/10000], Loss: 103.6170\n",
            "Epoch [9227/10000], Loss: 107.6936\n",
            "Epoch [9228/10000], Loss: 102.3706\n",
            "Epoch [9229/10000], Loss: 102.5289\n",
            "Epoch [9230/10000], Loss: 106.4585\n",
            "Epoch [9231/10000], Loss: 101.4776\n",
            "Epoch [9232/10000], Loss: 103.5212\n",
            "Epoch [9233/10000], Loss: 104.5369\n",
            "Epoch [9234/10000], Loss: 106.5095\n",
            "Epoch [9235/10000], Loss: 111.6337\n",
            "Epoch [9236/10000], Loss: 101.6486\n",
            "Epoch [9237/10000], Loss: 104.8347\n",
            "Epoch [9238/10000], Loss: 110.7368\n",
            "Epoch [9239/10000], Loss: 109.7840\n",
            "Epoch [9240/10000], Loss: 104.5844\n",
            "Epoch [9241/10000], Loss: 102.7952\n",
            "Epoch [9242/10000], Loss: 100.8054\n",
            "Epoch [9243/10000], Loss: 105.3602\n",
            "Epoch [9244/10000], Loss: 101.7457\n",
            "Epoch [9245/10000], Loss: 104.4430\n",
            "Epoch [9246/10000], Loss: 110.6792\n",
            "Epoch [9247/10000], Loss: 105.5877\n",
            "Epoch [9248/10000], Loss: 105.0938\n",
            "Epoch [9249/10000], Loss: 112.5388\n",
            "Epoch [9250/10000], Loss: 111.6442\n",
            "Epoch [9251/10000], Loss: 104.4011\n",
            "Epoch [9252/10000], Loss: 101.0340\n",
            "Epoch [9253/10000], Loss: 107.6393\n",
            "Epoch [9254/10000], Loss: 98.9085\n",
            "Epoch [9255/10000], Loss: 104.1384\n",
            "Epoch [9256/10000], Loss: 102.8363\n",
            "Epoch [9257/10000], Loss: 102.2581\n",
            "Epoch [9258/10000], Loss: 107.4965\n",
            "Epoch [9259/10000], Loss: 102.0165\n",
            "Epoch [9260/10000], Loss: 102.7442\n",
            "Epoch [9261/10000], Loss: 104.4329\n",
            "Epoch [9262/10000], Loss: 107.3482\n",
            "Epoch [9263/10000], Loss: 104.9621\n",
            "Epoch [9264/10000], Loss: 101.1409\n",
            "Epoch [9265/10000], Loss: 102.5496\n",
            "Epoch [9266/10000], Loss: 106.1539\n",
            "Epoch [9267/10000], Loss: 103.7036\n",
            "Epoch [9268/10000], Loss: 103.7168\n",
            "Epoch [9269/10000], Loss: 111.3419\n",
            "Epoch [9270/10000], Loss: 103.0518\n",
            "Epoch [9271/10000], Loss: 103.2152\n",
            "Epoch [9272/10000], Loss: 100.2567\n",
            "Epoch [9273/10000], Loss: 108.2706\n",
            "Epoch [9274/10000], Loss: 102.2342\n",
            "Epoch [9275/10000], Loss: 104.3592\n",
            "Epoch [9276/10000], Loss: 105.1840\n",
            "Epoch [9277/10000], Loss: 102.7086\n",
            "Epoch [9278/10000], Loss: 107.3198\n",
            "Epoch [9279/10000], Loss: 107.5062\n",
            "Epoch [9280/10000], Loss: 101.6289\n",
            "Epoch [9281/10000], Loss: 105.2815\n",
            "Epoch [9282/10000], Loss: 98.8456\n",
            "Epoch [9283/10000], Loss: 102.3996\n",
            "Epoch [9284/10000], Loss: 105.1285\n",
            "Epoch [9285/10000], Loss: 108.5023\n",
            "Epoch [9286/10000], Loss: 103.3041\n",
            "Epoch [9287/10000], Loss: 107.0999\n",
            "Epoch [9288/10000], Loss: 105.5361\n",
            "Epoch [9289/10000], Loss: 112.3117\n",
            "Epoch [9290/10000], Loss: 103.1684\n",
            "Epoch [9291/10000], Loss: 102.1152\n",
            "Epoch [9292/10000], Loss: 104.8713\n",
            "Epoch [9293/10000], Loss: 101.3241\n",
            "Epoch [9294/10000], Loss: 102.4522\n",
            "Epoch [9295/10000], Loss: 106.1241\n",
            "Epoch [9296/10000], Loss: 97.1326\n",
            "Epoch [9297/10000], Loss: 101.2767\n",
            "Epoch [9298/10000], Loss: 111.9593\n",
            "Epoch [9299/10000], Loss: 107.2797\n",
            "Epoch [9300/10000], Loss: 103.0794\n",
            "Epoch [9301/10000], Loss: 102.5952\n",
            "Epoch [9302/10000], Loss: 105.9093\n",
            "Epoch [9303/10000], Loss: 107.6277\n",
            "Epoch [9304/10000], Loss: 105.6941\n",
            "Epoch [9305/10000], Loss: 103.6533\n",
            "Epoch [9306/10000], Loss: 100.9484\n",
            "Epoch [9307/10000], Loss: 94.2419\n",
            "Epoch [9308/10000], Loss: 106.0708\n",
            "Epoch [9309/10000], Loss: 103.9537\n",
            "Epoch [9310/10000], Loss: 106.3762\n",
            "Epoch [9311/10000], Loss: 102.9526\n",
            "Epoch [9312/10000], Loss: 102.6181\n",
            "Epoch [9313/10000], Loss: 99.4448\n",
            "Epoch [9314/10000], Loss: 108.3586\n",
            "Epoch [9315/10000], Loss: 108.5839\n",
            "Epoch [9316/10000], Loss: 103.6182\n",
            "Epoch [9317/10000], Loss: 103.0908\n",
            "Epoch [9318/10000], Loss: 98.9177\n",
            "Epoch [9319/10000], Loss: 102.5908\n",
            "Epoch [9320/10000], Loss: 110.0220\n",
            "Epoch [9321/10000], Loss: 104.1698\n",
            "Epoch [9322/10000], Loss: 94.8475\n",
            "Epoch [9323/10000], Loss: 106.7457\n",
            "Epoch [9324/10000], Loss: 99.6375\n",
            "Epoch [9325/10000], Loss: 102.0715\n",
            "Epoch [9326/10000], Loss: 101.1105\n",
            "Epoch [9327/10000], Loss: 106.3115\n",
            "Epoch [9328/10000], Loss: 103.8520\n",
            "Epoch [9329/10000], Loss: 102.2201\n",
            "Epoch [9330/10000], Loss: 99.8583\n",
            "Epoch [9331/10000], Loss: 103.2638\n",
            "Epoch [9332/10000], Loss: 106.1453\n",
            "Epoch [9333/10000], Loss: 103.9256\n",
            "Epoch [9334/10000], Loss: 105.7439\n",
            "Epoch [9335/10000], Loss: 103.6032\n",
            "Epoch [9336/10000], Loss: 100.5279\n",
            "Epoch [9337/10000], Loss: 100.3144\n",
            "Epoch [9338/10000], Loss: 110.2069\n",
            "Epoch [9339/10000], Loss: 102.2574\n",
            "Epoch [9340/10000], Loss: 99.6982\n",
            "Epoch [9341/10000], Loss: 103.3352\n",
            "Epoch [9342/10000], Loss: 103.7337\n",
            "Epoch [9343/10000], Loss: 99.5900\n",
            "Epoch [9344/10000], Loss: 101.0221\n",
            "Epoch [9345/10000], Loss: 95.9040\n",
            "Epoch [9346/10000], Loss: 104.8345\n",
            "Epoch [9347/10000], Loss: 100.1046\n",
            "Epoch [9348/10000], Loss: 108.1660\n",
            "Epoch [9349/10000], Loss: 101.8034\n",
            "Epoch [9350/10000], Loss: 105.6462\n",
            "Epoch [9351/10000], Loss: 102.6118\n",
            "Epoch [9352/10000], Loss: 105.1390\n",
            "Epoch [9353/10000], Loss: 101.5583\n",
            "Epoch [9354/10000], Loss: 104.4693\n",
            "Epoch [9355/10000], Loss: 106.8034\n",
            "Epoch [9356/10000], Loss: 100.2361\n",
            "Epoch [9357/10000], Loss: 101.2845\n",
            "Epoch [9358/10000], Loss: 105.5269\n",
            "Epoch [9359/10000], Loss: 102.5683\n",
            "Epoch [9360/10000], Loss: 107.3082\n",
            "Epoch [9361/10000], Loss: 102.8978\n",
            "Epoch [9362/10000], Loss: 108.5175\n",
            "Epoch [9363/10000], Loss: 108.6200\n",
            "Epoch [9364/10000], Loss: 105.3317\n",
            "Epoch [9365/10000], Loss: 107.6202\n",
            "Epoch [9366/10000], Loss: 98.7460\n",
            "Epoch [9367/10000], Loss: 101.9533\n",
            "Epoch [9368/10000], Loss: 106.3935\n",
            "Epoch [9369/10000], Loss: 100.8260\n",
            "Epoch [9370/10000], Loss: 101.3447\n",
            "Epoch [9371/10000], Loss: 103.3466\n",
            "Epoch [9372/10000], Loss: 104.7324\n",
            "Epoch [9373/10000], Loss: 102.0794\n",
            "Epoch [9374/10000], Loss: 102.2313\n",
            "Epoch [9375/10000], Loss: 99.7146\n",
            "Epoch [9376/10000], Loss: 97.7703\n",
            "Epoch [9377/10000], Loss: 102.1484\n",
            "Epoch [9378/10000], Loss: 109.5740\n",
            "Epoch [9379/10000], Loss: 97.0541\n",
            "Epoch [9380/10000], Loss: 100.2303\n",
            "Epoch [9381/10000], Loss: 104.2138\n",
            "Epoch [9382/10000], Loss: 101.3146\n",
            "Epoch [9383/10000], Loss: 104.6679\n",
            "Epoch [9384/10000], Loss: 103.7999\n",
            "Epoch [9385/10000], Loss: 100.6848\n",
            "Epoch [9386/10000], Loss: 102.1680\n",
            "Epoch [9387/10000], Loss: 103.2830\n",
            "Epoch [9388/10000], Loss: 103.7020\n",
            "Epoch [9389/10000], Loss: 108.3254\n",
            "Epoch [9390/10000], Loss: 104.9382\n",
            "Epoch [9391/10000], Loss: 105.0935\n",
            "Epoch [9392/10000], Loss: 102.6958\n",
            "Epoch [9393/10000], Loss: 100.4384\n",
            "Epoch [9394/10000], Loss: 103.1087\n",
            "Epoch [9395/10000], Loss: 102.2805\n",
            "Epoch [9396/10000], Loss: 111.3582\n",
            "Epoch [9397/10000], Loss: 104.9556\n",
            "Epoch [9398/10000], Loss: 96.1548\n",
            "Epoch [9399/10000], Loss: 103.2542\n",
            "Epoch [9400/10000], Loss: 108.5970\n",
            "Epoch [9401/10000], Loss: 103.2830\n",
            "Epoch [9402/10000], Loss: 99.9436\n",
            "Epoch [9403/10000], Loss: 97.6258\n",
            "Epoch [9404/10000], Loss: 108.6260\n",
            "Epoch [9405/10000], Loss: 107.2344\n",
            "Epoch [9406/10000], Loss: 107.6911\n",
            "Epoch [9407/10000], Loss: 105.5345\n",
            "Epoch [9408/10000], Loss: 109.6373\n",
            "Epoch [9409/10000], Loss: 103.2883\n",
            "Epoch [9410/10000], Loss: 104.0584\n",
            "Epoch [9411/10000], Loss: 99.4454\n",
            "Epoch [9412/10000], Loss: 100.4269\n",
            "Epoch [9413/10000], Loss: 98.1262\n",
            "Epoch [9414/10000], Loss: 97.4199\n",
            "Epoch [9415/10000], Loss: 98.7587\n",
            "Epoch [9416/10000], Loss: 97.2724\n",
            "Epoch [9417/10000], Loss: 102.7148\n",
            "Epoch [9418/10000], Loss: 104.3978\n",
            "Epoch [9419/10000], Loss: 109.0755\n",
            "Epoch [9420/10000], Loss: 99.1235\n",
            "Epoch [9421/10000], Loss: 100.3574\n",
            "Epoch [9422/10000], Loss: 106.2852\n",
            "Epoch [9423/10000], Loss: 106.6457\n",
            "Epoch [9424/10000], Loss: 103.4245\n",
            "Epoch [9425/10000], Loss: 98.1328\n",
            "Epoch [9426/10000], Loss: 102.0861\n",
            "Epoch [9427/10000], Loss: 100.2375\n",
            "Epoch [9428/10000], Loss: 97.3122\n",
            "Epoch [9429/10000], Loss: 103.7459\n",
            "Epoch [9430/10000], Loss: 105.1289\n",
            "Epoch [9431/10000], Loss: 104.3541\n",
            "Epoch [9432/10000], Loss: 109.1671\n",
            "Epoch [9433/10000], Loss: 105.3920\n",
            "Epoch [9434/10000], Loss: 100.2622\n",
            "Epoch [9435/10000], Loss: 98.1152\n",
            "Epoch [9436/10000], Loss: 104.8717\n",
            "Epoch [9437/10000], Loss: 100.5970\n",
            "Epoch [9438/10000], Loss: 104.4359\n",
            "Epoch [9439/10000], Loss: 102.9911\n",
            "Epoch [9440/10000], Loss: 105.6101\n",
            "Epoch [9441/10000], Loss: 108.0086\n",
            "Epoch [9442/10000], Loss: 108.0783\n",
            "Epoch [9443/10000], Loss: 100.3329\n",
            "Epoch [9444/10000], Loss: 100.3886\n",
            "Epoch [9445/10000], Loss: 107.8441\n",
            "Epoch [9446/10000], Loss: 102.9186\n",
            "Epoch [9447/10000], Loss: 103.1199\n",
            "Epoch [9448/10000], Loss: 99.3744\n",
            "Epoch [9449/10000], Loss: 96.1047\n",
            "Epoch [9450/10000], Loss: 99.5194\n",
            "Epoch [9451/10000], Loss: 103.1095\n",
            "Epoch [9452/10000], Loss: 104.8008\n",
            "Epoch [9453/10000], Loss: 100.0977\n",
            "Epoch [9454/10000], Loss: 102.9072\n",
            "Epoch [9455/10000], Loss: 102.7879\n",
            "Epoch [9456/10000], Loss: 104.6752\n",
            "Epoch [9457/10000], Loss: 103.3118\n",
            "Epoch [9458/10000], Loss: 100.7020\n",
            "Epoch [9459/10000], Loss: 101.3729\n",
            "Epoch [9460/10000], Loss: 103.4034\n",
            "Epoch [9461/10000], Loss: 102.0281\n",
            "Epoch [9462/10000], Loss: 100.9341\n",
            "Epoch [9463/10000], Loss: 106.8141\n",
            "Epoch [9464/10000], Loss: 101.9954\n",
            "Epoch [9465/10000], Loss: 107.8909\n",
            "Epoch [9466/10000], Loss: 107.6977\n",
            "Epoch [9467/10000], Loss: 101.9168\n",
            "Epoch [9468/10000], Loss: 108.1175\n",
            "Epoch [9469/10000], Loss: 97.3941\n",
            "Epoch [9470/10000], Loss: 101.3119\n",
            "Epoch [9471/10000], Loss: 107.3852\n",
            "Epoch [9472/10000], Loss: 103.7265\n",
            "Epoch [9473/10000], Loss: 103.3012\n",
            "Epoch [9474/10000], Loss: 101.1025\n",
            "Epoch [9475/10000], Loss: 98.7880\n",
            "Epoch [9476/10000], Loss: 104.5134\n",
            "Epoch [9477/10000], Loss: 98.9344\n",
            "Epoch [9478/10000], Loss: 104.5101\n",
            "Epoch [9479/10000], Loss: 99.8065\n",
            "Epoch [9480/10000], Loss: 101.4289\n",
            "Epoch [9481/10000], Loss: 101.3054\n",
            "Epoch [9482/10000], Loss: 98.0898\n",
            "Epoch [9483/10000], Loss: 106.3701\n",
            "Epoch [9484/10000], Loss: 97.5725\n",
            "Epoch [9485/10000], Loss: 99.0983\n",
            "Epoch [9486/10000], Loss: 105.4079\n",
            "Epoch [9487/10000], Loss: 97.7416\n",
            "Epoch [9488/10000], Loss: 101.5210\n",
            "Epoch [9489/10000], Loss: 99.9306\n",
            "Epoch [9490/10000], Loss: 102.5377\n",
            "Epoch [9491/10000], Loss: 101.2112\n",
            "Epoch [9492/10000], Loss: 101.8686\n",
            "Epoch [9493/10000], Loss: 101.6738\n",
            "Epoch [9494/10000], Loss: 105.8486\n",
            "Epoch [9495/10000], Loss: 103.3073\n",
            "Epoch [9496/10000], Loss: 111.2081\n",
            "Epoch [9497/10000], Loss: 103.0393\n",
            "Epoch [9498/10000], Loss: 102.4544\n",
            "Epoch [9499/10000], Loss: 101.6084\n",
            "Epoch [9500/10000], Loss: 100.1585\n",
            "Epoch [9501/10000], Loss: 105.3064\n",
            "Epoch [9502/10000], Loss: 95.5231\n",
            "Epoch [9503/10000], Loss: 104.3249\n",
            "Epoch [9504/10000], Loss: 99.2830\n",
            "Epoch [9505/10000], Loss: 98.4615\n",
            "Epoch [9506/10000], Loss: 105.1600\n",
            "Epoch [9507/10000], Loss: 106.6704\n",
            "Epoch [9508/10000], Loss: 103.2313\n",
            "Epoch [9509/10000], Loss: 101.8502\n",
            "Epoch [9510/10000], Loss: 100.5272\n",
            "Epoch [9511/10000], Loss: 102.4697\n",
            "Epoch [9512/10000], Loss: 104.2464\n",
            "Epoch [9513/10000], Loss: 105.0011\n",
            "Epoch [9514/10000], Loss: 102.6226\n",
            "Epoch [9515/10000], Loss: 102.6795\n",
            "Epoch [9516/10000], Loss: 107.8949\n",
            "Epoch [9517/10000], Loss: 107.0695\n",
            "Epoch [9518/10000], Loss: 97.7626\n",
            "Epoch [9519/10000], Loss: 106.7048\n",
            "Epoch [9520/10000], Loss: 99.0637\n",
            "Epoch [9521/10000], Loss: 103.0322\n",
            "Epoch [9522/10000], Loss: 106.6564\n",
            "Epoch [9523/10000], Loss: 105.1102\n",
            "Epoch [9524/10000], Loss: 98.2568\n",
            "Epoch [9525/10000], Loss: 103.1838\n",
            "Epoch [9526/10000], Loss: 106.4109\n",
            "Epoch [9527/10000], Loss: 103.4200\n",
            "Epoch [9528/10000], Loss: 102.2567\n",
            "Epoch [9529/10000], Loss: 98.4938\n",
            "Epoch [9530/10000], Loss: 104.5795\n",
            "Epoch [9531/10000], Loss: 100.2281\n",
            "Epoch [9532/10000], Loss: 104.5434\n",
            "Epoch [9533/10000], Loss: 103.0046\n",
            "Epoch [9534/10000], Loss: 103.7544\n",
            "Epoch [9535/10000], Loss: 100.5930\n",
            "Epoch [9536/10000], Loss: 104.3513\n",
            "Epoch [9537/10000], Loss: 104.9612\n",
            "Epoch [9538/10000], Loss: 100.7822\n",
            "Epoch [9539/10000], Loss: 106.1783\n",
            "Epoch [9540/10000], Loss: 99.6885\n",
            "Epoch [9541/10000], Loss: 101.9644\n",
            "Epoch [9542/10000], Loss: 104.7719\n",
            "Epoch [9543/10000], Loss: 105.6030\n",
            "Epoch [9544/10000], Loss: 99.5623\n",
            "Epoch [9545/10000], Loss: 103.2071\n",
            "Epoch [9546/10000], Loss: 99.1596\n",
            "Epoch [9547/10000], Loss: 101.2096\n",
            "Epoch [9548/10000], Loss: 98.4954\n",
            "Epoch [9549/10000], Loss: 104.4304\n",
            "Epoch [9550/10000], Loss: 100.0889\n",
            "Epoch [9551/10000], Loss: 102.2098\n",
            "Epoch [9552/10000], Loss: 99.7768\n",
            "Epoch [9553/10000], Loss: 97.1635\n",
            "Epoch [9554/10000], Loss: 102.8406\n",
            "Epoch [9555/10000], Loss: 104.6053\n",
            "Epoch [9556/10000], Loss: 97.3127\n",
            "Epoch [9557/10000], Loss: 109.9524\n",
            "Epoch [9558/10000], Loss: 107.1272\n",
            "Epoch [9559/10000], Loss: 106.8264\n",
            "Epoch [9560/10000], Loss: 103.3675\n",
            "Epoch [9561/10000], Loss: 104.3025\n",
            "Epoch [9562/10000], Loss: 93.5615\n",
            "Epoch [9563/10000], Loss: 101.7079\n",
            "Epoch [9564/10000], Loss: 102.9732\n",
            "Epoch [9565/10000], Loss: 105.4328\n",
            "Epoch [9566/10000], Loss: 98.6594\n",
            "Epoch [9567/10000], Loss: 101.0475\n",
            "Epoch [9568/10000], Loss: 100.8979\n",
            "Epoch [9569/10000], Loss: 96.4857\n",
            "Epoch [9570/10000], Loss: 106.2911\n",
            "Epoch [9571/10000], Loss: 109.4272\n",
            "Epoch [9572/10000], Loss: 99.3199\n",
            "Epoch [9573/10000], Loss: 105.8963\n",
            "Epoch [9574/10000], Loss: 105.1541\n",
            "Epoch [9575/10000], Loss: 98.5009\n",
            "Epoch [9576/10000], Loss: 102.3769\n",
            "Epoch [9577/10000], Loss: 102.9010\n",
            "Epoch [9578/10000], Loss: 103.8708\n",
            "Epoch [9579/10000], Loss: 99.2910\n",
            "Epoch [9580/10000], Loss: 104.8262\n",
            "Epoch [9581/10000], Loss: 98.0854\n",
            "Epoch [9582/10000], Loss: 100.2547\n",
            "Epoch [9583/10000], Loss: 102.6897\n",
            "Epoch [9584/10000], Loss: 109.1203\n",
            "Epoch [9585/10000], Loss: 107.8696\n",
            "Epoch [9586/10000], Loss: 106.4575\n",
            "Epoch [9587/10000], Loss: 107.7424\n",
            "Epoch [9588/10000], Loss: 102.5777\n",
            "Epoch [9589/10000], Loss: 103.6234\n",
            "Epoch [9590/10000], Loss: 99.3759\n",
            "Epoch [9591/10000], Loss: 100.0454\n",
            "Epoch [9592/10000], Loss: 100.5162\n",
            "Epoch [9593/10000], Loss: 106.5365\n",
            "Epoch [9594/10000], Loss: 107.2859\n",
            "Epoch [9595/10000], Loss: 103.2929\n",
            "Epoch [9596/10000], Loss: 98.1530\n",
            "Epoch [9597/10000], Loss: 101.5044\n",
            "Epoch [9598/10000], Loss: 99.9864\n",
            "Epoch [9599/10000], Loss: 99.9516\n",
            "Epoch [9600/10000], Loss: 97.2092\n",
            "Epoch [9601/10000], Loss: 105.2911\n",
            "Epoch [9602/10000], Loss: 97.3474\n",
            "Epoch [9603/10000], Loss: 98.3720\n",
            "Epoch [9604/10000], Loss: 101.6761\n",
            "Epoch [9605/10000], Loss: 98.9287\n",
            "Epoch [9606/10000], Loss: 102.5963\n",
            "Epoch [9607/10000], Loss: 98.4235\n",
            "Epoch [9608/10000], Loss: 103.5955\n",
            "Epoch [9609/10000], Loss: 109.5740\n",
            "Epoch [9610/10000], Loss: 108.9634\n",
            "Epoch [9611/10000], Loss: 97.1905\n",
            "Epoch [9612/10000], Loss: 99.7887\n",
            "Epoch [9613/10000], Loss: 108.3349\n",
            "Epoch [9614/10000], Loss: 104.3528\n",
            "Epoch [9615/10000], Loss: 101.2025\n",
            "Epoch [9616/10000], Loss: 103.3936\n",
            "Epoch [9617/10000], Loss: 101.0118\n",
            "Epoch [9618/10000], Loss: 98.1362\n",
            "Epoch [9619/10000], Loss: 102.5435\n",
            "Epoch [9620/10000], Loss: 101.2663\n",
            "Epoch [9621/10000], Loss: 91.6025\n",
            "Epoch [9622/10000], Loss: 98.9916\n",
            "Epoch [9623/10000], Loss: 97.5471\n",
            "Epoch [9624/10000], Loss: 105.7714\n",
            "Epoch [9625/10000], Loss: 102.4687\n",
            "Epoch [9626/10000], Loss: 98.4285\n",
            "Epoch [9627/10000], Loss: 97.8376\n",
            "Epoch [9628/10000], Loss: 95.6335\n",
            "Epoch [9629/10000], Loss: 98.5754\n",
            "Epoch [9630/10000], Loss: 101.5441\n",
            "Epoch [9631/10000], Loss: 100.5746\n",
            "Epoch [9632/10000], Loss: 104.8939\n",
            "Epoch [9633/10000], Loss: 102.6151\n",
            "Epoch [9634/10000], Loss: 102.8684\n",
            "Epoch [9635/10000], Loss: 100.6645\n",
            "Epoch [9636/10000], Loss: 103.3898\n",
            "Epoch [9637/10000], Loss: 103.4440\n",
            "Epoch [9638/10000], Loss: 104.1016\n",
            "Epoch [9639/10000], Loss: 105.8419\n",
            "Epoch [9640/10000], Loss: 98.0282\n",
            "Epoch [9641/10000], Loss: 104.8286\n",
            "Epoch [9642/10000], Loss: 99.3531\n",
            "Epoch [9643/10000], Loss: 101.9722\n",
            "Epoch [9644/10000], Loss: 107.6951\n",
            "Epoch [9645/10000], Loss: 104.2652\n",
            "Epoch [9646/10000], Loss: 94.7802\n",
            "Epoch [9647/10000], Loss: 97.4401\n",
            "Epoch [9648/10000], Loss: 102.4538\n",
            "Epoch [9649/10000], Loss: 99.2288\n",
            "Epoch [9650/10000], Loss: 95.1702\n",
            "Epoch [9651/10000], Loss: 98.9299\n",
            "Epoch [9652/10000], Loss: 104.8556\n",
            "Epoch [9653/10000], Loss: 103.1899\n",
            "Epoch [9654/10000], Loss: 104.6010\n",
            "Epoch [9655/10000], Loss: 102.4246\n",
            "Epoch [9656/10000], Loss: 98.3862\n",
            "Epoch [9657/10000], Loss: 101.0861\n",
            "Epoch [9658/10000], Loss: 102.1678\n",
            "Epoch [9659/10000], Loss: 98.9649\n",
            "Epoch [9660/10000], Loss: 108.0222\n",
            "Epoch [9661/10000], Loss: 98.4790\n",
            "Epoch [9662/10000], Loss: 93.8055\n",
            "Epoch [9663/10000], Loss: 102.4257\n",
            "Epoch [9664/10000], Loss: 106.6923\n",
            "Epoch [9665/10000], Loss: 97.2922\n",
            "Epoch [9666/10000], Loss: 106.0701\n",
            "Epoch [9667/10000], Loss: 101.1013\n",
            "Epoch [9668/10000], Loss: 103.1161\n",
            "Epoch [9669/10000], Loss: 99.4061\n",
            "Epoch [9670/10000], Loss: 104.0518\n",
            "Epoch [9671/10000], Loss: 103.0483\n",
            "Epoch [9672/10000], Loss: 97.4674\n",
            "Epoch [9673/10000], Loss: 101.2352\n",
            "Epoch [9674/10000], Loss: 103.0125\n",
            "Epoch [9675/10000], Loss: 99.9694\n",
            "Epoch [9676/10000], Loss: 99.2121\n",
            "Epoch [9677/10000], Loss: 98.9708\n",
            "Epoch [9678/10000], Loss: 100.2296\n",
            "Epoch [9679/10000], Loss: 106.7675\n",
            "Epoch [9680/10000], Loss: 99.3708\n",
            "Epoch [9681/10000], Loss: 102.8478\n",
            "Epoch [9682/10000], Loss: 102.2087\n",
            "Epoch [9683/10000], Loss: 104.2093\n",
            "Epoch [9684/10000], Loss: 102.1362\n",
            "Epoch [9685/10000], Loss: 103.4014\n",
            "Epoch [9686/10000], Loss: 101.6024\n",
            "Epoch [9687/10000], Loss: 99.5416\n",
            "Epoch [9688/10000], Loss: 108.7312\n",
            "Epoch [9689/10000], Loss: 98.9552\n",
            "Epoch [9690/10000], Loss: 105.4824\n",
            "Epoch [9691/10000], Loss: 101.3460\n",
            "Epoch [9692/10000], Loss: 99.4611\n",
            "Epoch [9693/10000], Loss: 98.2496\n",
            "Epoch [9694/10000], Loss: 102.1285\n",
            "Epoch [9695/10000], Loss: 102.4834\n",
            "Epoch [9696/10000], Loss: 100.4843\n",
            "Epoch [9697/10000], Loss: 98.4417\n",
            "Epoch [9698/10000], Loss: 94.9387\n",
            "Epoch [9699/10000], Loss: 101.7916\n",
            "Epoch [9700/10000], Loss: 99.2476\n",
            "Epoch [9701/10000], Loss: 109.9466\n",
            "Epoch [9702/10000], Loss: 103.5567\n",
            "Epoch [9703/10000], Loss: 105.4387\n",
            "Epoch [9704/10000], Loss: 96.8448\n",
            "Epoch [9705/10000], Loss: 93.4486\n",
            "Epoch [9706/10000], Loss: 105.9854\n",
            "Epoch [9707/10000], Loss: 106.8773\n",
            "Epoch [9708/10000], Loss: 103.1180\n",
            "Epoch [9709/10000], Loss: 100.5301\n",
            "Epoch [9710/10000], Loss: 103.7295\n",
            "Epoch [9711/10000], Loss: 104.3009\n",
            "Epoch [9712/10000], Loss: 100.0838\n",
            "Epoch [9713/10000], Loss: 98.9339\n",
            "Epoch [9714/10000], Loss: 101.7546\n",
            "Epoch [9715/10000], Loss: 103.2694\n",
            "Epoch [9716/10000], Loss: 94.7902\n",
            "Epoch [9717/10000], Loss: 107.3931\n",
            "Epoch [9718/10000], Loss: 105.1007\n",
            "Epoch [9719/10000], Loss: 101.6518\n",
            "Epoch [9720/10000], Loss: 98.8948\n",
            "Epoch [9721/10000], Loss: 106.1839\n",
            "Epoch [9722/10000], Loss: 100.7014\n",
            "Epoch [9723/10000], Loss: 105.3378\n",
            "Epoch [9724/10000], Loss: 105.8053\n",
            "Epoch [9725/10000], Loss: 104.7520\n",
            "Epoch [9726/10000], Loss: 103.4355\n",
            "Epoch [9727/10000], Loss: 99.5721\n",
            "Epoch [9728/10000], Loss: 100.7273\n",
            "Epoch [9729/10000], Loss: 99.5518\n",
            "Epoch [9730/10000], Loss: 103.6038\n",
            "Epoch [9731/10000], Loss: 99.2334\n",
            "Epoch [9732/10000], Loss: 96.0751\n",
            "Epoch [9733/10000], Loss: 99.0833\n",
            "Epoch [9734/10000], Loss: 96.5068\n",
            "Epoch [9735/10000], Loss: 99.1542\n",
            "Epoch [9736/10000], Loss: 96.6374\n",
            "Epoch [9737/10000], Loss: 100.4895\n",
            "Epoch [9738/10000], Loss: 99.7903\n",
            "Epoch [9739/10000], Loss: 105.8248\n",
            "Epoch [9740/10000], Loss: 101.5396\n",
            "Epoch [9741/10000], Loss: 103.6030\n",
            "Epoch [9742/10000], Loss: 98.7710\n",
            "Epoch [9743/10000], Loss: 102.8665\n",
            "Epoch [9744/10000], Loss: 101.7467\n",
            "Epoch [9745/10000], Loss: 89.7251\n",
            "Epoch [9746/10000], Loss: 96.8530\n",
            "Epoch [9747/10000], Loss: 102.5101\n",
            "Epoch [9748/10000], Loss: 105.1190\n",
            "Epoch [9749/10000], Loss: 101.5095\n",
            "Epoch [9750/10000], Loss: 99.2991\n",
            "Epoch [9751/10000], Loss: 95.3554\n",
            "Epoch [9752/10000], Loss: 103.1760\n",
            "Epoch [9753/10000], Loss: 98.7430\n",
            "Epoch [9754/10000], Loss: 99.0373\n",
            "Epoch [9755/10000], Loss: 99.3872\n",
            "Epoch [9756/10000], Loss: 101.2160\n",
            "Epoch [9757/10000], Loss: 100.3614\n",
            "Epoch [9758/10000], Loss: 99.0905\n",
            "Epoch [9759/10000], Loss: 101.3799\n",
            "Epoch [9760/10000], Loss: 103.5370\n",
            "Epoch [9761/10000], Loss: 98.9567\n",
            "Epoch [9762/10000], Loss: 101.7276\n",
            "Epoch [9763/10000], Loss: 99.2084\n",
            "Epoch [9764/10000], Loss: 98.6922\n",
            "Epoch [9765/10000], Loss: 103.3941\n",
            "Epoch [9766/10000], Loss: 102.2934\n",
            "Epoch [9767/10000], Loss: 95.8857\n",
            "Epoch [9768/10000], Loss: 96.0956\n",
            "Epoch [9769/10000], Loss: 103.0581\n",
            "Epoch [9770/10000], Loss: 94.6707\n",
            "Epoch [9771/10000], Loss: 101.5924\n",
            "Epoch [9772/10000], Loss: 95.8868\n",
            "Epoch [9773/10000], Loss: 98.0036\n",
            "Epoch [9774/10000], Loss: 95.6587\n",
            "Epoch [9775/10000], Loss: 99.7071\n",
            "Epoch [9776/10000], Loss: 104.6800\n",
            "Epoch [9777/10000], Loss: 96.4800\n",
            "Epoch [9778/10000], Loss: 101.6332\n",
            "Epoch [9779/10000], Loss: 100.2877\n",
            "Epoch [9780/10000], Loss: 98.0567\n",
            "Epoch [9781/10000], Loss: 97.7202\n",
            "Epoch [9782/10000], Loss: 103.8317\n",
            "Epoch [9783/10000], Loss: 101.3726\n",
            "Epoch [9784/10000], Loss: 103.5032\n",
            "Epoch [9785/10000], Loss: 98.9711\n",
            "Epoch [9786/10000], Loss: 101.6310\n",
            "Epoch [9787/10000], Loss: 105.7771\n",
            "Epoch [9788/10000], Loss: 104.1594\n",
            "Epoch [9789/10000], Loss: 99.0477\n",
            "Epoch [9790/10000], Loss: 102.7838\n",
            "Epoch [9791/10000], Loss: 99.6095\n",
            "Epoch [9792/10000], Loss: 106.9779\n",
            "Epoch [9793/10000], Loss: 98.9061\n",
            "Epoch [9794/10000], Loss: 100.9642\n",
            "Epoch [9795/10000], Loss: 100.9804\n",
            "Epoch [9796/10000], Loss: 100.6093\n",
            "Epoch [9797/10000], Loss: 100.8468\n",
            "Epoch [9798/10000], Loss: 94.8252\n",
            "Epoch [9799/10000], Loss: 99.7789\n",
            "Epoch [9800/10000], Loss: 93.6737\n",
            "Epoch [9801/10000], Loss: 105.4642\n",
            "Epoch [9802/10000], Loss: 97.6315\n",
            "Epoch [9803/10000], Loss: 103.3767\n",
            "Epoch [9804/10000], Loss: 93.5884\n",
            "Epoch [9805/10000], Loss: 106.0941\n",
            "Epoch [9806/10000], Loss: 97.9897\n",
            "Epoch [9807/10000], Loss: 101.8405\n",
            "Epoch [9808/10000], Loss: 101.5365\n",
            "Epoch [9809/10000], Loss: 101.6020\n",
            "Epoch [9810/10000], Loss: 98.1966\n",
            "Epoch [9811/10000], Loss: 101.1010\n",
            "Epoch [9812/10000], Loss: 107.1077\n",
            "Epoch [9813/10000], Loss: 101.9049\n",
            "Epoch [9814/10000], Loss: 101.9471\n",
            "Epoch [9815/10000], Loss: 101.0579\n",
            "Epoch [9816/10000], Loss: 104.5038\n",
            "Epoch [9817/10000], Loss: 97.6178\n",
            "Epoch [9818/10000], Loss: 94.2070\n",
            "Epoch [9819/10000], Loss: 100.7829\n",
            "Epoch [9820/10000], Loss: 100.6348\n",
            "Epoch [9821/10000], Loss: 98.9340\n",
            "Epoch [9822/10000], Loss: 98.4473\n",
            "Epoch [9823/10000], Loss: 100.7537\n",
            "Epoch [9824/10000], Loss: 93.7265\n",
            "Epoch [9825/10000], Loss: 97.4382\n",
            "Epoch [9826/10000], Loss: 98.3748\n",
            "Epoch [9827/10000], Loss: 102.6878\n",
            "Epoch [9828/10000], Loss: 93.6030\n",
            "Epoch [9829/10000], Loss: 96.8334\n",
            "Epoch [9830/10000], Loss: 102.6056\n",
            "Epoch [9831/10000], Loss: 104.5891\n",
            "Epoch [9832/10000], Loss: 97.0449\n",
            "Epoch [9833/10000], Loss: 98.4933\n",
            "Epoch [9834/10000], Loss: 98.6971\n",
            "Epoch [9835/10000], Loss: 97.5900\n",
            "Epoch [9836/10000], Loss: 102.5335\n",
            "Epoch [9837/10000], Loss: 100.2184\n",
            "Epoch [9838/10000], Loss: 98.3024\n",
            "Epoch [9839/10000], Loss: 99.4301\n",
            "Epoch [9840/10000], Loss: 99.5513\n",
            "Epoch [9841/10000], Loss: 98.1586\n",
            "Epoch [9842/10000], Loss: 106.4652\n",
            "Epoch [9843/10000], Loss: 99.0090\n",
            "Epoch [9844/10000], Loss: 95.2848\n",
            "Epoch [9845/10000], Loss: 102.0757\n",
            "Epoch [9846/10000], Loss: 100.9992\n",
            "Epoch [9847/10000], Loss: 99.9932\n",
            "Epoch [9848/10000], Loss: 104.0819\n",
            "Epoch [9849/10000], Loss: 95.3554\n",
            "Epoch [9850/10000], Loss: 101.3837\n",
            "Epoch [9851/10000], Loss: 96.0199\n",
            "Epoch [9852/10000], Loss: 99.8281\n",
            "Epoch [9853/10000], Loss: 100.4537\n",
            "Epoch [9854/10000], Loss: 97.6919\n",
            "Epoch [9855/10000], Loss: 98.3583\n",
            "Epoch [9856/10000], Loss: 98.5896\n",
            "Epoch [9857/10000], Loss: 101.7607\n",
            "Epoch [9858/10000], Loss: 101.9082\n",
            "Epoch [9859/10000], Loss: 97.2024\n",
            "Epoch [9860/10000], Loss: 98.2015\n",
            "Epoch [9861/10000], Loss: 101.0817\n",
            "Epoch [9862/10000], Loss: 96.6292\n",
            "Epoch [9863/10000], Loss: 104.8404\n",
            "Epoch [9864/10000], Loss: 94.6780\n",
            "Epoch [9865/10000], Loss: 102.7778\n",
            "Epoch [9866/10000], Loss: 103.0663\n",
            "Epoch [9867/10000], Loss: 103.0537\n",
            "Epoch [9868/10000], Loss: 105.5927\n",
            "Epoch [9869/10000], Loss: 99.6477\n",
            "Epoch [9870/10000], Loss: 95.6366\n",
            "Epoch [9871/10000], Loss: 98.9240\n",
            "Epoch [9872/10000], Loss: 101.4713\n",
            "Epoch [9873/10000], Loss: 97.9848\n",
            "Epoch [9874/10000], Loss: 100.6579\n",
            "Epoch [9875/10000], Loss: 102.9733\n",
            "Epoch [9876/10000], Loss: 99.5656\n",
            "Epoch [9877/10000], Loss: 96.5387\n",
            "Epoch [9878/10000], Loss: 102.6797\n",
            "Epoch [9879/10000], Loss: 100.2927\n",
            "Epoch [9880/10000], Loss: 101.6089\n",
            "Epoch [9881/10000], Loss: 102.7075\n",
            "Epoch [9882/10000], Loss: 99.5815\n",
            "Epoch [9883/10000], Loss: 100.8359\n",
            "Epoch [9884/10000], Loss: 98.2229\n",
            "Epoch [9885/10000], Loss: 96.3611\n",
            "Epoch [9886/10000], Loss: 100.9086\n",
            "Epoch [9887/10000], Loss: 96.6730\n",
            "Epoch [9888/10000], Loss: 99.1263\n",
            "Epoch [9889/10000], Loss: 100.6122\n",
            "Epoch [9890/10000], Loss: 101.2047\n",
            "Epoch [9891/10000], Loss: 99.9329\n",
            "Epoch [9892/10000], Loss: 98.3537\n",
            "Epoch [9893/10000], Loss: 97.8960\n",
            "Epoch [9894/10000], Loss: 101.2233\n",
            "Epoch [9895/10000], Loss: 100.3780\n",
            "Epoch [9896/10000], Loss: 106.0366\n",
            "Epoch [9897/10000], Loss: 100.7200\n",
            "Epoch [9898/10000], Loss: 104.8682\n",
            "Epoch [9899/10000], Loss: 100.9499\n",
            "Epoch [9900/10000], Loss: 103.7653\n",
            "Epoch [9901/10000], Loss: 97.9205\n",
            "Epoch [9902/10000], Loss: 100.5866\n",
            "Epoch [9903/10000], Loss: 93.4452\n",
            "Epoch [9904/10000], Loss: 98.5555\n",
            "Epoch [9905/10000], Loss: 104.1810\n",
            "Epoch [9906/10000], Loss: 98.3546\n",
            "Epoch [9907/10000], Loss: 100.0259\n",
            "Epoch [9908/10000], Loss: 100.8064\n",
            "Epoch [9909/10000], Loss: 99.1713\n",
            "Epoch [9910/10000], Loss: 101.3949\n",
            "Epoch [9911/10000], Loss: 98.1729\n",
            "Epoch [9912/10000], Loss: 100.1112\n",
            "Epoch [9913/10000], Loss: 102.4484\n",
            "Epoch [9914/10000], Loss: 100.7499\n",
            "Epoch [9915/10000], Loss: 97.8105\n",
            "Epoch [9916/10000], Loss: 97.9651\n",
            "Epoch [9917/10000], Loss: 99.3742\n",
            "Epoch [9918/10000], Loss: 93.3737\n",
            "Epoch [9919/10000], Loss: 94.7466\n",
            "Epoch [9920/10000], Loss: 100.8927\n",
            "Epoch [9921/10000], Loss: 96.7991\n",
            "Epoch [9922/10000], Loss: 101.6991\n",
            "Epoch [9923/10000], Loss: 99.2461\n",
            "Epoch [9924/10000], Loss: 97.9531\n",
            "Epoch [9925/10000], Loss: 97.9974\n",
            "Epoch [9926/10000], Loss: 103.1525\n",
            "Epoch [9927/10000], Loss: 99.6718\n",
            "Epoch [9928/10000], Loss: 104.6248\n",
            "Epoch [9929/10000], Loss: 98.8245\n",
            "Epoch [9930/10000], Loss: 100.6711\n",
            "Epoch [9931/10000], Loss: 94.9937\n",
            "Epoch [9932/10000], Loss: 99.5901\n",
            "Epoch [9933/10000], Loss: 96.9715\n",
            "Epoch [9934/10000], Loss: 94.6172\n",
            "Epoch [9935/10000], Loss: 100.5884\n",
            "Epoch [9936/10000], Loss: 98.9200\n",
            "Epoch [9937/10000], Loss: 94.1084\n",
            "Epoch [9938/10000], Loss: 102.5840\n",
            "Epoch [9939/10000], Loss: 100.2831\n",
            "Epoch [9940/10000], Loss: 95.5054\n",
            "Epoch [9941/10000], Loss: 99.4053\n",
            "Epoch [9942/10000], Loss: 96.0487\n",
            "Epoch [9943/10000], Loss: 100.9326\n",
            "Epoch [9944/10000], Loss: 101.8927\n",
            "Epoch [9945/10000], Loss: 96.5123\n",
            "Epoch [9946/10000], Loss: 101.2939\n",
            "Epoch [9947/10000], Loss: 96.7629\n",
            "Epoch [9948/10000], Loss: 102.7677\n",
            "Epoch [9949/10000], Loss: 97.2944\n",
            "Epoch [9950/10000], Loss: 102.1059\n",
            "Epoch [9951/10000], Loss: 99.9909\n",
            "Epoch [9952/10000], Loss: 93.6029\n",
            "Epoch [9953/10000], Loss: 98.4554\n",
            "Epoch [9954/10000], Loss: 101.0226\n",
            "Epoch [9955/10000], Loss: 94.8303\n",
            "Epoch [9956/10000], Loss: 96.0813\n",
            "Epoch [9957/10000], Loss: 98.3185\n",
            "Epoch [9958/10000], Loss: 99.7309\n",
            "Epoch [9959/10000], Loss: 97.6497\n",
            "Epoch [9960/10000], Loss: 100.5016\n",
            "Epoch [9961/10000], Loss: 98.8542\n",
            "Epoch [9962/10000], Loss: 97.9954\n",
            "Epoch [9963/10000], Loss: 93.3596\n",
            "Epoch [9964/10000], Loss: 101.1470\n",
            "Epoch [9965/10000], Loss: 97.1932\n",
            "Epoch [9966/10000], Loss: 100.5194\n",
            "Epoch [9967/10000], Loss: 102.9616\n",
            "Epoch [9968/10000], Loss: 102.1552\n",
            "Epoch [9969/10000], Loss: 100.3651\n",
            "Epoch [9970/10000], Loss: 100.4164\n",
            "Epoch [9971/10000], Loss: 94.4335\n",
            "Epoch [9972/10000], Loss: 102.3214\n",
            "Epoch [9973/10000], Loss: 98.0058\n",
            "Epoch [9974/10000], Loss: 103.3614\n",
            "Epoch [9975/10000], Loss: 99.4332\n",
            "Epoch [9976/10000], Loss: 99.3612\n",
            "Epoch [9977/10000], Loss: 99.6903\n",
            "Epoch [9978/10000], Loss: 101.3945\n",
            "Epoch [9979/10000], Loss: 97.5366\n",
            "Epoch [9980/10000], Loss: 101.7806\n",
            "Epoch [9981/10000], Loss: 99.7886\n",
            "Epoch [9982/10000], Loss: 99.8231\n",
            "Epoch [9983/10000], Loss: 93.2769\n",
            "Epoch [9984/10000], Loss: 94.4055\n",
            "Epoch [9985/10000], Loss: 99.0127\n",
            "Epoch [9986/10000], Loss: 98.8174\n",
            "Epoch [9987/10000], Loss: 104.1041\n",
            "Epoch [9988/10000], Loss: 102.3965\n",
            "Epoch [9989/10000], Loss: 95.8049\n",
            "Epoch [9990/10000], Loss: 97.4793\n",
            "Epoch [9991/10000], Loss: 92.7605\n",
            "Epoch [9992/10000], Loss: 102.9228\n",
            "Epoch [9993/10000], Loss: 105.6977\n",
            "Epoch [9994/10000], Loss: 93.2969\n",
            "Epoch [9995/10000], Loss: 102.2918\n",
            "Epoch [9996/10000], Loss: 100.1052\n",
            "Epoch [9997/10000], Loss: 99.8454\n",
            "Epoch [9998/10000], Loss: 104.6111\n",
            "Epoch [9999/10000], Loss: 100.5508\n",
            "Epoch [10000/10000], Loss: 103.6642\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "num_epoch = 10000\n",
        "training_losses = []\n",
        "loss_history = []\n",
        "tolerance = 5\n",
        "xTrainTensor = torch.tensor(xTrainNumpy, dtype=torch.float32)\n",
        "yTrainTensor = torch.tensor(yTrainNumpy, dtype=torch.float32)\n",
        "# put xtrain and ytrain on device\n",
        "xTrainTensor = xTrainTensor.to(device)\n",
        "yTrainTensor = yTrainTensor.to(device)\n",
        "\n",
        "for epoch in range(1,num_epoch+1):\n",
        "    predict = model(xTrainTensor)\n",
        "    loss = criterion(predict.squeeze(), yTrainTensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    current_loss:float = loss.item()\n",
        "    loss_history.append(round(current_loss, 2))\n",
        "    if len(loss_history)>5:\n",
        "        if all(loss_history[-1] == last_loss for last_loss in loss_history[-tolerance-1:-1]):\n",
        "            print(f\"Training completed, Epoch: {epoch}, Final Loss: {current_loss:.4f}\")\n",
        "            break\n",
        "    print(f'Epoch [{epoch}/{num_epoch}], Loss: {current_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "2158832c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "2158832c",
        "outputId": "06417e10-62dc-4d94-a140-9db6fc372b23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_history, label='Loss History', color='blue')\n",
        "plt.title('Loss History Over Epochs')\n",
        "plt.xlabel('Epoch')  # X-axis label\n",
        "plt.ylabel('Loss')  # Y-axis label\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2c3d6def",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "2c3d6def"
      },
      "outputs": [],
      "source": [
        "def data_cleaner(file_name):\n",
        "    train_df = pd.read_csv(file_name)\n",
        "    clean_df = train_df.drop([\"Gender\",\"Smoking Status\", \"Alcohol Consumption\", \"Diet\", \"Family History\", \"Mental Health Status\", \"Sleep Patterns\", \"Stress Levels\", \"Pollution Exposure\", \"Sun Exposure\", \"Income Level\"], axis='columns')\n",
        "    columns_with_empty_cells = clean_df.columns[clean_df.isna().any()].tolist()\n",
        "    i=1\n",
        "\n",
        "    for col in columns_with_empty_cells:\n",
        "        clean_df[col] = clean_df[col].fillna(f\"None{i}\")\n",
        "        i+=1\n",
        "    clean_df[['Systolic Blood Pressure', 'Diastolic Blood Pressure']] = clean_df[\"Blood Pressure (s/d)\"].str.split('/', expand=True)\n",
        "    clean_df['Systolic Blood Pressure'] = clean_df['Systolic Blood Pressure'].astype(int)\n",
        "    clean_df['Diastolic Blood Pressure'] = clean_df['Diastolic Blood Pressure'].astype(int)\n",
        "    clean_df.pop(\"Blood Pressure (s/d)\")\n",
        "\n",
        "    # Handle categorical variables manually instead of using pd.get_dummies\n",
        "    categorical_columns = [\"Chronic Diseases\", \"Medication Use\", \"Education Level\", \"Physical Activity Level\"]\n",
        "\n",
        "    for cat_col in categorical_columns:\n",
        "        unique_values = clean_df[cat_col].unique()\n",
        "        for value in unique_values:\n",
        "            if pd.notna(value):  # Skip NaN values\n",
        "                col_name = f\"{value}\"\n",
        "                clean_df[col_name] = (clean_df[cat_col] == value).astype(int)\n",
        "        clean_df.pop(cat_col)\n",
        "\n",
        "    xdf = clean_df\n",
        "    xNumpy = xdf.to_numpy()\n",
        "\n",
        "    xNumpy = np.array(xNumpy, dtype=np.float32)\n",
        "    xNumpy[xNumpy == True] = 1\n",
        "    xNumpy[xNumpy == False] = 0\n",
        "\n",
        "    xTensor = torch.tensor(xNumpy, dtype=torch.float32)\n",
        "\n",
        "    return xTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "8c621ea6",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "8c621ea6"
      },
      "outputs": [],
      "source": [
        "xTestTensor = data_cleaner('Test.csv')\n",
        "# change device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "xTestTensor = xTestTensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check device of model and xTestTensor\n",
        "print(next(model.parameters()).device)\n",
        "print(xTestTensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFTu5l3nBSp5",
        "outputId": "44c7c78b-570a-495c-d416-f48a7ea54546"
      },
      "id": "nFTu5l3nBSp5",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evalute on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(xTestTensor)\n",
        "\n",
        "# print predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqetHWO0A_bl",
        "outputId": "174f20d3-c898-419f-aafe-cd55caec72d2"
      },
      "id": "VqetHWO0A_bl",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[79.7560],\n",
            "        [71.1430],\n",
            "        [73.3879],\n",
            "        ...,\n",
            "        [75.9043],\n",
            "        [32.3913],\n",
            "        [65.2671]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMbCqc84AeeP",
        "outputId": "52fda0f0-a40d-40d4-f85f-09d6003be3a1"
      },
      "id": "jMbCqc84AeeP",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-b12886257c97>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('age_predictor.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), 'age_predictor.pth')"
      ],
      "metadata": {
        "id": "tTwyqGSr_Rwd"
      },
      "id": "tTwyqGSr_Rwd",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "dbc2dbdd",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "dbc2dbdd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the saved model from file\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AgePredictionNN()\n",
        "model.load_state_dict(torch.load('age_predictor.pth',weights_only=True))\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "xTestTensor = xTestTensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "9dbc14be",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dbc14be",
        "outputId": "0d1c7dab-7ed8-4838-ec4b-e3258f110390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+---------------+\n",
            "| Row | True Age | Predicted Age |\n",
            "+-----+----------+---------------+\n",
            "|  1  |    89    |      79       |\n",
            "|  2  |    77    |      71       |\n",
            "|  3  |    70    |      73       |\n",
            "|  4  |    52    |      57       |\n",
            "|  5  |    79    |      76       |\n",
            "|  6  |    29    |      25       |\n",
            "|  7  |    76    |      78       |\n",
            "|  8  |    26    |      27       |\n",
            "|  9  |    50    |      56       |\n",
            "| 10  |    77    |      78       |\n",
            "| 11  |    77    |      77       |\n",
            "| 12  |    64    |      63       |\n",
            "| 13  |    65    |      75       |\n",
            "| 14  |    25    |      23       |\n",
            "| 15  |    47    |      48       |\n",
            "| 16  |    26    |      31       |\n",
            "| 17  |    56    |      60       |\n",
            "| 18  |    53    |      41       |\n",
            "| 19  |    76    |      73       |\n",
            "| 20  |    20    |      29       |\n",
            "+-----+----------+---------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "\n",
        "# Load the training data to get true ages\n",
        "train_data = pd.read_csv('Train.csv')\n",
        "train_subset = train_data.iloc[:20]  # Take first 20 samples\n",
        "true_ages = train_subset['Age (years)'].tolist()\n",
        "\n",
        "# Create a copy of the data without the 'Age (years)' column for data_cleaner\n",
        "train_data_copy = train_data.copy()\n",
        "train_data_copy.pop('Age (years)')\n",
        "train_data_copy.to_csv('Train_without_age.csv', index=False)\n",
        "\n",
        "# Use the data_cleaner function to process the training data\n",
        "train_tensor = data_cleaner('Train_without_age.csv')\n",
        "train_tensor = train_tensor[:20].to(device)  # Take first 20 samples and move to device\n",
        "\n",
        "# Get predictions for the subset\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    subset_predictions = model(train_tensor)\n",
        "\n",
        "# Convert predictions to integers\n",
        "predicted_ages = subset_predictions.cpu().int().numpy().flatten().tolist()\n",
        "\n",
        "# Create comparison table with index, true age, and predicted age\n",
        "comparison_table = [[i + 1, true, pred] for i, (true, pred) in enumerate(zip(true_ages, predicted_ages))]\n",
        "print(tabulate(comparison_table, headers=[\"Row\", \"True Age\", \"Predicted Age\"],\n",
        "               tablefmt=\"pretty\", stralign=\"center\"))"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}